The Role of Emotions in Native Language Identiﬁcation
Ilia Markov1, Vivi Nastase2, Carlo Strapparava3, Grigori Sidorov4

1INRIA, Paris, France

2University of Heidelberg, Heidelberg, Germany

3Fondazione Bruno Kessler, Trento, Italy

4Instituto Polit´ecnico Nacional, Center for Computing Research, Mexico City, Mexico

ilia.markov@inria.fr, nastase@cl.uni-heidelberg.de,

strappa@fbk.eu, sidorov@cic.ipn.mx

Abstract

We explore the hypothesis that emotion is one
of the dimensions of language that surfaces
from the native language into a second lan-
guage. To check the role of emotions in native
language identiﬁcation (NLI), we model emo-
tion information through polarity and emotion
load features, and use document representa-
tions using these features to classify the native
language of the author. The results indicate
that emotion is relevant for NLI, even for high
proﬁciency levels and across topics.

1 Introduction
Native Language Identiﬁcation (NLI) is the task
of identifying the native language (L1) of a person
based on his/her writing in the second language
(L2). NLI can inform security, marketing and ed-
ucational applications by tuning pedagogical ma-
terials to L1s, and for this it is important to un-
derstand the phenomena that get transfered from
L1 to L2 (native language interference). Emotion
is one of these. Linguistics research (Dewaele,
2010) has focused on the way emotions are en-
coded in different text types and in different lan-
guages. How to express emotion appropriately is
related to the origin of the speaker (country, re-
gion), situational context in which social norms
might be different (formal vs.
informal setting),
interlocutors (age, gender, social distance), topic.
As emotions are psychological constructions
of cultural meaning, there may be a misﬁt be-
tween emotions and social context when individ-
uals change cultural contexts or live two cultural
models (Leersnyder et al., 2011). The use of emo-
tions is considered both culture- and language-
speciﬁc (Wierzbicka, 1994, 1999). We hypothe-
size that this leads to different emotion signals in
writings in a second language, by authors with dif-
ferent native languages.

We test this hypothesis through multi-class clas-
siﬁcation of the L1 of the authors of essays writ-
ten in L2 in different experimental set-ups that
take into account proﬁciency levels and topics of
the written essays. We encode emotion infor-
mation using polarity and sentiment information
from the NRC Word-Emotion Association Lexi-
con (NRC emotion lexicon) (Mohammad and Tur-
ney, 2013), taking into account not only the ﬁne-
grained (word-level) emotion information, but
also general aspects of the written material (over-
all high- or low-emotion load). The results show
that emotional information contributes to detect-
ing the native language of the speaker.

2 Related Work

Caldwell-Harris (2014) shows that emotion usage
depends on the language by focusing on differ-
ences in emotion usage in L1 and L2. The author
states that there is a correlation between the usage
of emotions and proﬁciency levels and the age a
language is acquired.

While emotion-based features have been used
in other NLP tasks, such as sentiment analy-
sis (Sidorov et al., 2013), classiﬁcation of doc-
uments into the corresponding emotion cate-
gory (Wen and Wan, 2014), deception detec-
tion (Newman et al., 2003), among others, they are
an underexplored area of second language writing.
Torney et al. (2012) use psycholinguistic fea-
tures extracted by the Linguistic Inquiry and
Word Count (LIWC) tool (Pennebaker et al.,
2007) to identify the ﬁrst language of an author,
where emotion-based features are included as part
of the feature vector, e.g., percentage of posi-
tive/negative emotion words. The LIWC feature
set used in the paper also contains other types of
features, e.g., personal concern categories (work,
leisure), paralinguistic dimensions (assents, ﬁllers,

Proceedingsofthe9thWorkshoponComputationalApproachestoSubjectivity,SentimentandSocialMediaAnalysis,pages123–129Brussels,Belgium,October31,2018.c(cid:13)2018AssociationforComputationalLinguisticshttps://doi.org/10.18653/v1/P17123nonﬂuencies), which obscure the contribution of
the actual emotion features.

Rangel and Rosso (2013; 2016) investigate and
conﬁrm the hypothesis that the use of emotions
depends on author’s age and gender. The au-
thors used a graph-based approach, where each
node and edge were represented by the corre-
sponding part-of-speech (POS) tag, then the repre-
sentation was enriched with semantic information,
emoticons, and with emotion information, which
included polarity of words (polarity of common
nouns, adjectives, adverbs or verbs in a sentiment
lexicon) and emotionally charged words (replac-
ing common nouns, adjectives, adverbs or verbs
with the emotion information from the Spanish
Emotion Lexicon (Sidorov et al., 2013)). The rep-
resentation combining all the features described
above was used with a SVM classiﬁer.

Rangel and Rosso (2013; 2016) suggest that
there are commonalities in the use of emotions
across author age and gender. We examine the hy-
pothesis that there are commonalities in the use of
emotions in L2 across different L1s, suggested by
the linguistic and psycholinguistic studies (Leer-
snyder et al., 2011; Wierzbicka, 1999). We test
this by evaluating the impact of emotion-based
features on classifying the L1 of the authors of es-
says written in L2.

3 Emotion features for NLI
The best performing features for NLI are word
and character n-grams (Jarvis et al., 2013). They
cover – and obscure – a wide range of phenomena,
because language usage has multiple dimensions
that can reveal information such as age, gender,
cultural inﬂuences.
In this study, we investigate
the impact of words that have an emotion signal,
since studies have shown that emotion is culture
speciﬁc (Wierzbicka, 1994, 1999), and thus could
be indicative of the native language of a speaker.

3.1 Datasets
We conduct experiments on two datasets com-
monly used in NLI research:

(Blanchard et al., 2013):

TOEFL11
the ETS
Corpus of Non-Native Written English (TOEFL11)
contains 1,100 essays in English (avg. 348 to-
kens/essay) for each of the 11 L1s: Arabic (ARA),
Chinese (CHI), French (FRE), German (GER),
Hindi (HIN), Italian (ITA), Japanese (JPN), Ko-
rean (KOR), Spanish (SPA), Telugu (TEL), and

Turkish (TUR). The essays were written in re-
sponse to eight different writing prompts, all of
which appear in all 11 L1 groups. The dataset con-
tains information regarding the proﬁciency level
(low, medium, high) of the authors.

(Granger et al., 2009):

ICLE
the ICLEv2
dataset consists of essays written by highly-
proﬁcient non-native college-level students of En-
glish. We used a 7-language subset of the cor-
pus normalized for topic and character encod-
ing (Tetreault et al., 2012; Ionescu et al., 2014) to
which we refer as ICLE. This subset contains 110
essays (avg. 747 tokens/essay after tokenization
and removal of metadata) for each of the 7 lan-
guages: Bulgarian (BUL), Chinese (CHI), Czech
(CZE), French (FRE), Japanese (JPN), Russian
(RUS), and Spanish (SPA).

the

version

(NLTK)1

(pre-)tokenized

3.2 Experiment setup
of
We
used
and tokenized ICLE with the Nat-
TOEFL11
ural Language Toolkit
tokenizer.
ICLE metadata was removed in pre-processing.
Each essay was represented through the sets of
features described below, using term frequency
(tf) and the liblinear scikit-learn (Pedregosa
et al., 2011) implementation of Support Vector
Machines (SVM) with OvR (one vs.
the rest)
multi-class strategy. We report classiﬁcation
accuracy on 10-fold cross-validation experiments.

3.3 Features
3.3.1 Part-of-speech tags and function words
POS tag n-grams and function words (FWs) are
considered core features in NLI research (Mal-
masi and Dras, 2015), not susceptible to topic bias,
unlike word and character n-grams (Brooke and
Hirst, 2011).

POS n-grams, n=1..3 POS features capture the
morpho-syntactic patterns in a text, and are in-
dicative of the L1, especially when used in com-
bination with other types of features (Cimino and
Dell’Orletta, 2017; Markov et al., 2017). POS tags
were obtained with TreeTagger (Schmid, 1999),
which uses the Penn Treebank tagset (36 tags).

Function words (FWs) n-grams, n=1..3 Func-
tion words clarify the relationships between the
content-carrying elements of a sentence, and intro-
duce syntactic structures like verbal complements,

1http://www.nltk.org

124relative clauses, and questions (Smith and Witten,
1993). They are considered one of the most impor-
tant stylometric features (Kestemont, 2014). The
FW feature set consists of 318 English FWs from
the scikit-learn package (Pedregosa et al., 2011).
With respect to emotion features, FWs can ap-
pear as quantiﬁers, intensiﬁers (e.g., very good) or
modify the emotion expressed in other ways.
3.3.2 Emotion words
We use the 14,182 emotion words and their asso-
ciations with eight emotions (anger, fear, antici-
pation, trust, surprise, sadness, joy, and disgust)
and two sentiments (negative and positive) from
the NRC emotion lexicon (Mohammad and Tur-
ney, 2013). Table 1 presents the emotion words
statistics for our data.

TOEFL11
L1
No.
96,184 KOR
HIN
88,979
88,268
CHI
TEL
87,486
JPN
83,945
TUR
82,878
82,454
FRE
81,497 GER
75,339
ITA
SPA
73,740

L1
%
L1
CZE
24.93
HIN
24.62
RUS
TEL
24.32 BUL
GER
SPA
24.19
CHI
CHI
24.15
TUR
FRE
23.90
KOR
23.30
JPN
FRE
23.21
SPA
23.16
ITA
JPN
22.40
ARA 69,156 ARA 21.91

ICLE

L1
No.
20,162
CHI
20,142 BUL
18,939
JPN
RUS
17,187
FRE
16,794
CZE
16,750
16,234
SPA

%
26.81
25.06
24.74
24.72
23.88
23.81
23.33

Table 1: Emotion words statistics (absolute number and
frequency) sorted from the highest to the lowest.

Before committing to analyzing emotion fea-
tures, we want to test whether emotion-loaded
words have any impact on the NLI task. The bag-
of-words (BoW) representation covers a variety of
phenomena, without distinguishing them and giv-
ing us insight into their individual impact on the
task. We represent our data using BoW varia-
tions – including and excluding words that have
an emotional dimension. To verify that the ef-
fect in classiﬁcation is not just due to a smaller
feature set, we match the BoW size by removing
a selection of random words. Table 2 presents
the 10-fold cross-validation results (accuracy, %)
on the TOEFL11 and ICLE datasets, when using
emotion words and random words of such that the
BoW representations have the same size, as well
as the results when excluding emotion words and
the random words.2

The results in Table 2 show that emotion words
have higher impact on classiﬁcation accuracy than
random words when evaluated in isolation. More-
over, the accuracy drop is higher when excluding
2Random words accuracy was calculated as average over

ﬁve experiments with ﬁve different sets of random words.

Features
BoW
Random words
Emotion words
BoW w/o random words
BoW w/o emotion words

TOEFL11

Acc., % No.
61,339
68.65
8,187
36.15
8,187
46.75
53,152
66.68
63.11
53,152

ICLE

Acc., % No.
20,032
80.65
6,465
70.21
72.86
6,465
13,567
76.83
75.19
13,567

Table 2: Performance of emotion words.

emotion words from the BoW approach than when
excluding random words, conﬁrming that emotion
is a useful dimension for L1 classiﬁcation, and not
just an effect of having additional features.

3.3.3 Emotion features
Having conﬁrmed that due to cultural identity and
linguistic habits of an author’s native language, we
can distinguish the L1 of the author of an essay, we
proceed with a deeper analysis, for which we build
two types of emotion features.

Emotion polarity features
(emoP) In the NRC
emotion lexicon, binary associations are provided
for each emotion word for 8 emotions (anger, fear,
anticipation, trust, surprise, sadness, joy, or dis-
gust) and two sentiments (negative or positive) –
e.g., good = “0100101011”. This representation is
used as a categorial feature (not a 10-dimensional
binary vector).
It performed best compared to
other ways of encoding the emotion information
we tried, e.g., using a 10-dimensional binary vec-
tor or excluding the sentiment information.

The emoP features are added to the POS
and to POS & FW representations:
the phrase
This is very good is represented through POS
& emoP unigrams as ‘DT’, ‘VBZ’, ‘RB’, ‘JJ-
0100101011’, or as 3-grams ‘DT VBZ RB’,
VBZ RB JJ-0100101011’, and as POS & FW
& emoP 3-grams as ‘This is very’, ‘is very JJ-
0100101011’.

Emotion load features
(emoL) Speakers of dif-
ferent L1s may use a higher or lower number of
emotionally charged words than speakers of other
L1s, reﬂecting cultural customs or linguistic habits
of the respective cultures. We modeled this infor-
mation using three types of emotion load features:
(i) two binary features, emoL (binary) that capture
whether an essay has a high or low emotional load:
(a) we compute the average ratio of emotion words
in all essays in each dataset: for TOEFL11 this was
0.236 and for ICLE 0.246; (b) if the ratio of emo-
tion words in an essay was higher/lower than the
average, assigned it a “highly-emotional”/“low-
emotional” feature. We used this representation

125to examine whether the polarity as such is infor-
mative. We also used more ﬁne-grained emoL fea-
tures: (ii) the ratio of the emotion words in each
essay as a numeric feature (1 feature, emoL (1)),
and (iii) the ratio of each emotion/sentiment in
each essay (10 numeric features: 8 emotions and
2 sentiments, emoL (10)). Overall, three different
types of emoL features are examined.

4 Results and Discussion
Following previous studies on NLI
(Markov
et al., 2018) and author proﬁling (Rangel and
Rosso, 2016), we provide the results when adding
emotion-based features to POS tag feature set. We
also experiment with POS and FW feature sets
similarly to, e.g., (Malmasi and Dras, 2015).

The 10-fold cross-validation results in terms of
accuracy (%) on the TOEFL11 and ICLE datasets
for POS and POS & FW n-gram (n = 1–3) rep-
resentations are shown in Tables 3 and 4, respec-
tively. The number of features (No.) is included.
Statistically signiﬁcant gains/drops according to
McNemar’s statistical signiﬁcance test (McNe-
mar, 1947) with α < 0.05 are marked with ‘*’.

The experimental results show that emotion fea-
tures, in particular the emoP features, signiﬁcantly
contribute to the results for all the considered set-
tings, indicating that different cultures (as deﬁned
by the authors’ L1) have different emotion word
usage. It is very interesting to note that despite be-
ing very general, the three types of emoL features –
13 features that characterize the emotional load of
a document – also improve the results in the major-
ity of settings, including when combined with the
emoP features. This supports the hypothesis that
some cultures use a bigger or smaller emotional
vocabulary. More ﬁne grained emotional load fea-
tures could improve the results further.

To explore whether emotion usage depends on
speciﬁc topics, we conducted experiments for the
topics in the TOEFL11 dataset (Table 5).3 The im-
provement brought by the emotion-based features
does seem to depend on the topic, as some top-
ics more naturally elicit emotional reactions. The
highest improvements were achieved for P5 (car
usage) and P7 (young vs. old people comparison).
When combined with the POS & FW representa-
tion, emotion-based features are less helpful (not

3We did not conduct this experiment on the ICLE dataset,
since it has a higher number of topics, with a fewer number
of documents per topic, which would not allow us to learn
informative topic-speciﬁc models.

statistically signiﬁcant improvements) for the top-
ics discussing traveling (P1), ideas vs. facts (P3),
and education (P4). Overall, adding emotion-
based features to POS and POS & FW represen-
tations leads to accuracy improvement for all the
topics present in the dataset.

The ability to choose the proper words to ex-
press oneself increases with the proﬁciency level.
From this perspective, identifying the L1 of au-
thors of essays in L2 using emotion words infor-
mation should be performed with better results.
On the other hand, we expect other linguistic char-
acteristics to become closer to a native L2 speaker,
and thus make identifying L1 harder. We exper-
iment with L1 classiﬁcation separating the data
based on the three different proﬁciency levels in
TOEFL11. The results are included in Table 6.
With respect to the emotion features, medium and
high proﬁciency levels have a much better perfor-
mance. As postulated above, this could be ex-
plained by the different ability of the L1 speakers
to choose the words that express closely the mes-
sage and nuances they wish to convey.

5 Conclusions
We investigated the hypothesis that the use of
emotions is indicative of an author’s native lan-
guage. We used two types of emotion-based fea-
tures – one that captures the types of sentiments
expressed,
the other captures the frequency of
emotion words in documents. We expected these
features to capture cultural characteristics and lin-
guistic habits from the authors’ L1. The fact that
adding these features to POS and function word
n-grams leads to improvements in predicting a
text’s author’s native language leads us to con-
clude that emotion characteristics from a native
language are “imported” into the production of L2.
The overall goal of this paper was to understand
the inﬂuence of various facets of L1 speakers’ lan-
guage and culture on their acquisition (and pro-
duction) of L2. These inﬂuences from L1 are not
under the author’s conscious control, and it is very
interesting to understand their nature. Emotion is
one of these. The fact that we explore the use of
emotions on learner corpora (“controlled environ-
ment”), with a speciﬁc task and speciﬁc require-
ment – and a (implied, not speciﬁcally requested)
more neutral style – should probably lower the ef-
fect of emotional inﬂuences from the L1 and its
culture. From that point of view, it is even more
remarkable that such an effect is detected.

126TOEFL11

Features

POS 1–3-grams (baseline)
POS 1–3-grams + emoL (binary)
POS 1–3-grams + emoL (1)
POS 1–3-grams + emoL (10)
POS 1–3-grams + emoL (binary) + emoL (1) + emoL (10)
Difference:
POS 1–3-grams + emoP
Difference:
POS 1–3-grams + emotion-based features
Difference (with POS 1–3 + emoP):
Difference (with baseline):

Acc., %
40.16
40.60
40.19
40.41
40.65
0.49*
50.36
10.20*
50.28
–0.08
10.12*

No.
17,483
17,485
17,484
17,493
17,496

216,090

216,103

ICLE

Acc., % No.
11,755
62.86
11,757
62.86
11,756
62.86
62.99
17,765
62.60
11,768
–0.26
67.66
4.80*
67.79
0.13
4.93*

90,920

90,933

Table 3: 10-fold cross-validation accuracy for POS 1–3-grams combined with emotion-based features. ‘*’ marks
statistically signiﬁcant differences.

TOEFL11

ICLE

Features

POS 1–3-grams
POS & FW 1–3-grams (baseline)
Difference:
POS & FW 1–3-grams + emoL (binary)
POS & FW 1–3-grams + emoL (1)
POS & FW 1–3-grams + emoL (10)
POS & FW 1–3-grams + emoL (binary) + emoL (1) + emoL (10)
Difference:
POS & FW 1–3-grams + emoP
Difference:
POS & FW 1–3-grams + emotion-based features
Difference (with POS & FW 1–3 + emoP):
Difference (with baseline):

Acc., %
40.16
64.06
23.90*
64.10
64.10
64.09
64.13
0.07
67.73
3.67*
67.85
0.12
3.79*

No.
17,483
411,599

411,601
411,600
411,609
411,612

880,595

880,608

No.
11,755
138,170

138,172
138,171
138,180
138,183

268,605

268,618

Acc., %
62.86
74.42
11.56*
74.42
74.42
74.42
74.42
0.00
77.92
3.50*
78.31
0.39
3.89*

Table 4: 10-fold cross-validation accuracy for POS & FW 1–3-grams combined with emotion-based features. ‘*’
marks statistically signiﬁcant differences.

POS 1–3-grams
POS 1–3-grams + emotion-based features
Difference:
POS & FW 1–3-grams
POS & FW 1–3-grams + emotion-based features
Difference:
No. of emotion words:
Ratio:

P0
33.74
41.14
7.40*
50.54
53.18
2.64*
99,606
0.213

P1
39.26
47.34
8.08*
56.54
57.66
1.12
75,308
0.239

P2
38.54
44.79
6.25*
53.28
56.56
3.28*
116,795
0.222

P3
39.89
46.02
6.13*
55.62
57.04
1.42

P4
42.40
49.12
6.72*
60.34
62.28
1.94

118,427
0.226

122,741
0.238

P5
38.29
49.55
11.26*
56.84
62.40
5.56*
129,837
0.239

P6
42.08
49.01
6.93*
57.79
61.46
3.67*
107,924
0.243

P7
38.15
47.19
9.04*
55.31
58.66
3.35*
139,288
0.274

Table 5: 10-fold cross-validation accuracy for each topic in the TOEFL11 dataset. ‘*’ marks statistically signiﬁcant
differences.

POS 1–3-grams
POS 1–3-grams + emotion-based features
Difference:
POS & FW 1–3-grams
POS & FW 1–3-grams + emotion-based features
Difference:
No. of emotion words:
Ratio:

Low

Medium

High

Acc., %
41.10
44.56
3.46*
52.40
54.13
1.73
62,223
0.228

No.
9,751
51,108

91,340
155,725

No.

15,334
152,059

L

288,658
585,083

Acc., %
43.07
52.64
9.57*
66.52
69.09
2.57*
475,665
0.235

No.

14,454
136,783

242,880
491,342

Acc., %
34.65
42.58
7.93*
54.25
57.20
2.95*
372,025
0.242

Table 6: 10-fold cross-validation accuracy for each proﬁciency level. ‘*’ marks statistically signiﬁcant differences.

127References
Daniel Blanchard,

Joel Tetreault, Derrick Hig-
gins, Aoife Cahill, and Martin Chodorow. 2013.
TOEFL11: A corpus of non-native English. ETS
Research Report Series, 2013(2):i–15.

Julian Brooke and Graeme Hirst. 2011. Native lan-
In
guage detection with ‘cheap’ learner corpora.
Proceedings of
the Conference of Learner Cor-
pus Research, pages 37–47, Louvain-la-Neuve, Bel-
gium. Presses universitaires de Louvain.

Catherine Caldwell-Harris. 2014. Emotionality dif-
ferences between a native and foreign language:
Theoretical implications. Frontiers in Psychology,
5(1055).

Andrea Cimino and Felice Dell’Orletta. 2017. Stacked
sentence-document classiﬁer approach for improv-
In Proceedings
ing native language identiﬁcation.
of the 12th Workshop on Building Educational Ap-
plications Using NLP, pages 430–437, Copenhagen,
Denmark. ACL.

Jean-Marc Dewaele. 2010. Emotions in Multiple Lan-

guages. Basingstoke: Palgrave Macmillan.

Sylviane Granger, Estelle Dagneaux, Fanny Meunier,
and Magali Paquot. 2009. International Corpus of
Learner English v2 (ICLE). Presses Universitaires
de Louvain, Louvain-la-Neuve, Belgium.

Radu Tudor Ionescu, Marius Popescu, and Aoife
Cahill. 2014. Can characters reveal your native lan-
guage? A language-independent approach to native
language identiﬁcation. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1363–1373, Doha, Qatar.
ACL.

Scott Jarvis, Yves Bestgen, and Steve Pepper. 2013.
Maximizing classiﬁcation accuracy in native lan-
In Proceedings of the Eighth
guage identiﬁcation.
Workshop on Innovative Use of NLP for Building
Educational Applications, pages 111–118, Atlanta,
GA, USA. ACL.

Mike Kestemont. 2014. Function words in authorship
In Pro-
attribution. From black magic to theory?
ceedings of the 3rd Workshop on Computational Lin-
guistics for Literature, pages 59–66, Gothenburg,
Sweden. ACL.

Jozeﬁen De Leersnyder, Batja Mesquita, and Hee-
jung S. Kim. 2011. Where do my emotions belong?
a study of immigrants’ emotional acculturation. Per-
sonality and Social Psychology Bulletin, 37(4):451–
463.

Shervin Malmasi and Mark Dras. 2015. Multilingual
native language identiﬁcation. Natural Language
Engineering, 23(2):163–215.

Ilia Markov, Lingzhen Chen, Carlo Strapparava, and
Grigori Sidorov. 2017. CIC-FBK approach to native
language identiﬁcation. In Proceedings of the 12th
Workshop on Building Educational Applications Us-
ing NLP, pages 374–381, Copenhagen, Denmark.
ACL.

Ilia Markov, Vivi Nastase, and Carlo Strapparava.
2018. Punctuation as native language interference.
In Proceedings of the 27th International Conference
on Computational Linguistics, pages 3456–3466,
Santa Fe, New Mexico, USA. The COLING 2018
Organizing Committee.

Quinn McNemar. 1947. Note on the sampling error
of the difference between correlated proportions or
percentages. Psychometrika, 12(2):153–157.

Saif Mohammad and Peter Turney. 2013. Crowdsourc-
ing a word-emotion association lexicon. Computa-
tional Intelligence, 29:436–465.

Matthew Newman, James Pennebaker, Diane Berry,
and Jane Richards. 2003. Lying words: Predicting
deception from linguistic styles. Personality and So-
cial Psychology Bulletin, 29(5).

Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Matthieu Brucher,
Matthieu Perrot, and ´Edouard Duchesnay. 2011.
Scikit-learn: Machine learning in Python. Journal
of Machine Learning Research, 12:2825–2830.

James Pennebaker, Roger Booth, and Martha Fran-
Linguistic Inquiry and Word Count:

cis. 2007.
LIWC2007. Austin, TX: LIWC.net.

Francisco Rangel and Paolo Rosso. 2013. On the iden-
tiﬁcation of emotions and authors’ gender in Face-
book comments on the basis of their writing style.
In Proceedings of the First International Workshop
on Emotion and Sentiment in Social and Expres-
sive Media: Approaches and perspectives from AI,
volume 1096, pages 34–46, Torino, Italy. CEUR-
WS.org.

Francisco Rangel and Paolo Rosso. 2016. On the im-
Information

pact of emotions on author proﬁling.
Processing & Management, 52(1):74–92.

Helmut Schmid. 1999.

Improvements In Part-of-
Speech Tagging With an Application to German.
Springer.

Grigori Sidorov, Sabino Miranda-Jim´enez, Francisco
Viveros-Jim´enez, Alexander Gelbukh, No´e Castro-
S´anchez, Francisco Vel´asquez, Ismael D´ıaz-Rangel,
Sergio Su´arez-Guerra, Alejandro Trevi˜no, and Juan
Gordon. 2013. Empirical study of machine learn-
ing based approach for opinion mining in tweets.
In Proceedings of the Mexican International Confer-
ence on Artiﬁcial Intelligence, volume 7629, pages
1–14, San Luis Potos´ı. Mexico. Springer.

128Tony C. Smith and Ian H. Witten. 1993. Language
inference from function words. Working papers,
https://hdl.handle.net/10289/9927.

Joel Tetreault, Daniel Blanchard, Aoife Cahill, and
Martin Chodorow. 2012. Native tongues, lost and
found: Resources and empirical evaluations in na-
In Proceedings of the
tive language identiﬁcation.
24th International Conference on Computational
Linguistics, pages 2585–2602, Mumbai, India. The
COLING 2012 Organizing Committee.

Rosemary Torney, Peter Vamplew, and John Yearwood.
2012. Using psycholinguistic features for proﬁling
ﬁrst language of authors. Journal of the Association
for Information Science and Technology, 63(6).

Shiyang Wen and Xiaojun Wan. 2014. Emotion clas-
siﬁcation in microblog texts using class sequential
In Proceedings of the Twenty-Eighth AAAI
rules.
Conference on Artiﬁcial Intelligence, pages 187–
193, Quebec, Canada. AAAI Press.

Anna Wierzbicka. 1994. Emotion, language, and cul-
tural scripts. Emotion and culture: Empirical stud-
ies of mutual inﬂuence, pages 133–196.

Anna Wierzbicka. 1999. Emotions across languages
and cultures: Diversity and universals. Cambridge
University Press.

129