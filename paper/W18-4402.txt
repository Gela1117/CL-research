RiTUAL-UH at TRAC 2018 Shared Task: Aggression Identiﬁcation

Niloofar Saﬁ Samghabadi

Deepthi Mave

Sudipta Kar

Thamar Solorio

Department of Computer Science

University of Houston

Houston, TX 77204-3010

{nsafisamghabadi, dmave, skar3, tsolorio}@uh.edu

Abstract

This paper presents our system for “TRAC 2018 Shared Task on Aggression Identiﬁcation”. Our
best systems for the English dataset use a combination of lexical and semantic features. However,
for Hindi data using only lexical features gave us the best results. We obtained weighted F1-
measures of 0.5921 for the English Facebook task (ranked 12th), 0.5663 for the English Social
Media task (ranked 6th), 0.6292 for the Hindi Facebook task (ranked 1st), and 0.4853 for the
Hindi Social Media task (ranked 2nd).

1

Introduction

Users’ activities on social media is increasing at a fast rate. Unfortunately, a lot of people misuse these
online platforms to harass, threaten, and bully other users. This growing aggression against social media
users has caused serious effects on victims, which can even lead them to harm themselves. The TRAC
2018 Shared Task on Aggression Identiﬁcation (Kumar et al., 2018a) aims at developing a classiﬁer that
could make a 3-way classiﬁcation of a given data instance between “Overtly Aggressive”, “Covertly
Aggressive”, and “Non-aggressive”. We present here the different systems we submitted to the shared
task, which mainly use lexical and semantic features to distinguish different levels of aggression over
multiple datasets from Facebook and other social media that cover both English and Hindi texts.

2 Related Work

In recent years, several studies have been done towards detecting abusive and hateful language in online
texts. Some of these works target different online platforms like Twitter (Waseem and Hovy, 2016),
Wikipedia (Wulczyn et al., 2016), and ask.fm (Samghabadi et al., 2017) to encourage other research
groups to contribute to aggression identiﬁcation in these sources.

Most of the approaches proposed to detect offensive language in social media make use of multiple
types of hand-engineered features. Nobata et al. (2016) use n-grams, linguistic, syntactic and distri-
butional semantic features to build a hate speech detection framework over Yahoo! Finance and News
and get an F-score of 81% for a combination of all features. Davidson et al. (2017) combine n-grams,
POS-colored n-grams, and sentiment lexicon features to detect hate speech on Twitter data. Van Hee et
al. (2015) use word and character n-grams along with sentiment lexicon features to identify nasty posts
in ask.fm. Samghabadi et al. (2017) build a model based on lexical, semantic, sentiment, and stylistic
features to detect nastiness in ask.fm. They also show the robustness of the model by applying it to the
dataset from different other sources.

Based on Malmasi and Zampieri (2018), distinguishing hate speech from profanity is not a trivial task
and requires features that capture deeper information from the comments. In this paper, we try different
combinations of lexical, semantic, sentiment, and lexicon-based features to identify various levels of
aggression in online texts.

This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/.

ProceedingsoftheFirstWorkshoponTrolling,AggressionandCyberbullying,pages12–18SantaFe,USA,August25,2018.123 Methodology and Data

3.1 Data

Data
English
Hindi

Training (FB) Validation (FB) Test (FB) Test (SM)
1257
1194

12000
12000

3001
3001

916
970

Table 1: Data distribution for English and Hindi corpus

The datasets were provided by Kumar et al. (2018b). Table 1 shows the distribution of training,
validation and test (Facebook and social media) data for English and Hindi corpora. The data has been
labeled with one out of three possible tags:

• Non-aggressive (NAG): There is no aggression in the text.
• Overtly aggressive (OAG): The text is containing either aggressive lexical items or certain syntac-

tic structures.

• Covertly aggressive (CAG): The text is containing an indirect attack against the target using polite

expressions in most cases.

3.2 Data Pre-processing
Generally the data from social media resources is noisy, grammar and syntactic errors are common, with
a lot of ad-hoc spellings, that make it hard to analyze. Therefore, we ﬁrst put our efforts to clean and
prepare the data to feed it to our systems. For the English dataset, we lowercased the data and removed
URLs, Email addresses, and numbers. We also did minor stemming by removing “ing”, plural and
possessive “s”, and replaced a few common abstract grammatical forms with the formal versions.

On manual inspection of the training data for Hindi, we found that some of the instances are Hindi-
English code-mixed, some use Roman script for Hindi and others are in Devanagari. Only 26% of the
training data is in Devanagari script. We normalize the data by transliterating instances in Devanagari
to Roman script. These instances are identiﬁed using Unicode pattern matching and are transliterated
to Roman script using indic-trans transliteration tool1. For further analysis, we run an in-house word-
level language identiﬁcation system on the training data (Mave et al., 2018). This CRF system is trained
on Facebook posts and has an F1-weighted score of 97%. Approximately 60% of the training data is
code-mixed, 39% is only Hindi and 0.42% is only English.

3.3 Features
We make use of the following features:
Lexical: Words are powerful mediums to convey a feeling, describe or express ideas. With this notion,
we use word n-grams (n=1, 2, 3), char n-grams (n=3, 4, 5), and k-skip n-grams (k=2, n=2, 3) as features.
We weigh each term with its term frequency-inverse document frequency (TF-IDF). We also consider
using another weighting scheme by trying binary word n-grams (n=1, 2, 3).
Word Embeddings: The idea behind this approach is to use a vector space model for extracting se-
mantic information from the text (Le and Mikolov, 2014). For the embedding model we use pre-trained
vectors trained on part of Google News dataset including about 3 million words2. We computed word
embeddings feature vectors by averaging the word vector of all the words in each comment. We skip
the words which are not in the vocabulary of the pre-trained model. This representation is only used for
English data and the coverage of the Google word embedding is 63% for this corpus.

1https://github.com/libindic/indic-trans
2https://code.google.com/archive/p/word2vec/

13Sentiment: We use Stanford Sentiment Analysis tool (Socher et al., 2013)3 to extract ﬁne-grained sen-
timent distribution of each comment. For every message, we calculate the mean and standard deviation
of sentiment distribution over all sentences and use them as feature vector.
LIWC (Linguistic Inquiry and Word Count): LIWC2007 (Pennebaker et al., 2007) includes around
70 word categories to analyze different language dimensions. In our approach, we only use the categories
related to positive or negative emotions and self-references. To build the feature vectors in this case, we
use a normalized count of words separated by any of the mentioned categories. This feature is only
applicable to English data.
Gender Probability: Following the approach in Waseem (2016) we use the Twitter based lexicon pre-
sented in Sap et al. (2014) to calculate the probability of gender. We also convert these probabilities to
binary gender by considering the positive cases as female and the rest as male. We make the feature vec-
tors with the probability of the gender and binary gender for each message. This feature is not applicable
to Hindi corpus.

4 Experiments and Results
4.1 Experimental Settings
For both datasets, we trained several classiﬁcation models using different combinations of features dis-
cussed in 3.3. Since this is a multi-class classiﬁcation task, we use a one-versus-rest classiﬁer which
trains a separate classiﬁer for each class and labels each comment with the class with highest predicted
probability across all classiﬁers. We tried Logistic Regression and linear SVM as the estimator for the
classiﬁer. We decided to use Logistic Regression in our ﬁnal systems, since it works better in the valida-
tion phase. We implemented all models using scikit-learn tool4.

4.2 Results
To build our best systems for both English and Hindi data, we experimented with several models using
the different combinations of available features. Table 2 shows the validation results on training and
validation sets.

F1-weighted

English Hindi
Feature
0.5804
0.6159
Unigram (U)
0.5195
0.4637
Bigram (B)
0.4300
0.3846
Trigram (T)
0.5694
0.6065
Char 3gram (C3)
0.6212
0.5794
Char 4gram (C4)
0.6195
0.5758
Char 5gram (C5)
N/A
0.5463
Word Embeddings (W2V)
0.3961
N/A
Sentiment (S)
N/A
0.4350
LIWC
N/A
Gender Probability (GP)
0.3440
BU + U + C4 + C5 + W2V 0.5875
N/A
C3 + C4 + C5
0.5494
0.6207
0.6267
0.5541
U + C3 + C4 + C5

Table 2: Validation results for different features for the English and Hindi datasets using Logistic Re-
gression model. In this table BU stands for Binary Unigram.

Table 3 shows the results of our three submitted systems for the English Facebook and Social Media
data. In all three systems, we used the same set of features as follows: binary unigram, word unigram,

3https://nlp.stanford.edu/sentiment/code.html
4http://scikit-learn.org/stable/

14character n-grams of length 4 and 5, and word embeddings. In the ﬁrst system, we used both train and
validation sets for training our ensemble classiﬁer. In the second system we only used the train data for
training the model. The only difference between the second and the third models is that we corrected
the misspellings using PyEnchant5 spell checking tool. Unfortunately, we could not try applying the
sentiment and lexicon-based features after spell correction due to the restrictions on the total number of
submissions. However, we believe that it can improve the performance of the system.

System
Random Baseline
System 1
System 2
System 3

F1 (weighted)
FB
SM
0.3477
0.5453
0.5391
0.5663

0.3535
0.5673
0.5847
0.5921

Table 3: Results for the English test set. FB: Facebook and SM: Social Media.

System
Random Baseline
System 1
System 2

F1 (weighted)
FB
SM
0.3206
0.4853
0.4689

0.3571
0.6451
0.6292

Table 4: Results for the Hindi test set. FB: Facebook and SM: Social Media.

Table 4 shows the performance of our systems for the Hindi Facebook and social media data. For the
Hindi dataset, the combination of word unigrams, character n-grams of length 3, 4 and 5 gives the best
performance over the validation set. These features capture the word usage distribution across classes.
Both System 1 and System 2 use these features, trained over training set only and training and validation
sets respectively.

4.3 Analysis
Looking at the mislabeled instances at validation phase, we found that there are two main reasons for the
classiﬁer mistakes:

1. Perceived level of aggression can be subjective. There are some examples in the validation dataset
where the label is CAG but it is more likely to be OAG and vice versa. Table 5 shows some of these
examples.

2. There are several typos and misspellings in the data that affect the performance.

Language Example
English

What has so far Mr.Yechuri done for this Country. Ask him to shut down his bloody
piehole for good or I if given the chance will crap on his mouth hole.
The time you tweeted is around 3 am morning,,which is not at all a namaz time.,As
you bollywood carrier is almost ﬁnished, you are preparing yourself for politics by
these comments.
ajeeb chutya hai.... kahi se course kiya hai ya paida hee chutya hua tha
Salman aur aamir ki kounsi movie release huyee jo aandhi me dub gaye?? ?Bikau
chatukar media

Hindi

Table 5: Misclassiﬁed examples in case of the aggression level

5https://pypi.org/project/pyenchant

Label

Predicted
OAG

Actual
CAG

OAG

CAG
OAG

CAG

OAG
CAG

15Also, it is obvious from Figure 1 that Hindi corpus is more balanced than the English one in case of
OAG and CAG instances. That could be a good reason why the performance of the lexical features is
better for Hindi data.

(a) Data distribution for training sets

(b) Data distribution for evaluation sets

Figure 1: Label distribution comparison between training and evaluation sets

Table 6 illustrates the most informative features learned by the classiﬁer for all three classes in Hindi
data. We observe that word unigrams and character trigrams are the most important features for the
system. From the table, the top features for CAG are mostly swear words in Hindi and character n-grams
of the swear words. More English words appear in the top list for NAG than the other two classes.
There is no overlap between these features with top features from either CAG or OAG. Our system has
difﬁculty differentiating between OAG and CAG when there is no strong swear word in the comments.

NAG

unigram :

unigram mera
unigram bike
unigram jai
unigram main
unigram sahi
unigram ...........
unigram launch

unigram jay

CAG

unigram ?

unigram baki
unigram ??
unigram pm
unigram o

char tri gram ky
unigram badla
cha tri gram yad
char 5 gram e...

char tri gram mer

unigram 3

OAG

char tri gram kut

unigram bc

char tri gram cho
char 4 gram kut
unigram chutiya

unigram maa
unigram mc
unigram gand
char tri gram tiy
char tri gram chu

Table 6: Top 10 features learned by System 1 for each class for the Hindi dataset.

Figure 2a shows the confusion matrix of our best model for all three classes in English Facebook
corpus. The most interesting part of this ﬁgure is that the classiﬁer mislabeled several NAG instances with
CAG label. Since our system is mostly based on lexical features, we can conclude that there are much
fewer profanities in CAG instances comparing with the OAG ones, which make it hard to distinguish
them from NAG examples without considering the sentiment aspects of the messages. This fact can also
be proved by looking at Figure 2b, since it seems that the classiﬁer was also confused to label CAG
instances in both cases with and without profanities in English Social Media corpus.

Figure 3a shows that for Hindi Facebook data, the most biggest challenge is to distinguish OAG
instances from CAG ones. Since our proposed system, in this case, is completely built on lexical features,
it can be inferred from the ﬁgure that even indirect aggressive comments in Hindi language contains lots
of profanities. However, for the Hindi Social Media corpus, we have the same concern as English data.

16(a) EN-FB task

(b) EN-SM task

Figure 2: plots of confusion matrices of our best performing systems for English Facebook and Social
Media data

(a) HI-FB task

(b) HI-SM task

Figure 3: Plots of confusion matrices of our best performing systems for Hindi Facebook and Social
Media data

5 Conclusion

In this paper, we present our approaches to identify the aggression level in English and Hindi comments
in two different datasets, one from Facebook and another from other social media. In our best performing
systems, we use a combination of lexical and semantic features for English corpus, and lexical features
for Hindi data.

Future work for English data includes exploring more sentiment features to capture implicit hateful
comments and adding more pre-processing levels. For instance, non-English character removal can
improve the system since our proposed model is mainly based on lexical features, and is likely very
sensitive to unknown characters and words. For the Hindi dataset, identifying the Hindi-English code-
mixed instances and processing these instances and Hindi monolingual instances separately could be a
future direction to explore. As the classiﬁcation of aggression is subjective in most scenarios, adding
sentiment features to the lexical information might help to model performance for Hindi data.

17OAGCAGNAGPredicted labelOAGCAGNAGTrue label83421928793575210345Confusion Matrix0.00.10.20.30.40.5OAGCAGNAGPredicted labelOAGCAGNAGTrue label244744315013113226105352Confusion Matrix0.00.10.20.30.40.50.60.7OAGCAGNAGPredicted labelOAGCAGNAGTrue label199155869313312554116Confusion Matrix0.00.10.20.30.40.50.60.7OAGCAGNAGPredicted labelOAGCAGNAGTrue label177134148501551762378253Confusion Matrix0.00.10.20.30.40.50.60.7References
Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated Hate Speech Detection

and the Problem of Offensive Language. In Proceedings of ICWSM.

Ritesh Kumar, Atul Kr. Ojha, Shervin Malmasi, and Marcos Zampieri. 2018a. Benchmarking Aggression Identiﬁ-
cation in Social Media. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbulling (TRAC),
Santa Fe, USA.

Ritesh Kumar, Aishwarya N. Reganti, Akshit Bhatia, and Tushar Maheshwari. 2018b. Aggression-annotated
Corpus of Hindi-English Code-mixed Data. In Proceedings of the 11th Language Resources and Evaluation
Conference (LREC), Miyazaki, Japan.

Quoc V. Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents.

volume 14, pages 1188–1196.

In ICML,

Shervin Malmasi and Marcos Zampieri. 2018. Challenges in Discriminating Profanity from Hate Speech. Journal

of Experimental & Theoretical Artiﬁcial Intelligence, 30:1–16.

Deepthi Mave, Suraj Maharjan, and Thamar Solorio. 2018. Language Identiﬁcation and Analysis of Code-
Switched Social Media Text. In Proceedings of the Third Workshop on Computational Approaches to Linguistic
Code-Switching, Melbourne, Australia, July. Association for Computational Linguistics.

Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive Language Detec-
tion in Online User Content. In Proceedings of the 25th International Conference on World Wide Web, pages
145–153. International World Wide Web Conferences Steering Committee.

James W. Pennebaker, Roger J. Booth, and Martha E. Francis. 2007. Liwc2007: Linguistic inquiry and word

count. Austin, Texas: liwc.net.

Niloofar Saﬁ Samghabadi, Suraj Maharjan, Alan Sprague, Raquel Diaz-Sprague, and Thamar Solorio. 2017.
Detecting nastiness in social media. In Proceedings of the First Workshop on Abusive Language Online, pages
63–72.

Maarten Sap, Gregory Park, Johannes Eichstaedt, Margaret Kern, David Stillwell, Michal Kosinski, Lyle Ungar,
and Hansen Andrew Schwartz. 2014. Developing age and gender predictive lexica over social media.
In
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages
1146–1151.

Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, and Christopher
Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings
of the 2013 conference on empirical methods in natural language processing, pages 1631–1642.

Cynthia Van Hee, Els Lefever, Ben Verhoeven, Julie Mennes, Bart Desmet, Guy De Pauw, Walter Daelemans, and
Veronique Hoste. 2015. Detection and ﬁne-grained classiﬁcation of cyberbullying events. In Proceedings of
the International Conference Recent Advances in Natural Language Processing, pages 672–680. INCOMA Ltd.
Shoumen, Bulgaria.

Zeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speech

detection on twitter. In Proceedings of the NAACL student research workshop, pages 88–93.

Zeerak Waseem. 2016. Are you a racist or am i seeing things? annotator inﬂuence on hate speech detection on

twitter. In Proceedings of the ﬁrst workshop on NLP and computational social science, pages 138–142.

Ellery Wulczyn, Nithum Thain, and Lucas Dixon. 2016. Ex machina: Personal attacks seen at scale. CoRR,

abs/1610.08914.

18