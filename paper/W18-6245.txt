Super Characters: A Conversion from Sentiment Classiﬁcation to Image

Classiﬁcation

Baohua Sun, Lin Yang, Patrick Dong, Wenhan Zhang, Jason Dong, Charles Young

Gyrfalcon Technology Inc.

1900 McCarthy Blvd. Milpitas, CA 95035

{baohua.sun,lin.yang,patrick.dong,wenhan.zhang}@gyrfalcontech.com

Abstract

We propose a method named Super Charac-
ters for sentiment classiﬁcation. This method
converts the sentiment classiﬁcation problem
into image classiﬁcation problem by project-
ing texts into images and then applying CNN
models for classiﬁcation. Text features are ex-
tracted automatically from the generated Su-
per Characters images, hence there is no need
of any explicit step of embedding the words
or characters into numerical vector represen-
tations. Experimental results on large so-
cial media corpus show that the Super Char-
acters method consistently outperforms other
methods for sentiment classiﬁcation and topic
classiﬁcation tasks on ten large social media
datasets of millions of contents in four dif-
ferent languages, including Chinese, Japanese,
Korean and English.

1

Introduction

is

an

classiﬁcation

(Hatzivassiloglou and McKeown,

Sentiment
interest-
ing topic that has been studied for many
1997;
years
Pang et al., 2002; Hong and Fang, 2015). Word
embedding is a widely used technique for sen-
timent classiﬁcation tasks, which embeds the
words into numerical vector representation before
the sentences are fed into models for classiﬁ-
cation
(Mikolov et al., 2013; Le and Mikolov,
2014; Pennington et al., 2014; Yu et al., 2017;
Cao et al., 2018). For sequential input, RNNs are
usually used and have very good results for text
classiﬁcation tasks (Lai et al., 2015; Tang et al.,
2015). Recently,
there are also works using
Convolutional Neural Networks (CNN) for text
classiﬁcation (Kim, 2014; Severyn and Moschitti,
2015; Vaswani et al., 2017; Bai et al., 2018).
CNN models have feature extraction and classiﬁ-
cation in a whole model, which require no need
of manually extracting features from images and

are proved to be successful in image classiﬁcation
tasks (LeCun et al., 1998; Krizhevsky et al., 2012;
Simonyan and Zisserman, 2014; Szegedy et al.,
2015; He et al., 2016a; Hu et al., 2017). There
are also works on character level text classiﬁ-
cations (Zhang et al., 2015; Zhang and LeCun,
2015; Kim et al., 2016). However, the input for
CNNs are still using the embedding vectors.

Zhang and LeCun (2017) had studied the differ-
ent ways of encoding Chinese, Japanese, Korean
(CJK) and English languages for text classiﬁca-
tion. These encoding mechanisms include One-
hot encoding, embedding and images of charac-
ter glyphs. Comparisons with linear models, fast-
Text (Joulin et al., 2016), and convolutional net-
works were provided. This work studied 473
models, using 14 large-scale text classiﬁcation
datasets in 4 languages including Chinese, En-
glish, Japanese and Korean.

Our work in this paper is based on the datasets
provided in (Zhang and LeCun, 2017) and down-
loadable at (Zhang, 2017). Different from existing
methods, our method has no explicit step of em-
bedding the text into numerical vector representa-
tions. Instead, we project the text into images and
then directly feed the images into CNN models to
classify the sentiments.

Before introducing the details of our solution,
let us ﬁrst look at how humans read text and do
sentiment analysis. Humans read sentences and
can immediately understand the sentiment of the
text; Humans can also read multiple lines at a ﬁrst
sight of paragraphs and get the general idea in-
stantly. This fast process consists of two steps.
First, the texts are perceived by human’s eyes as
a whole picture of text, while the details of this
picture are block-built by many characters. Sec-
ond, the image containing the texts are fed into the
brain. And then the human brain processes the im-
age of texts to output the sentiment classiﬁcation

Proceedingsofthe9thWorkshoponComputationalApproachestoSubjectivity,SentimentandSocialMediaAnalysis,pages309–315Brussels,Belgium,October31,2018.c(cid:13)2018AssociationforComputationalLinguisticshttps://doi.org/10.18653/v1/P17309inal text, so we convert the sentiment classiﬁca-
tion problem into image classiﬁcation problem.
The Super Characters images are similar to how
humans perceive text: as whole pictures contain-
ing text, whether printed on paper, projected on a
screen, or written by hand. After the texts are con-
verted to images, the performance of our text clas-
siﬁcation method is determined by the accuracy
of image classiﬁcation models. For large scale
image classiﬁcation tasks, CNN models such as
ResNet(He et al., 2016b) have outperformed hu-
mans in image classiﬁcation tasks as an end to
end solution. Thus, if we feed the Super Char-
acters images into CNN models such as ResNet,
we expect the text classiﬁcation using this 2-step
pipeline to have a high accuracy.

For detailed implementation of projecting text
into Super Characters image, there are a few set-
tings to conﬁgure, including the image size of
the whole Super Characters image; number of
characters per row/column; size of each charac-
ter; cut-length, which is the length of sentence to
cut/padding in order to ﬁt into the image; the fonts
used to project each character into an image, and
so on.

For Latin languages, we have the option of pro-
jecting text at the word level or at the alphabet
level, which will make differences at some cases.
For example, how to handle line-change if a word
is at the end of a row in the Super Characters im-
age and can’t ﬁt in the residual space in that row.
If we separate the words into separate alphabets,
we can ﬁt as many characters in the residual space
in that row and change to the next row for the rest
of the alphabets in that word. Or, if we keep the
word as a whole entity and avoid spliting, we have
to change to the next line for that word.

For example, here are the settings used in one
of our experiments in Section 3. We use a ﬁxed
image size of 224x224. And we also prefer inte-
ger numbers of characters in each row and hav-
ing same-sized characters. Thus, we prefer to use
8x8=64, or 28x28=784, or 32x32=1024 charac-
ters per image. And we set the cut/padding length
as the same. That also means, for 8x8 =64 set-
tings, we will have 8 characters per row, and we
have 8 rows in total. And each character is set
to be of size 224/8=28 square pixels. The Ar-
ial Unicode MS font is selected as font to draw
text onto image. For padding, we just draw noth-
ing on the image.

Figure 1: A Super Character example.

results. During the processing, the human brain
may recognize words and phrases as the interme-
diate results, in order to further analyze the senti-
ment. However, if we treat the human brain as a
black box system, its input is the image of texts re-
ceived by the eyes, and its output is the sentiment
classiﬁcation result.

In this paper, we propose a two-step method that
is similar to how humans do sentiment classiﬁca-
tion. We tested our method using the datasets pro-
vided by Zhang and LeCun (2017) on text classi-
ﬁcation tasks for social media contents from dif-
ferent countries in four languages, including En-
glish, Chinese, Japanese, and Korean. And com-
pared with other existing methods, including fast-
Text, EmbedNet, OnehotNet, and linear models.
The results show our method consistently outper-
forms other method on these datasets for sentiment
classiﬁcation tasks.

2 Super Characters Method

The Super Characters method converts the senti-
ment classiﬁcation problem into an image classiﬁ-
cation problem. It is deﬁned in two steps.

• First, the texts, e.g. sentences or paragraphs,
are “drawn” onto blank images, character by
character. For example, a generated Super
Characters image from Chinese text inputs
(including punctuation marks) is shown in
Figure 1. The Chinese text means “Super
characters are a method for NLP. It consists
of two steps: Frist, “draw” text onto images;
second, feed images into CNN”. Each gener-
ated Super Character image is attached with
the same sentiment labels as its original text.

• Second, feed the generated Super Characters

images with its labels to train CNN models.

The information embedded in the Super Char-
acters image is near identical to that in the orig-

310From the deﬁnition and description of Super
Character, we can see it has the following advan-
tages. 1. Its speed is not sensitive to the length of
the text input, so it can easily handle long and short
texts input. This advantage will be more obvious
when the input text is long, because super charac-
ter using CNN as model will be parallel processing
the input. And the processing time is invariant for
training and inference. 2. The feature engineering
work is no longer needed, which includes gener-
ating manmade features of each character related
to the culture behind each language. The Super
Characters image is treated as an input for CNN
models, and the feature extraction task are han-
dled automatically by CNN models. 3. Similar to
image classiﬁcation using CNN networks which
requires large amount of labeled image data, this
method of Super Characters for sentiment analysis
also requires large amount of labeled text data.

3 Experiments

3.1 Sentiment Classiﬁcation on Large

Datasets from Online Social Media

Ten of 14 datasets provided by (Zhang and LeCun,
2017) were tested on, a brief description of which
is provided:

Dianping: Chinese restaurant reviews were
evenly split as follows: 4 and 5 star reviews were
assigned to the positive class while 1-3 star re-
views were in the negative class.

JD Full: Chinese shopping reviews wer evenly
split for predicting full ﬁve stars. JD Binary Chi-
nese shopping reviews are evenly split into posi-
tive (4-and-5 star reviews) and negative (1-and-2
star reviews) sentiments, ignoring 3-star reviews.
Rakuten Full Japanese shopping reviews were
evenly split into predicting full ﬁve stars. Rakuten
Binary Japanese shopping reviews were evenly
split into positive (4-and-5 star reviews) and neg-
ative (1-and-2 star reviews) sentiments, removing
duplicates and ignoring 3-star reviews.

11st Full Korean shopping reviews were evenly
split into predicting full ﬁve stars. 11st Binary
Korean shopping reviews were evenly split into
identifying positive (4-and-5 star reviews) or neg-
ative (1-3 star reviews) sentiments.

Amazon Full: English shopping reviews were

evenly split into predicting full ﬁve stars.

Ifeng: First paragraphs of Chinese news arti-
cles from 2006-2016 were evenly split into 5 news
channels.

Chinanews: Chinese news articles from 2008-
2016 were evenly split into 7 news channels, re-
moving duplicates.

The statistics of these datasets are given in Table
1. We can see that eight out of the ten datasets has
more than millions of samples in training, and the
largest datasets have 4 millions of samples in train-
ing set. The test datasets are in the range of 1/4
to 1/16 of the training datasets respectively. The
languages used in these datasets include Chinese,
Japanese, Korean, and English. And the number
of classes ranges from 2, 5 to 7.

For each dataset, we generate Super Characters
images ﬁrst. We draw text with the Python Imag-
ing Library (PIL) (Lundh, 2009), and set all the
Super Character image sizes to 224x224 pixels,
the background set to black. For long text in-
puts such as paragraphs or articles, the length of
which is different so we set a cut-length from the
beginning of the news article. Although we may
forcely cut the input and ignore the rest, this cut-
length still works well since the ﬁrst few sentences
usually convey the general information about the
whole contents. For other text sources and tasks,
the starting point of the text for the cut-length may
change accordingly. For each experiment, we de-
termine the estimated cut-length by using a thresh-
old on sentence lengths. We have only tried one
cut-length of 14x14=196 for every experimental
data set. We set the size of each character as
224/14=16 square pixels.

And then, we feed the generated Super Charac-
ters to train CNN models. We use successful pre-
trained model SENet-154 (Hu et al., 2017) in the
ImageNet competition (Russakovsky et al., 2015),
which is the winner in ImageNet2017 competition
and achieves 81.32% Top1 accuracy and 95.53%
Top5 accuracy. We used pretrained model down-
loadable at (Hu, 2017) because it gave a good ini-
tialization for transfer learning tasks. We changed
the last layer to the corresponding number of cat-
egories in each data set to train on the Super Char-
acters images.

The sentiment classiﬁcation results on test
datasets are shown in Table 2. The accuracy
numbers for the models of OnehotNet, Em-
bedNet, Linear Model, and fastText are given
by (Zhang and LeCun, 2017).
in
(Zhang and LeCun, 2017), each model is tried
with different encoding methods. For example,
OnehotNet uses 4 different encodings, EmbedNet

Note that

311uses 10, Linear Models uses 11, and fastText uses
10. We only listed the best results for each ex-
isting method across different encodings. And
compare our results with the best of them. That
means we compare our results with the ﬁnetuned
best encoding of each existing model in 2. From
the results we can see that our Super Characters
method (short as S.C.) consistently outperforms
other methods, even with their best encodings.

3.2 Experiments on THUCTC corpus

THUCTC (Sun et al., 2016) was provided by the
Tsinghua University NLP lab in 2016.
It to-
tals 836075 documents after downloaded, cov-
ering 14 topics including 24373 Game, 37098
Finance, 63086 Politics, 50849 Society, 32586
Living, 20050 Real Estate, 7588 Lottery, 92632
Entertainment, 41936 Education, 13368 Fashion,
3578 Constellation, 162929 Technology, 131604
Sports and 154398 Stocks.
The majority of
the documents are long articles with hundreds
or sometimes thousands of characters in mul-
tiple sentences or paragraphs. We use a cut-
length of 28x28=784, each having an 8x8 pixel
size and utilize simhei font for Super Characters
on the THUCTC data.
In Table 3, we showed
our Super Character method using ResNet-50
(SC+ResNet50) attained an accuracy of 94.85%
and our Super Character method using ResNet-
152 (SC+ResNet152) attained an accuracy of
94.35%, while the result given by Sun et al. (2016)
achieved only an accuracy of 88.6% using LibLin-
ear. LibLinear (Fan et al., 2008) implements lin-
ear SVMs and logistic regression models trained
using a coordinate descent algorithm. Our models
reduce the error by 50.4% compared to this exist-
ing model.

3.3 Experiments on Fudan Corpus

The Fudan corpus (Li, 2011) contains 9804 doc-
uments of long sentences and paragraphs in 20
categories. We use the same split as (Xu et al.,
2016; Cao et al., 2018) in selecting the same 5 cat-
egories: 1218 environmental, 1022 agricultural,
1601 economical, 1025 political and 1254 sport
documents; 70% of the total data is used for train-
ing and the rest for testing.

• SC+ResNet-50: Using a ResNet-50 model
pretrained on the ImageNet dataset, we ﬁne-
tuned the transfer learning model on the new
generated super character dataset.

• SC+ResNet-50-THUCTC: Using a ResNet-
50 model pretrained on THUCTC data, we
ﬁne-tuned the trasfere learning model on the
new generated super character dataset.

We used a cut-length of 28x28=784 and words of
pixel size 8x8 with the simhei font for our Su-
per Characters in this experiment. In Table 4, the
ﬁrst 7 rows of model accuracies for different al-
gorithms are given by (Cao et al., 2018). We can
see that our SC+ResNet-50-THUCTC model at-
tained an accuracy of 97.8% while the best exist-
ing method achieved only a 95.3% accuracy. Our
SC+ResNet50-THUCTC model reduces the error
by 53.2% compared with the best existing model.
The SC+ResNet-50 model with 95.7% accuracy
also outperforms the best existing model. The pre-
trained model on THUCTC dataset gives 2.1% ac-
curacy improvement than SC+ResNet-50 model,
which means pretrained models on the same lan-
guage and a larger dataset will help for a better ini-
tialization and better model. For this data set, we
did not delete the non-Chinese characters as (Cao
et al., 2018) did. The result shows that our simple
projection from text to Super Characters image is
easy to implement and very robust. Users do not
even need to perform complicated preprocessing
techniques for the data.

3.4 Analysis on the Impact of the Cut-length
for Conﬁguring Super Characters Image

The cut-length determines how many characters in
each generated Super Characters image. So it will
impact if an input text needs clipping or padding,
in order to have the same pixel size of each char-
acter and same length for all the text samples in
the same dataset. The short cut-length may clip
long sentences and cause information loss, which
will decrease the sentiment classiﬁcation accuracy.
But increasing the cut-length of the text may pre-
vent inadvertently clipping long sentences but also
increases the number of blank spaces for short sen-
tences. Thus it may impact the model and the
sentiment analysis accuracy. The best setting for
cut-length should be based on the dataset statis-
tics. We have a study on different settings of cut-
length using ResNet-50 on the Fudan corpus, and
the results are given in Table 5. For this Fudan
data, the average sentence length is 530, and the
median sentence length is 509. It shows that the
setting of cut-length=784 is the best conﬁguration
for this dataset compared with other options. This

312Dataset
Dianping

JD full

JD binary

Rakuten full

Rakuten binary

11st full

11st binary
Amazon full

Ifeng

Chinanews

Short Name Language Classes

Train

Test

D.P.
JD.f
JD.b
RKT.f
RKT.b
11st.f
11st.b
AMZ.f
Ifeng
Cnews

Chinese
Chinese
Chinese
Japanese
Japanese
Korean
Korean
English
Chinese
Chinese

2
5
2
5
2
5
2
5
5
7

2,000,000
3,000,000
4,000,000
4,000,000
3,400,000
750,000
4,000,000
3,000,000
800,000
1,400,000

500,000
250,000
360,000
500,000
400,000
100,000
400,000
650,000
50,000
112,000

Table 1: Datasets statistics used in Table 2 and short names used for convenience.

Model

OnehotNet
EmbedNet

Linear
fastText

S.C.(ours)

D.P.
76.83
76.40
76.97
77.66
77.80

JD.f
51.90
51.71
51.82
52.01
54.10

JD.b RKT.f RKT.b
94.07
90.69
90.81
93.93
93.37
91.18
94.55
91.28
92.20
94.85

54.90
54.80
54.74
56.73
57.70

11st.f
67.57
67.71
56.58
61.42
68.70

11st.b AMZ.f
57.79
86.70
86.75
56.30
57.30
86.60
59.98
86.89
87.60
60.70

Ifeng Cnews
89.38
83.51
82.99
89.45
89.24
81.70
90.90
83.69
84.40
92.00

Table 2: Results of our Super Character
by (Zhang and LeCun, 2017).

(SC) method against other models on datasets provided

Model
LibLinear (Sun et al., 2016)
SC+ResNet-50 (ours)
SC+ResNet-152 (ours)

Accuracy
88.6%
94.85%
94.35%

Cut-length

Accuracy(%)

196
93.45

256
93.3

784
95.7

1024
89.35

Table 5: Cut-length Impact on Accuracy.

Table 3: Results of our Super Character (SC) method
against other models on THUCTC data set.

4 Conclusion and Future Work

Model
skip-gram (Mikolov et al., 2013)
cbow (Mikolov et al., 2013)
GloVe (Pennington et al., 2014)
CWE (Chen et al., 2015)
GWE (Su and Lee, 2017)
JWE (Yu et al., 2017)
cw2vec (Cao et al., 2018)
SC+ResNet-50-THUCTC (ours)
SC+ResNet-50 (ours)

Accuracy
93.4%
93.4%
94.2%
93.2%
94.3%
94.2%
95.3%
97.8%
95.7%

Table 4: Results of our Super Character (SC) method
against other models on the Fudan dataset.

indicates that setting the cut-length according to
the median or average sentence length could be a
good option.

In this paper, we proposed the Super Characters
method for sentiment classiﬁcation.
It converts
text into images and then applies CNN models to
classify the sentiment. The text features are au-
tomatically extracted by CNN models. We have
tested our method on social media text contents
from four different languages. The experimen-
tal results showed that our method consistently
outperforms other methods for Chinese, English,
Japanese, and Korean text contents for sentiment
classiﬁcation tasks. We also showed that pre-
trained Chinese text classiﬁcation models on large
datasets helps attain a higher accuracy for text
classiﬁcation on other Chinese datasets.

For future work, we can apply various prepro-
cessing techniques such as the elimination of com-
mon words and other methods to further increase
the accuracy of this method, and ﬁne-tune the cut
length to analyze its impact on different data sets.
And we also need to compare with other RNN
methods on the same datasets.

313References

Shaojie Bai, J Zico Kolter, and Vladlen Koltun.
2018. An empirical evaluation of generic convolu-
tional and recurrent networks for sequence model-
ing. arXiv preprint arXiv:1803.01271.

Shaosheng Cao, Wei Lu, Jun Zhou, and Xiaolong Li.
2018. cw2vec: Learning chinese word embeddings
with stroke n-gram information.

Heng Chen, Junying Liang, and Haitao Liu. 2015. How
does word length evolve in written chinese? PloS
one, 10(9):e0138567.

Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classiﬁcation. Journal of ma-
chine learning research, 9(Aug):1871–1874.

Vasileios Hatzivassiloglou and Kathleen R McKeown.
1997. Predicting the semantic orientation of adjec-
tives.
In Proceedings of the 35th annual meeting
of the association for computational linguistics and
eighth conference of the european chapter of the as-
sociation for computational linguistics, pages 174–
181. Association for Computational Linguistics.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016a. Deep residual learning for image recog-
nition.
In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 770–
778.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016b. Deep residual learning for image recog-
nition.
In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 770–
778.

James Hong and Michael Fang. 2015. Sentiment anal-
ysis with deeply learned distributed representations
of variable length texts. Technical report, Technical
report, Stanford University.

Jie Hu. 2017. Senet-154. Github and model download:

https://github.com/hujie-frank/SENet.

Jie Hu, Li Shen, and Gang Sun. 2017.
arXiv

networks.

and-excitation
arXiv:1709.01507, 7.

Squeeze-
preprint

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2016. Bag of tricks for efﬁcient text
classiﬁcation. arXiv preprint arXiv:1607.01759.

Yoon Kim. 2014.

works for sentence classiﬁcation.
arXiv:1408.5882.

Convolutional neural net-
arXiv preprint

Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der M Rush. 2016. Character-aware neural language
models. In AAAI, pages 2741–2749.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-
ton. 2012.
Imagenet classiﬁcation with deep con-
volutional neural networks. In Advances in neural
information processing systems, pages 1097–1105.

Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. 2015.
Recurrent convolutional neural networks for text
classiﬁcation.
In AAAI, volume 333, pages 2267–
2273.

Quoc Le and Tomas Mikolov. 2014. Distributed rep-
resentations of sentences and documents. In Inter-
national Conference on Machine Learning, pages
1188–1196.

Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick
Haffner. 1998. Gradient-based learning applied to
document recognition. Proceedings of the IEEE,
86(11):2278–2324.

Ronglu
text
Data
http://www.datatang.com/data/44139.

Li.
classiﬁcation.

Fudan

2011.

corpus

for
download:

Fredrik

Lundh.
library

2009.
(pil).

ing
http://www.pythonware.com/products/pil/.

Python

imag-
Webpage:

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity.
In Advances in neural information processing
systems, pages 3111–3119.

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classiﬁcation using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing-Volume 10, pages 79–86. As-
sociation for Computational Linguistics.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
Sanjeev Satheesh, Sean Ma, Zhiheng Huang, An-
drej Karpathy, Aditya Khosla, Michael Bernstein,
Alexander C. Berg, and Li Fei-Fei. 2015.
Ima-
geNet Large Scale Visual Recognition Challenge.
International Journal of Computer Vision (IJCV),
115(3):211–252.

Aliaksei Severyn and Alessandro Moschitti. 2015.
Twitter sentiment analysis with deep convolutional
neural networks. In Proceedings of the 38th Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 959–
962. ACM.

Karen Simonyan and Andrew Zisserman. 2014. Very
deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556.

Tzu-Ray Su and Hung-Yi Lee. 2017. Learning chi-
nese word representations from glyphs of characters.
arXiv preprint arXiv:1708.04755.

314Maosong

Sun,

Jingyang Li,

Zhipeng Guo,
and
Yu Zhao, Yabin Zheng, Xiance Si,
Zhiyuan Liu. 2016.
Thuctc: An efﬁcient chi-
nese text classiﬁer. Github and data download:
https://github.com/thunlp/THUCTC.

Christian Szegedy, Wei Liu, Yangqing Jia, Pierre
Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Ra-
binovich. 2015. Going deeper with convolutions. In
Proceedings of the IEEE conference on computer vi-
sion and pattern recognition, pages 1–9.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Docu-
ment modeling with gated recurrent neural network
for sentiment classiﬁcation.
In Proceedings of the
2015 conference on empirical methods in natural
language processing, pages 1422–1432.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, pages 6000–6010.

Jian Xu, Jiawei Liu, Liangang Zhang, Zhengyu Li, and
Huanhuan Chen. 2016. Improve chinese word em-
beddings by exploiting internal structure.
In Pro-
ceedings of the 2016 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
1041–1050.

Jinxing Yu, Xun Jian, Hao Xin, and Yangqiu Song.
2017.
Joint embeddings of chinese words, char-
acters, and ﬁne-grained subcharacter components.
In Proceedings of the 2017 Conference on Empiri-
cal Methods in Natural Language Processing, pages
286–291.

Xiang Zhang. 2017. Which encoding is the best
for text classiﬁcation in chinese, english, japanese
and korean?
Github and data download:
https://github.com/zhangxiangxiao/glyph.

Xiang Zhang and Yann LeCun. 2015. Text understand-
ing from scratch. arXiv preprint arXiv:1502.01710.

Xiang Zhang and Yann LeCun. 2017. Which en-
coding is the best for text classiﬁcation in chinese,
english,
arXiv preprint
arXiv:1708.02657.

japanese and korean?

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
siﬁcation.
In Advances in neural information pro-
cessing systems, pages 649–657.

315