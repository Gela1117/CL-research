Geocoding Without Geotags: A Text-based Approach for reddit

Keith Harrigian

Warner Media Applied Analytics

Boston, MA

keith.harrigian@appliedanalytics.net

Abstract

In this paper, we introduce the ﬁrst geolocation
inference approach for reddit, a social media
platform where user pseudonymity has thus far
made supervised demographic inference dif-
ﬁcult to implement and validate.
In particu-
lar, we design a text-based heuristic schema to
generate ground truth location labels for red-
dit users in the absence of explicitly geotagged
data. After evaluating the accuracy of our la-
beling procedure, we train and test several ge-
olocation inference models across our reddit
data set and three benchmark Twitter geoloca-
tion data sets. Ultimately, we show that ge-
olocation models trained and applied on the
same domain substantially outperform models
attempting to transfer training data across do-
mains, even more so on reddit where platform-
speciﬁc interest-group metadata can be used to
improve inferences.

1

Introduction

The rise of social media over the past decade has
brought with it the capability to positively inﬂu-
ence and deeply understand demographic groups
at a scale unachievable within a controlled lab
environment.
For example, despite only hav-
ing access to sparse demographic metadata, social
media researchers have successfully engineered
systems to promote targeted responses to pub-
lic health issues (Yamaguchi et al., 2014; Huang
et al., 2017) and to characterize complex human
behaviors (Mellon and Prosser, 2017).

However, recent studies have demonstrated that
social media data sets often contain strong pop-
ulation biases, especially those which are ﬁltered
down to users who have opted to share sensitive
attributes such as name, age, and location (Malik
et al., 2015; Sloan and Morgan, 2015; Lippincott
and Carrell, 2018). These existing biases are likely
to be compounded by new data privacy legislation

that will require more thorough informed consent
processes (Kho et al., 2009; European Commis-
sion, 2018).

While some social platforms have previously
approached the challenge of balancing data access
and privacy by offering users the ability to share
and explicitly control public access to sensitive at-
tributes, others have opted not to collect sensitive
attribute data altogether. The social news website
reddit is perhaps the largest platform in the lat-
ter group; as of January 2018, it was the 5th most
visited website in the United States and 6th most
visited website globally (Alexa, 2018). Unlike
real-name social media platforms such as Face-
book, reddit operates as a pseudonymous website,
with the only requirement for participation being
a screen name.

Fortunately, there has been signiﬁcant progress
made using statistical models to infer user demo-
graphics based on text and other features when
self-attribution data is sparse (Han et al., 2014;
Ajao et al., 2015). On reddit in particular, Harri-
gian et al. (2016) has used self-attributed “ﬂair”
as labels for training a text-based gender infer-
ence model. However, to the best of our knowl-
edge, user geolocation inference has not yet been
attempted on reddit, where a complete lack of
location-based features (e.g. geotags, proﬁles with
a location ﬁeld) has made it difﬁcult to train and
validate a supervised model.

The ability to geolocate users on reddit has
substantial implications for conversation mining
and high-level property modeling, especially since
pseudonymity tends to encourage disinhibition
(Gagnon, 2013). For instance, geolocation could
be used to segment users discussing a movie trailer
into US and international audiences to estimate a
ﬁlm’s global appeal or to inform advertising strat-
egy within different global markets. Alternatively,
user geolocation may be used in conjunction with

Proceedingsofthe2018EMNLPWorkshopW-NUT:The4thWorkshoponNoisyUser-generatedText,pages17–27Brussels,Belgium,Nov1,2018.c(cid:13)2018AssociationforComputationalLinguistics17sentiment analysis of political discussions to pre-
dict future voting outcomes.

Moving toward these goals, we introduce a text-
based heuristic schema to generate ground truth
location labels for reddit users in the absence of
explicitly geotagged data. After evaluating the ac-
curacy of our labeling procedure, we train and test
several geolocation inference models across our
reddit data set and three benchmark Twitter ge-
olocation data sets. Ultimately, we show that ge-
olocation models trained and applied on the same
domain substantially outperform models attempt-
ing to transfer training data across domains, even
more so on reddit where platform-speciﬁc interest-
group metadata can be used to improve inferences.

2

reddit: the front page of the internet

Founded originally as a social news platform in
2005, reddit has since become one of the most
visited websites in the world, offering an expan-
sive suite of features designed to “[bridge] com-
munities and individuals with ideas, the latest dig-
ital trends, and breaking news” (reddit, 2018). Al-
though the so-called front page of the internet still
boasts an impressive amount of link-sharing, red-
dit has gradually evolved into a self-referential
community where original thoughts and new con-
tent prevail (Singer et al., 2014).

reddit is structured much like a traditional on-
line forum, where over one-hundred thousand top-
ical categories known as subreddits separate user
communities and conversation. Subreddits may
cover topics as general as humor and movies (e.g.
r/funny, r/movies) or as speciﬁc as an unusual ﬁt-
ness goal (e.g. r/100pushups). Within each sub-
reddit, users can post thematically relevant sub-
missions in the form of an image, text blurb, or
external link. Users are then able to post com-
ments on the submission, responding to either the
content in the original submission or to comments
made by other users.

reddit users tend to feel protected by the site’s
pseudonymity and consequently eschew their of-
ﬂine persona in favor of a more genuine online
persona (Gagnon, 2013; Shelton et al., 2015).
Thus, there is much potential in reddit as a data
source for conversation mining. Unfortunately, the
same policies which promote this favorable be-
havior currently preclude the segmentation of con-
versation based on demographic dimensions and
serve as a fundamental motivation to our research.

3 Geocoding reddit Users

Previous research on geolocation inference for so-
cial media has primarily used three Twitter data
sets for model training and validation (Eisenstein
et al., 2010; Roller et al., 2012; Han et al., 2012).
Although Twitter’s topical diversity typically sup-
ports generalization to other platforms (Mejova
and Srinivasan, 2012), it has not been tested thor-
oughly in the geolocation context or on reddit at
all.

There is substantial reason to believe that geolo-
cation models trained on Twitter data will not per-
form optimally when applied to reddit. One of the
most glaring concerns is the variation in user de-
mographics between the platforms. Namely, Twit-
ter tends to skew female while reddit tends to skew
male (Barthel et al., 2016; Smith and Anderson,
2018). Coates and Pichler (2011) have shown that
language varies between genders, which suggests
that language-model priors may vary based on so-
cial platform.

Additionally,

reddit necessarily excludes

the lack of geolocation ground
several
truth for
promising inference models from being applied
to the platform.
For example, network-based
geolocation approaches exploit the empirical re-
lationship between physical user distance and
connectedness on a social graph to propagate
known user locations to unlabeled users (Back-
strom et al., 2010). Rahimi et al.
(2015) argue
that network-based approaches are generally su-
perior to content-based methods, especially when
the social graph is well-connected. However, these
models require within-domain grounding for the
propagation algorithms to be useful.

Finally, while the reddit platform lacks certain
features useful for geolocation on Twitter (e.g.
timezones, proﬁle location ﬁelds),
it possesses
its own unique assets which we hypothesize can
prove useful for user geolocation. In this paper,
we quantify the predictive value of subreddit meta-
data, leaving other features such as user ﬂair and
the platform’s hierarchical comment structure for
future research.

3.1 Labeling Procedure
Since reddit does not offer geotagging capabilities,
nor do reddit user proﬁles include location ﬁelds,
we design a free-text geocoding procedure to as-
sociate reddit users with a home location. While
we focus on reddit for this paper, we believe that

18CORPUS OF CONTEMPORARY ENGLISH (Davies,
2009) are removed from the gazetteer. After ap-
plying this ﬁlter, our gazetteer is left with 23,018
cities and their associated location hierarchies (i.e.
city, state, country).

To aid in the disambiguation of common lo-
cation names, we create a small dictionary of
57 frequently occurring abbreviations found dur-
ing a preliminary exploration of the data. This
dictionary includes abbreviations for each state
and territory of the United States, in addition to
the following: USA (United States), UK (United
Kingdom), BC (British Columbia), and OT (On-
tario). Abbreviations are only extracted if they di-
rectly follow an n-gram found within the location
gazetteer.

is

Each comment

tokenized into an or-
dered list using standard processing techniques—
contraction and case normalization, number and
hyperlink removal, and whitespace splitting. To
support identiﬁcation of multi-token locations, we
then chunk each list into all possible n-grams for
n ∈ [1, 4]. We remove any n-gram which does not
have an exact match to a location in the gazetteer
or the abbreviation dictionary. When two or more
of the matched n-grams occur in an order of a
known location hierarchy from GEONAMES, they
are concatenated together. Any remaining n-gram
which is a substring of a larger n-gram in the list
of matches is removed.

One issue with this approach is that cities under
the population threshold, or cities missing from
our gazetteer, are ignored entirely. However, we
note that users often reference their home loca-
tion in the form City, State, Country. To improve
our labeling procedure’s recall, we devise an addi-
tional rule that captures location mentions which
match this syntactic pattern and contain at least
one of our gazetteer or abbreviation dictionary en-
tries as a substring. The inclusion of this rule ex-
pands the set of users with estimated city-level lo-
cations from 25k to 38k.

Geocoding. To associate each n-gram with a
coordinate position, we employ Google’s Geocod-
ing API, which ingests a string and returns the
most probable coordinate pair and nominal loca-
tion hierarchy information. To help disambiguate
common location names, we manually map re-
gion biases to a subset of location-related subred-
dits that house the seed submissions. We feed
these region biases into the Geocoding API as a

Figure 1: Comments from one of the seed submissions.
Replies (gray background) are ﬁltered out because they often
contain location names not representative of user location.
the following labeling method should generalize
to other pseudonymous platforms that have a ques-
tion and answer-based submission structure.

Data. We begin by querying the reddit API
for submissions with a title similar to “Where are
you from?”, “Where do you live?”, or “Where
are you living?” This query yields 3,600 English-
language submissions, from which we manually
curate a subset of 1,200 seed submissions where
we expect users to self-identify their home loca-
tion. Examples of submissions within the ﬁnal set
include “Where do you support Liverpool from?”
and “How much is your rent, and where do you
live?” Examples of submissions in the original
query which were excluded from the ﬁnal set in-
clude “Where are you banned from?” and “With-
out naming the location, where are you from?”

We then query comment data from the 1,200
seed submissions using the Python Reddit API
Wrapper (PRAW)1. We ﬁlter out comments which
mention “move,” “moving,” “born,” or “raised”
to ensure only current home locations are iden-
tiﬁed. We also remove comment replies, ﬁnd-
ing that they often include location mentions from
a perspective of discussion as opposed to self-
identiﬁcation. Representative comments from one
of the seed submissions2 are displayed in Figure
1. Ultimately, we keep 96,071 comments from
89,697 unique users.

Entity Extraction. We employ a string match-
ing approach to identify locations mentioned
within the comment text. As a gazetteer, we use
a subset of the GEONAMES data set (Wick and
Vatant, 2012) with city populations greater than
15,000. To reduce the false positive rate of loca-
tion recognition, 90 location names found within
the 5,000 most common English words from the

1https://praw.readthedocs.io/en/latest/
2www.reddit.com/r/LiverpoolFC/comments/3wmjd4/

19[-] snappyNZ1 point 2 years agoBorn in Wigan. Live in New Zealand.permalink     embed     save     give gold[-] aznasazin115 points 2 years agoKansas City, Missouri, USA reporting in.permalink     embed     save     give gold[-] ziggy_zaggy3 points 2 years agoGlad you specified that you live on the Missouri side :)permalink     embed     save     give gold[-] yassjr2 points 2 years agoAm I the only one from Paris?permalink     embed     save     give gold[-] biosync1 point 2 years agoI went to a really nice LFC bar in Paris; I just can’t remember what it was called. But judging by the crowd there, you certainly aren’t the only one!permalink     embed     save     give goldCountry

Alexa Trafﬁc

United States

United Kingdom

Canada
Australia
Germany

58.7%
7.4%
6.0%
3.1%
2.1%

Labeled Users
60.1% (n=39,236)
5.4% (n=3,544)
9.4% (n=6,163)
3.5% (n=2,344)
1.7% (n=1,097)

Figure 2 & Table 1: The ﬁgure (left) shows the geographic distribution of labeled users. Users outside the Americas are
generally more likely to self-identify using a state-level resolution and above. The table (right) compares relative reddit trafﬁc
estimated using the proprietary Alexa (2018) panel to the distribution within our labeled data set.

query parameter for comments which were made
in any of the mapped subreddits. Thus, a com-
ment that mentions Scarborough in r/ontario will
be properly mapped to Canada, while a comment
that mentions Scarborough in r/CasualUK, will be
mapped to England.

In the ﬁnal stage of our procedure, we aggre-
gate location extractions across each user, taking
the maximum overlap within their identiﬁed lo-
cation hierarchies as the ground truth. For each
location above a city-level resolution, we use the
geodesic median (Vardi and Zhang, 2000) of la-
beled users at the given resolution and below as
the true coordinate pair.

3.2 Geographic Representation
Ultimately, we associate 65,245 users with geolo-
cation labels at varying maximum resolutions—
38,773 at a city level; 1,541 at a county level;
13,774 at a state level; and 11,157 at a country
level. The label distribution and resolution break-
down over continents can be seen in Figure 2.

While the underlying geographic distribution of
reddit users is not publicly available, Alexa (2018)
publishes an estimate of country-level activity for
the top-5 sources of reddit trafﬁc using a propri-
etary data panel. We ﬁnd that the same countries
make up the top-5 most represented nations in our
labeled data set, albeit having slightly different
proportional breakdowns (see Table 1). In particu-
lar, we note that our data set slightly over-indexes
on North American reddit users and suffers from a
low sample size for most countries outside of the
top-5.

3.3 Label Accuracy
To estimate precision of our labeling procedure
across the larger data set, we randomly sample
500 of the labeled users and the comment from

which their labeled location was extracted. For
each of the 500 comments, we hand label whether
the user’s home location was properly extracted
and, if correct, whether the location was extracted
at the appropriate resolution.

Formally, we score any extracted location
which falls within the true location hierarchy as
a correct label. For example, if the true location
is Boston, Massachusetts, but our procedure ex-
tracts Massachusetts (the state), we score the label
as correct, but at an incorrect resolution. We ﬁnd
that our labeling procedure correctly extracted and
geocoded 96.6% of the location names from the
raw comments. Of these correct labels, 92.55%
were labeled at the correct resolution.

Of the false positives in our random sample, 8
were due to disambiguation errors on part of the
Google Geocoding API, 7 were due to users ref-
erencing locations that were not their actual home
location, and 2 were due to usage of a common
word not ﬁltered out using the CORPUS OF CON-
TEMPORARY ENGLISH. Future work will look
into ways to effectively leverage more granular
subreddit-location mappings during the geocoding
procedure to aid in disambiguation. This explo-
ration may prove most helpful for ambiguous lo-
cations which are housed within the same national
region (e.g. Kansas City, MO and Kansas City,
KS).

For labels extracted within the appropriate hi-
erarchy, but at the incorrect resolution, there were
two main sources of error. First, over half of the
incorrect resolution labels were due to our system
(as designed) aggregating multiple location men-
tions within a comment up to the maximum over-
lap present. Second, several of the true cities did
not exist within the gazetteer and were not cap-
tured by our syntactic rule. More extensive named

20010203040# Users (thousands)AfricaOceaniaAsiaEuropeAmericasCityCountyStateCountryentity resolution systems may be useful in address-
ing the issue of missing gazetteer entries. How-
ever, correctly handling multiple location names
and location names not representative of a user’s
home location will likely require a more robust
natural language understanding system.

4 Geolocation Inference

In the remainder of the paper, we evaluate whether
our “imperfect” geolocation labels are still useful
in the context of a common task—user geoloca-
tion inference. We begin this analysis with a series
of experiments and qualitative diagnostics to un-
derstand geolocation inference performance when
training and applying models within the reddit do-
main. To quantify the effect of domain transfer,
we conclude with a comprehensive comparison
of inference performance across three benchmark
Twitter data sets and our new reddit data set.

4.1 Related Work
Accounting for variations in feature selection and
model architecture, existing geolocation inference
approaches broadly fall into the following three
categories (and their hybridizations): network-
based, content-based, and metadata-based. We re-
fer the reader to Han et al. (2014) and Ajao et al.
(2015) for a comprehensive overview of the liter-
ature, but will highlight research pertinent to this
particular study below. We ignore network-based
models because they are not relevant to our chosen
inference architecture.

Content-based. Content-based approaches, in
which geographically predictive features are ex-
tracted from user-generated multimedia and mod-
eled thereafter, remain some of the most fun-
damental to user geolocation on social media.
Drawing upon well-documented phenomena re-
garding lexicon usage and its geographical varia-
tion (Trudgill, 1974; Vaux and Golder, 2003), text-
driven models are particularly suited for applica-
tion on reddit, where written comments are the
lowest level of user behavior data accessible via
the platform’s public API.

One of the earliest contributors to user geolo-
cation inference for social media, Cheng et al.
(2010) introduced a generative model that operates
on word usage alone to infer a user’s home loca-
tion, achieving an average prediction error of 535
miles for US Twitter users. Chang et al. (2012)
extended this work by replacing frequency-based

word likelihoods with smoothed estimations using
Gaussian Mixture Models (GMM). We use this ap-
proach within our evaluation due to its ease of im-
plementation and interpretability. However, others
have substantially improved inference accuracy
using more ﬂexible modeling architectures such as
spatial topic models (Eisenstein et al., 2010; Hu
and Ester, 2013), stacked denoising autoencoders
(Liu and Inkpen, 2015), sparse coding and dictio-
nary learning (Cha et al., 2015), and most recently,
neural networks (Rahimi et al., 2017).

Metadata-based. We deﬁne metadata as all
user behavior not explicitly expressed in multi-
media, such as text or image posts, nor directly
encoded as a social network connection. While
metadata has generally been used to improve per-
formance of content- and network-based meth-
ods, there exist some cases where metadata-based
models outperform competing approaches out-
right (Han et al., 2014; Dredze et al., 2016). With
reddit only recently introducing user proﬁles to the
platform and their adoption by the larger commu-
nity still an open question (Shelton et al., 2015),
we focus primarily on comment metadata.

First, we suspect that the subreddits a user posts
in, which often cover geographically localized
topics such as sports and news, will be predic-
tive of user location. While subreddits are spe-
ciﬁc to the reddit platform, they theoretically align
with group membership, which has been shown to
correlate with and predict user location in other
domains (Zheleva and Getoor, 2009; Chen et al.,
2013).

interest

Of additional

is temporal metadata,
which can capture longitudinal variations in cycli-
cal user activity patterns (Gao et al., 2013) or iden-
tify geographically-centered and time-dependent
events (Yamaguchi et al., 2014).
In particular,
Dredze et al.
(2017) ﬁnd
self-identiﬁed timezone information to be a useful
geolocation predictor. Unfortunately, this explic-
itly encoded geographic indicator is absent from
reddit and thus motivates our work to transform
and model raw timestamp data in Section 4.2.

(2016) and Do et al.

4.2 Location Estimation Model

Each user is represented by a concatenation of
three feature vectors: word usage (cid:126)w, subreddit
submissions (cid:126)s, and posting frequency (cid:126)τ. (cid:126)w is con-
structed by concatenating all comment text for a
user, tokenizing into uni-grams (using the same

21process in 3.1), and counting token frequencies.
(cid:126)s is simply the frequency distribution of subred-
dits that a user has posted in across their comment
history.

We represent the temporal posting habits of a
user by (cid:126)τ, a 24-dimensional vector where each
index contains the comment counts for one hour
of the day.
reddit comment timestamps are re-
ported in Coordinated Universal Time (UTC) and
can therefore be interpreted uniformly across users
when constructing (cid:126)τ. Moving forward, we let (cid:126)u
represent the concatenation of (cid:126)w and (cid:126)s, allowing
either modality to be turned off within the model.
However, we keep (cid:126)τ separate for notational clarity.
Model Architecture. As mentioned brieﬂy
above, we use the generative model introduced by
Cheng et al. (2010) as the basis for our work, mod-
ifying it to enable ingestion of temporal metadata.
Formally, given a user with feature set (cid:126)u (each u
having an occurrence count (cid:107)u(cid:107)) and posting fre-
quency (cid:126)τ, we estimate the probability of the user
being located at geographic coordinate pair c us-
ing the following model:
P (c|(cid:126)u, (cid:126)τ ) ∝ P (c|(cid:126)τ )

(cid:107)u(cid:107)P (c|u)P (u).

(cid:88)

(1)

u∈(cid:126)u

To make a singular location prediction, we take the
argmax of P (c|(cid:126)u, (cid:126)τ ) over an arbitrarily discrete
set of coordinate pairs C.

Probability Density Estimation. As a base-
line, Cheng et al. (2010) use the count-based fre-
quency of features over cities in their training data
to estimate P (c|u). They recognize as a shortcom-
ing to this approach the issue of feature sparsity—
features with a low frequency or selective location
presence contribute a probability close to zero for
several candidate locations.

Drawing upon the relationship of geographic
query dispersion quantiﬁed by Backstrom (2008),
Chang et al. (2012) and Priedhorsky et al. (2014)
use a bivariate Gaussian Mixture Model (GMM)
to estimate P (c|u) and demonstrate a signiﬁ-
cant performance improvement over the Cheng et
al.
(2010) baseline approach. However, the au-
thors highlight as a potential caveat to their work
the sensitivity of performance to GMM hyper-
parameters, namely the number of mixture com-
ponents.
To mitigate this issue, we use a Dirichlet Pro-
cess Mixture Model (DPMM) to estimate P (c|u).
Generally, DPMM is able to better describe mix-
tures with a varying number of components by

Figure 3: The relative posting frequencies within each lon-
gitude bin (cid:96) ∈ L. Users east of 3° are more likely to post
between the 6th and 12th hours (UTC) of the day.
constructing an inﬁnite mixture with some com-
ponents damped to near-zero amplitude; addition-
ally, learned DPMM parameters remain relatively
stable regardless of hyper-parameter choice (At-
tias, 2000; Blei et al., 2006).

We perform a series of experiments to compare
performance between GMM and DPMM. Hold-
ing constant the hyper-parameter for number of
mixture components3, we ﬁnd DPMM reduces er-
ror relative to GMM on a ﬁxed test set by 5% to
32% depending on the type of covariance matrix
used (i.e. diagonal, spherical). Ultimately, we use
DPMM with a diagonal covariance matrix and 5
components to optimize inference performance.

Temporal Variation. A signiﬁcant change to
the Chang et al. (2010) model is the addition of a
temporal adjustment term P (c|(cid:126)τ ), designed to re-
weight the word and subreddit posterior according
to how well a user’s posting frequency (cid:126)τ aligns
with the posting frequency distribution for users at
coordinate pair c.

To make this estimate, we begin by discretiz-
ing the longitudes of users within our training data
into a set of percentile-based bins L. Then, we ﬁt
a Logistic Regression model to map each user’s
posting frequency vector (cid:126)τ to their associated lon-
gitude bin (cid:96) ∈ L, using cross-validation to se-
lect hyper-parameters (e.g. L2-regularization) that
maximize classiﬁcation accuracy. Additionally,
we use 5-fold cross-validation to select the number
of longitude bins (cid:107)L(cid:107) that minimizes downstream
inference error.
To use the trained temporal feature model
within our estimator, we ﬁrst estimate P ((cid:96)|(cid:126)τ ) for
each (cid:96) ∈ L. Then we assign each c ∈ C to its
appropriate longitude bin (cid:96) and map the predicted

3For DPMM, we use a truncated distribution with a max-
imum number of mixture components equal to the chosen
number of mixture components for GMM.

22061218Hour of Day (UTC)-180-118-96-88-81-75-319180Longitude BinsPosting Frequency (% of total)probability distribution across C. We visualize
the temporal variation across longitude bins in our
reddit data set within Figure 3.

Paralleling shifts in timezone, we note that peak
user activity occurs earlier (within the UTC nor-
malization) for users in eastern longitude bins than
users in western longitude bins. Additionally,
users in the eastern hemisphere are signiﬁcantly
more likely to post between the 6th and 12th hours
(UTC) of the day.

5 Within-Domain Evaluation

We ﬁrst examine geolocation inference perfor-
mance within the domain of our reddit data set.
We query all comment data for users within our
set of geolocation labels using a publicly available
corpus of reddit comments made between Decem-
ber 2005 and May 2018 (Baumgartner, 2018). For
each user, we keep a maximum of 1000 comments
posted up to one-month after they commented in
the set of submissions used for labeling; this date-
based ﬁltering is done to mitigate the effect of
users moving after posting in the seed set of sub-
missions. Additionally, to ensure our model is not
overtly biased by toponym mentions, we remove
comments that were used as a part of the labeling
procedure.

reddit data set

We separate our

into two
versions—US (restricted to users from the con-
tiguous United States) and GLOBAL (no location
restrictions). We require that users within the
United States have a minimum city-level resolu-
tion, while users outside the United States have
been labeled with at least a state-level resolution.
We quantify model performance using three
standard metrics from the user geolocation liter-
ature: Average Error Distance (AED), Median Er-
ror Distance (MED), and Accuracy at 100 miles
(Acc@100). AED and MED are simply the arith-
metic mean and median of error between pre-
dicted coordinates and true coordinates, respec-
tively. Acc@100 is the percentage of users whose
predicted location is less than 100 miles from their
true location.

5.1 Results
Feature Selection. Dimensionality reduction
methods have been used to improve geolocation
inference performance while reducing computa-
tional cost (Cheng et al., 2010; Chang et al., 2012;
Han et al., 2012). Of existing approaches, the

Massachusetts, USA

Ohio, USA

Germany

Belgium

Top Words
allston, mbta, waltham,
saugus, brookline, masshole,
somerville, alewife, braintree
ohioan, westerville, cincinnatis,
jenis, clevelander, graeters,
cuyahoga, bgsu, cbus
zeigen, dennoch, wenige,
zeigt, solltest, deutlich,
wollt, kriegt, stck
telenet, walloon, vlaams,
jupiler, leuven, vlaanderen,
ghent, molenbeek, azerty

Top Subreddits

r/PokemonGoBoston, r/WorcesterMA,
r/massachusetts, r/bostonhousing

r/uCinci, r/ColumbusSocial,
r/columbusclassiﬁeds, r/Columbus

r/FragReddit, r/de IAmA,
r/rocketbeans, r/kreiswichs

r/belgium, r/brussels,
r/Vivillon, r/ecr eu

Table 2: Examples of the top features ranked using non-
localness. Toponyms and non-English tokens are often the
most indicative of location.
non-localness (N L) criteria introduced by Chang
et al. (2012) stands out as being both effective at
improving inference performance and useful as a
means to understand feature alignment. Formally,
N L is computed according to Equation 2, where
simSKL is the Symmetric Kullback-Liebler diver-
gence, S is a set of “stopword-like” features which
are expected to occur uniformly across locations,
and f is a generic feature in a larger feature set F .

N L(f ) =

simSKL(f, s)

(cid:80)

count(s)
s(cid:48)S(cid:48) count(s(cid:48))

(2)

(cid:88)

sS

We apply non-localness to (cid:126)w and (cid:126)s separately to
control how many features from each modality are
kept. For (cid:126)w, we let S be a set of 130 English stop-
words taken from the Natural Language Toolkit4;
to apply non-localness to subreddit features (cid:126)s, we
assume the 30 most active subreddits5 in our data
set make up S.

We evaluate N L over a discretized set of “State,
Country, Continent” combinations, rolling up lo-
cations with less than 50 users in the training data
to the next level of the location hierarchy. While
Chang et al. (2012) ﬁnds modest performance im-
provements using GMM to estimate feature fre-
quencies in the simSKL computation, we limit
ourselves to frequency-based feature likelihoods
to reduce computational expense.

In alignment with previous research, we ﬁnd
that N L produces qualitatively intuitive feature
rankings (see Table 2). Furthermore, dimension-
ality reduction of both words and subreddits using
N L signiﬁcantly reduces error compared to us-
ing the full feature set for US and GLOBAL. The
most signiﬁcant source of error for large feature
set sizes is noise added by “stopword-like” fea-
tures, which generally have a large (cid:107)u(cid:107) and effec-
tively negate the contribution of more geographi-

4http://www.nltk.org/
5Examples include r/Politics, r/AskReddit, and r/funny.

23of performance achieved within-domain to perfor-
mance achieved using models trained outside the
reddit domain. To do so, we use three benchmark
Twitter geolocation data sets—GEOTEXT (Eisen-
stein et al., 2010), TWITTER-US (Roller et al.,
2012), and TWITTER-WORLD (Han et al., 2012).
All three data sets were created by monitor-
ing Twitter’s streaming API over a discrete period
of time and caching comments for users who en-
abled geotagging features on the Twitter platform.
Due to Twitter’s terms of service, TWITTER-US
and TWITTER-WORLD must be compiled from
scratch using tweet IDs. Unfortunately, several
users within the original data sets have since either
deleted their accounts or restricted access to their
tweet history. As such, we were not able to per-
fectly recreate the original data sets. Ultimately,
our compilation of TWITTER-US contains 246k
out of the original 440k users, while TWITTER-
WORLD contains 888k out of the original 1.4M
users.

To understand the impact that domain transfer
has on geolocation inference performance, we set
up a systematic model comparison. First, we run
5-fold cross-validation within each of the Twitter
data sets using both word and timestamp features.
For the TWITTER-WORLD data set, we run two in-
dependent cross-validation procedures, evaluating
on the subset of US users alone and also on the en-
tire data set. Then, we train models for each of our
data sets using all available data and apply them
to the data sets not used for training. When evalu-
ating performance on a data set that only contains
US users, we train the corresponding model only
using US user data. All model hyper-parameters
(e.g. feature set sizes, regularization, etc.) were
chosen to optimize within-data-set performance.

6.1 Results

Experimental results are summarized in Table 3
and explored in greater detail below. The base-
line model assigns each user in the test set to the
maximum a posteriori (MAP) of a DPMM ﬁt to
the locations of all users in the training data. As
an additional reference point, we also include re-
sults from two recent approaches for the Twitter
data sets.

Transfer Performance.

In validation of our
labeling procedure, we note that models trained
on reddit data outperform within-domain baselines
for nearly all Twitter data sets. The only exception

Figure 4: The effect of temporal and subreddit metadata on
inference error. Temporal features do not affect model perfor-
mance on the US data set, but reduce error for the GLOBAL
data set; subreddit metadata improves performance on both
data sets.
cally predictive features.

Final feature set sizes are selected to minimize
AED — 40k words and 650 subreddits for US
(originally 118k words and 13k subreddits); 50k
words and 1.1k subreddits for GLOBAL (originally
120k words and 14k subreddits).

Feature Modalities. Below, we discuss how
the addition of the temporal adjustment factor
P (c|(cid:126)τ ) and subreddit features (cid:126)s affect model per-
formance. We carry out 5-fold cross validation,
with splits varied for US and GLOBAL, but held
constant within each data set,
to evaluate the
modality effects fairly.

As seen in Figure 4, the temporal adjustment
factor does not signiﬁcantly affect model perfor-
mance on the US data set, but reduces error when
included within the GLOBAL data set, where un-
derlying differences in (cid:126)τ are magniﬁed across con-
tinents. The most signiﬁcant reduction in error oc-
curs for European users, whose posting levels tend
to peak around the 10th hour (UTC) of the day.

While subreddit features reduce error within
both data sets when combined with word features,
they do not outperform word features on their
own. Rather, models trained using word features
alone achieve an AED which is 17% and 4% lower
for US and GLOBAL, respectively, than models
trained using subreddit features alone. This im-
plies that text-based models trained on other do-
mains may perform adequately on reddit, but will
likely suffer from the inability to take advantage
of subreddit metadata in a supervised manner.

6 Cross-Domain Evaluation

While within-domain experiments suggest
that
reddit-speciﬁc metadata offers substantial predic-
tive value, we wish to compare the highest degree

24200300400**200400600800***w++sUSGlobalMedian ErrorDistance (miles)Test

Train
Rahimi et al. (2017) (Text-based)
Do et al. (2017) (Text + Network)
Baseline (MAP Estimate)
REDDIT-US

(cid:126)w

REDDIT-GLOBAL

GEOTEXT

TWITTER-US

(cid:126)w + (cid:126)τ

(cid:126)w + (cid:126)τ + (cid:126)s

(cid:126)w

(cid:126)w + (cid:126)τ

(cid:126)w + (cid:126)τ + (cid:126)s

(cid:126)w

(cid:126)w + (cid:126)τ

(cid:126)w

(cid:126)w + (cid:126)τ

TWITTER-WORLD (US)

(cid:126)w

TWITTER-WORLD (All)

(cid:126)w

(cid:126)w + (cid:126)τ

(cid:126)w + (cid:126)τ

-
-
894
602
580
502
-
-
-

-
-
750
295
278
157
-
-
-

1210
1209
670
635
963
923
-
-

1019
1019
326
294
729
717
-
-

0.05
0.36
0.36
0.45

-
-
-

0.07
0.07
0.36
0.36
0.20
0.18

-
-

REDDIT-US

REDDIT-GLOBAL

TWITTER-WORLD (All)
Acc@100 AED MED Acc@100 AED MED Acc@100 AED MED Acc@100 AED MED Acc@100 AED MED Acc@100 AED MED
415
118
2463

TWITTER-WORLD (US)

1456
1044
3893

0.34
0.53
0.04

TWITTER-US

GEOTEXT

2207

1221

0.03

-
-

-
-

-
-

-
-

-
-

-
-

-
-

0.38
0.62
0.33
0.21
0.21

-
-
-
-

0.38
0.38
0.34
0.33
0.12
0.13

-
-

844
532
679
695
695
-
-
-
-
591
575
631
632
635
628
-
-

389
32
424
479
480
-
-
-
-
280
271
301
304
313
311
-
-

0.54
0.66
0.07
0.31
0.31

-
-
-
-

0.12
0.12
0.40
0.40
0.23
0.22

-
-

554
433
1659
609
603
-
-
-
-
982
982
547
536
772
768
-
-

120
45
1869
362
358
-
-
-
-
755
755
225
220
564
563
-
-

-
-
-

0.24
0.25
0.36

-
-
-
-
-
-

-
-
-

1751
1475
1259

-
-
-
-
-
-

-
-
-
590
457
266
-
-
-
-
-
-

0.15
0.16

2737
1793

1829
817

0.07
0.14
0.13

-
-
-
-

0.13
0.13
0.24
0.24
0.22
0.22

-
-

1651
748
747
-
-
-
-
992
992
790
789
795
791
-
-

1869
605
592
-
-
-
-
755
755
583
582
589
584
-
-

-
-
-

-
-
-

-
-
-

0.09
0.09

2717
2708

1329
1329

-
-
-
-
-
-
-

-
-
-
-
-
-
-

-
-
-
-
-
-
-

0.16
0.16

2716
2610

1665
1405

Table 3: Summary statistics for the domain-transfer experiment. The best results from our cross-validation procedure are
bolded. Models trained on reddit data (third and fourth rows) outperform the baseline for Twitter data sets in nearly all cases
(see text for caveats). Within the reddit data sets (ﬁrst and second columns), models with access to platform-speciﬁc metadata
outperform all models transferred from the Twitter domain.

occurs for GEOTEXT, where less than 10% of red-
dit features are also present. Due to the lack of
feature overlap, many of the GEOTEXT, users are
assigned to the MAP of users in the reddit data
by default. While TWITTER-US and TWITTER-
WORLD also have low feature overlap with GEO-
TEXT, their MAP estimates are much closer to ma-
jority of users in GEOTEXT.

We also note that there is a signiﬁcant loss in-
curred by most domain transfers. This loss is mag-
niﬁed for models trained on Twitter data and ap-
plied to reddit data, since Twitter models critically
lack access to subreddit metadata during training.
Temporal Features. The effect of our tempo-
ral adjustment term P (c|(cid:126)τ ) varies between each
data set. Speciﬁcally, the temporal features sig-
niﬁcantly improve within-domain performance for
both of our “international” data sets (TWITTER-
WORLD and REDDIT-GLOBAL), but offer no sig-
niﬁcant gain for data sets with US users only. Ad-
ditionally, we note that temporal features signif-
icantly reduce the loss in performance incurred
by domain transfer going from TWITTER-US
to REDDIT-US and from TWITTER-WORLD to
REDDIT-GLOBAL.

Location Estimator. Based on within-domain
performance for each of the Twitter data sets, we
recognize that our inference modeling approach
is below state of the art. For example, in the
space of text-only models, Rahimi et al.
(2017)
have achieved an Acc@100 of 0.34 on TWITTER-
WORLD using a multilayer perceptron and k-d tree
discretization over the label set.

The performance gap between our model and
state of the art approaches widens when consid-

ering multi-modal architectures. Notably, Do et
(2017) have achieved an Acc@100 of 0.62
al.
on GEOTEXT using multi-view neural networks
that simultaneously leverage text, proﬁle meta-
data, and social network connections. Thus, we
hypothesize that implementing models which are
more complex than our current architecture will
magnify the performance gain achieved by includ-
ing subreddit metadata alongside text-based fea-
tures.

7 Discussion and Future Work

In this paper, we introduced the ﬁrst user geocod-
ing and geolocation inference approach for red-
dit, demonstrating that pseudonymity is not an ex-
haustive barrier to supervised learning.
In addi-
tion to designing a labeling procedure capable of
geocoding user home locations in noisy comment
data with a precision of 0.966, we demonstrated
that reddit-speciﬁc metadata can be used to signif-
icantly improve inferences. Ultimately, we trained
a multi-modal inference model which achieves a
median error of 157 miles and 266 miles for US
and international reddit users, respectively.

Moving forward, we plan to thoroughly exam-
ine underlying biases that may exist within the
users identiﬁed by our labeling procedure. Speciﬁ-
cally, we will build on the work of Sloan and Mor-
gan (2015) and Lippincott and Carrell (2018) to
understand differences in user activity, interests,
and conversation topicality, relative to the general
reddit population. We also plan to explore differ-
ent seed-submission sampling methods to improve
the representation of non-North American users.

25References
Oluwaseun Ajao, Jun Hong, and Weiru Liu. 2015. A
survey of location inference techniques on twitter.
Journal of Information Science, 41(6):855–864.

Amazon Alexa. 2018. Amazon top 500 global sites.

Hagai Attias. 2000. A variational baysian framework
for graphical models. In Advances in neural infor-
mation processing systems, pages 209–215.

Lars Backstrom, Jon Kleinberg, Ravi Kumar, and Jas-
mine Novak. 2008. Spatial variation in search en-
In Proceedings of the 17th interna-
gine queries.
tional conference on World Wide Web, pages 357–
366. ACM.

Lars Backstrom, Eric Sun, and Cameron Marlow. 2010.
Find me if you can: improving geographical predic-
tion with social and spatial proximity. In Proceed-
ings of the 19th international conference on World
wide web, pages 61–70. ACM.

Michael Barthel, Galen Stocking, Jesse Holcomb, and
Amy Mitchell. 2016. Seven-in-ten reddit users get
news on the site. [Online; posted 26-May-2016].

Jason Baumgartner. 2018. pushshift.io.

David M Blei, Michael I Jordan, et al. 2006. Vari-
inference for dirichlet process mixtures.

ational
Bayesian analysis, 1(1):121–143.

Miriam Cha, Youngjune Gwon, and HT Kung. 2015.
Twitter geolocation and regional classiﬁcation via
sparse coding. In ICWSM, pages 582–585.

Hau-wen Chang, Dongwon Lee, Mohammed Eltaher,
and Jeongkyu Lee. 2012. @ phillies tweeting from
philly? predicting twitter user locations with spatial
In Proceedings of the 2012 Interna-
word usage.
tional Conference on Advances in Social Networks
Analysis and Mining (ASONAM 2012), pages 111–
118. IEEE Computer Society.

Yan Chen, Jichang Zhao, Xia Hu, Xiaoming Zhang,
Zhoujun Li, and Tat-Seng Chua. 2013. From interest
to function: Location estimation in social media. In
AAAI.

Zhiyuan Cheng, James Caverlee, and Kyumin Lee.
2010. You are where you tweet: a content-based
approach to geo-locating twitter users. In Proceed-
ings of the 19th ACM international conference on In-
formation and knowledge management, pages 759–
768. ACM.

Jennifer Coates and Pia Pichler. 2011. Language and

gender: A reader. Wiley-blackwell Chichester.

Mark Davies. 2009. The 385+ million word corpus of
contemporary american english (1990–2008+): De-
Interna-
sign, architecture, and linguistic insights.
tional journal of corpus linguistics, 14(2):159–190.

Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsili-
gianni, Bruno Cornelis, and Nikos Deligiannis.
2017. Multiview deep learning for predicting twitter
users’ location. arXiv preprint arXiv:1712.08091.

Mark Dredze, Miles Osborne, and Prabhanjan Kam-
badur. 2016. Geolocation for twitter: Timing mat-
ters. In HLT-NAACL, pages 1064–1069.

Jacob Eisenstein, Brendan O’Connor, Noah A Smith,
and Eric P Xing. 2010. A latent variable model for
geographic lexical variation. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 1277–1287. Associa-
tion for Computational Linguistics.

European Union European Commission. 2018. Gen-

eral data protection regulation.

Tiffany Gagnon. 2013. The disinhibition of reddit

users. Adele Richardson’s Spring.

Huiji Gao, Jiliang Tang, Xia Hu, and Huan Liu. 2013.
Exploring temporal effects for location recommen-
In Pro-
dation on location-based social networks.
ceedings of the 7th ACM conference on Recom-
mender systems, pages 93–100. ACM.

Bo Han, Paul Cook, and Timothy Baldwin. 2012. Ge-
olocation prediction in social media data by ﬁnding
location indicative words. In Proceedings of COL-
ING, pages 1045–1062.

Bo Han, Paul Cook, and Timothy Baldwin. 2014. Text-
based twitter user geolocation prediction. Journal of
Artiﬁcial Intelligence Research, 49:451–500.

Keith Harrigian, Nathan Sanders, Jonathan Foster,
and Arjun Sangvhi. 2016. When anonymity is
not anonymous: Gender inference on reddit.
In
Northeastern Research, Innovation, and Scholarship
Expo, Boston, MA.

Bo Hu and Martin Ester. 2013. Spatial topic modeling
in online social media for location recommendation.
In Proceedings of the 7th ACM conference on Rec-
ommender systems, pages 25–32. ACM.

Xiaolei Huang, Michael C Smith, Michael J Paul,
Dmytro Ryzhkov, Sandra C Quinn, David A Bro-
niatowski, and Mark Dredze. 2017. Examining pat-
terns of inﬂuenza vaccination in social media.
In
Proceedings of the AAAI Joint Workshop on Health
Intelligence (W3PHIAI), San Francisco, CA, USA,
pages 4–5.

Michelle E Kho, Mark Duffett, Donald J Willison,
Deborah J Cook, and Melissa C Brouwers. 2009.
Written informed consent and selection bias in ob-
servational studies using medical records: system-
atic review. Bmj, 338:b866.

Tom Lippincott and Annabelle Carrell. 2018. Obser-
vational comparison of geo-tagged and randomly-
drawn tweets. In Proceedings of the Second Work-
shop on Computational Modeling of People?s Opin-
ions, Personality, and Emotions in Social Media,
pages 50–55.

26Peter Trudgill. 1974. Linguistic change and diffu-
sion: Description and explanation in sociolinguistic
dialect geography. Language in society, 3(2):215–
246.

Yehuda Vardi and Cun-Hui Zhang. 2000. The multi-
variate l1-median and associated data depth. Pro-
ceedings of
the National Academy of Sciences,
97(4):1423–1426.

Bert Vaux and Scott Golder. 2003. The harvard dialect
survey. Cambridge, MA: Harvard University Lin-
guistics Department.

Mark Wick and Bernard Vatant. 2012. The geonames
geographical database. Available from World Wide
Web: http://geonames. org.

Yuto Yamaguchi, Toshiyuki Amagasa, Hiroyuki Kita-
gawa, and Yohei Ikawa. 2014. Online user location
inference exploiting spatiotemporal correlations in
In Proceedings of the 23rd ACM
social streams.
International Conference on Conference on Infor-
mation and Knowledge Management, pages 1139–
1148. ACM.

Elena Zheleva and Lise Getoor. 2009. To join or not to
join: the illusion of privacy in social networks with
mixed public and private user proﬁles. In Proceed-
ings of the 18th international conference on World
wide web, pages 531–540. ACM.

Ji Liu and Diana Inkpen. 2015. Estimating user lo-
cation in social media with stacked denoising auto-
encoders. In VS@ HLT-NAACL, pages 201–210.

Momin M Malik, Hemank Lamba, Constantine Nakos,
and Jurgen Pfeffer. 2015. Population bias in geo-
tagged tweets. People, 1(3,759.710):3–759.

Yelena Mejova and Padmini Srinivasan. 2012. Cross-
ing media streams with sentiment: Domain adapta-
tion in blogs, reviews and twitter. In ICWSM.

Jonathan Mellon and Christopher Prosser. 2017. Twit-
ter and facebook are not representative of the gen-
eral population: Political attitudes and demograph-
ics of british social media users. Research & Poli-
tics, 4(3):2053168017720008.

Reid Priedhorsky, Aron Culotta, and Sara Y Del Valle.
2014. Inferring the origin locations of tweets with
quantitative conﬁdence. In Proceedings of the 17th
ACM conference on Computer supported coopera-
tive work & social computing, pages 1523–1536.
ACM.

Afshin Rahimi, Trevor Cohn, and Timothy Baldwin.
2017. A neural model for user geolocation and lexi-
cal dialectology. arXiv preprint arXiv:1704.04008.

Afshin Rahimi, Duy Vu, Trevor Cohn, and Timothy
Baldwin. 2015. Exploiting text and network context
for geolocation of social media users. arXiv preprint
arXiv:1506.04803.

reddit. 2018. reddit: the front page of the internet.

Stephen Roller, Michael Speriosu, Sarat Rallapalli,
Benjamin Wing, and Jason Baldridge. 2012. Super-
vised text-based geolocation using language models
on an adaptive grid. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 1500–1510. Association for
Computational Linguistics.

Martin Shelton, Katherine Lo, and Bonnie Nardi. 2015.
Online media forums as separate social lives: A
qualitative study of disclosure within and beyond
reddit. iConference 2015 Proceedings.

Philipp Singer, Fabian Fl¨ock, Clemens Meinhart, Elias
Zeitfogel, and Markus Strohmaier. 2014. Evolution
of reddit: from the front page of the internet to a
self-referential community? In Proceedings of the
23rd International Conference on World Wide Web,
pages 517–522. ACM.

Luke Sloan and Jeffrey Morgan. 2015. Who tweets
with their location? understanding the relationship
between demographic characteristics and the use of
geoservices and geotagging on twitter. PloS one,
10(11):e0142209.

Aaron Smith and Monica Anderson. 2018. Social me-

dia use in 2018. [Online; posted 1-March-2018].

27