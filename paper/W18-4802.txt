A Neural Morphological Analyzer for Arapaho Verbs Learned from a

Finite State Transducer

Sarah Moeller and Ghazaleh Kazeminejad and Andrew Cowell and Mans Hulden

Department of Linguistics

University of Colorado

first.last@colorado.edu

Abstract

We experiment with training an encoder-decoder neural model for mimicking the behavior of
an existing hand-written ﬁnite-state morphological grammar for Arapaho verbs, a polysynthetic
language with a highly complex verbal inﬂection system. After adjusting for ambiguous parses,
we ﬁnd that the system is able to generalize to unseen forms with accuracies of 98.68% (unam-
biguous verbs) and 92.90% (all verbs).

Introduction

1
One of the clear successes in computational modeling of linguistic patterns has been that of ﬁnite state
transducer (FST) models for morphological analysis and generation (Koskenniemi, 1983; Beesley and
Karttunen, 2003; Hulden, 2009; Lind´en et al., 2009). Given enough linguistic expertise and investment
in developing such models, FSTs provide the capability to analyze any well-formed word in a language.
Although FST models generally rely on lexicons, they can also be extended to handle complex inﬂected
word forms outside the lexicon as long as morphophonological regularities are obeyed. Even ill-formed
words can be mapped to a “closest plausible reading” through FST engineering (Beesley and Karttunen,
2003). On the downside, developing a robust FST model for a given language is very time-consuming and
requires knowledge of both the language and ﬁnite-state modeling tools (Maxwell, 2015). Development
of a ﬁnite-state grammar tends to follow a Pareto-style tradeoff where the bulk of the grammar can be
developed very quickly, and the long tail of remaining effort tends to focus on lexicon expansion and
difﬁcult corner cases.

In this paper we describe an experiment in training a neural encoder-decoder model to replicate the
behavior of an existing morphological analyzer for the Arapaho language (Kazeminejad et al., 2017).
Our purpose is to evaluate the feasibility of bootstrapping a neural analyzer with a hand-developed FST
grammar, particularly if we train from an incomplete selection of word forms in the hand-developed
grammar. A successful morphological analyzer is essential for downstream applications, such as speech
recognition and machine translation, that could provide Arapaho speakers access to common tools similar
to Siri or Google Translate that might support and accelerate language revitalization efforts.

2 Background & Related Work
Neural network models for word inﬂection have increased in popularity, particularly following the two
SIGMORPHON and CoNLL-SIGMORPHON shared tasks (Cotterell et al., 2016; Cotterell et al., 2017).
Most of the work in this domain relies on training encoder-decoder models used in machine translation to
perform ‘translations’ of base forms and grammatical speciﬁcations into output forms, such as fly +V
+3PPres (cid:55)→ flies, or vice versa. While such models can produce very reliable systems with a few
thousand examples, the small available sample of polysynthetic languages indicate they are slightly more
difﬁcult to learn. Compare, for example, the accuracies of the best teams at CoNLL-SIGMORPHON
2017 between Navajo (92.30%) and Quechua1 (99.90%). A remarkable detail about the neural inﬂection
This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/

1An agglutinating language with complex morphology, though not considered polysynthetic.

ProceedingsofWorkshoponPolysyntheticLanguages,pages12–20SantaFe,NewMexico,USA,August20-26,2018.12models is that in the 2017 shared task they were found to generalize beyond feature combinations that
they had witnessed. Thus, for example, if a system had seen future tense forms and plurals separately,
but never seen the combination of the two, they could produce the combination quite reliably (Cotterell
et al., 2017). This effect was most striking for Basque, which has a highly complex, albeit very regular,
verb system. One of the main purposes of the experiments described in this paper is to capitalize on this
capacity to automatically generalize beyond what has been explicitly encoded in an FST grammar.

Standard morphological analyzers tend to be designed to return all ‘plausible’ parses of a word. In
English, for example, this means that in practice any verb (e.g. sell) would always be alternatively parsed
as a noun reading as well; likewise for the third person present form, sells, which could be parsed as a
plural noun. This adds complications to the design of a neural model intended to mimic the behavior of a
classical morphological analyzer, since it needs to return multiple options, and a neural encoder-decoder
really encapsulates a distribution over all possible output strings Σ∗ for any input string read by the
encoder. An unexpected “advantage” of applying this to polysynthetic languages is that, while the verb
complex in polysynthetic languages tends to be very intricate and is time-consuming to model, it proffers
typically less ambiguity of a parse (as will be discussed in Section 6). Even when ambiguous readings are
possible, they tend to be highly systematic. Silfverberg and Hulden (2018) documents a neural model
from an FST model for Finnish (an agglutinative language) to retrieve all plausible parses of a word
form, reporting an F1-score of 0.92. The authors report that the recall was far lower than the precision,
indicating difﬁculty in learning to return all the valid parses. The problem of unsystematic ambiguity,
however, can often be avoided in the parsing of verbs in polysynthetic languages with mostly systematic
ambiguity. Navajo, for example, collapses singulars and duoplurals in the 3rd and 4th person, and so
the ambiguity between the two could be encoded by introducing an additional super-tag representing
both options at once.2 In other words, systematic multiple readings can be circumvented in systems
designed to give a single parse by simply altering the tagset for relevant cases, such that a parse with
the tag [SG/DPL] could be interpreted as a two-way ambiguity. Another example is seen in Algonquian
languages, which often have homophonous participle forms of verbs—afﬁxes expressing features of the
possessor are often homophonous with afﬁxes expressing features of the subject or object.3

3 The Arapaho Verb

Arapaho is a member of the Algonquian (and larger Algic) language family; it is an agglutinating,
polysynthetic language, with free word order (Cowell and Moss Sr, 2008). The language has a very
complex verbal inﬂection system, with a number of typologically uncommon elements. Verb stems
have unique stem-ﬁnal elements which specify for valency and animacy: a given stem is used either
with animate or inanimate subjects for intransitive verbs (tei’eihi- ‘be strong.animate’ vs. tei’oo- ‘be
strong.inanimate’), and with animate or inanimate objects for transitive verbs (noohow- ‘see s.o.’ vs.
noohoot- ‘see s.t.’). For each of these categories of stems, the pronominal afﬁxes/inﬂections that attach
to the verb stem vary in form, for example, 2SG with intransitive, animate subject verbs is /-n/, while for
transitive, inanimate object verbs it is /-ow/ (nih-tei’eihi-n ‘you were strong’ vs. nih-noohoot-ow ‘you
saw it’).

All of these stem types can occur in four different verbal orders, whose function is primarily modal—
afﬁrmative, conjunct/subordinate, imperative, and non-afﬁrmative. These verbal orders each use different
pronominal afﬁxes/inﬂections as well. For example, when a verbal root such as /nooh-/ ‘see’ is transi-
tive with an animate object, 2SG acting on 3SG is /-in/ or /-un/ for the imperative order (noohow-un
‘(you) see him!’), but /-ot/ for the afﬁrmative order (nih-noohow-ot ‘you saw him’), and with the non-
afﬁrmative order the 2SG marker is a preﬁx, /he-/, not a sufﬁx. Thus, with four different verb stem types
and four different verbal orders, there are a total of 16 different potential inﬂectional paradigms for any
verbal root, though there is some overlap in the paradigms, and not all stem forms are possible for all
roots.

2The fourth person in Navajo is the form for an obligatorily human “impersonal” third person participant (Akmajian and

Anderson, 1970; Young and Morgan, 1987).

3Thank you to an anonymous reviewer for this example.

13Two ﬁnal complications are vowel harmony with related consonant mutation, and a proxi-
mate/obviative system. Arapaho has both progressive and regressive vowel harmony, operating on /i/
and /e/ respectively. This results in alternations in both the inﬂections themselves, and the ﬁnal elements
of stems, such as noohow-un ‘see him’ vs. niiteheib-in ‘help him’, or nih-ni’eeneb-e3en ‘I liked you’
vs. nih-ni’eenow-oot ‘he liked her’. Arapaho also has a proximate/obviative system, which does not
overlap with either subject/object or agent/patient categories, but instead designates pragmatically more-
and less-prominent participants. There are “direction-of-action” markers (elsewhere, for simplicity, we
use “subject” and “object”) included in inﬂections, which do not correspond to true pronominal afﬁxes.
Thus nih-noohow-oot ‘more important 3SG saw less important 3S/PL’ vs. nih-noohob-eit ‘less impor-
tant 3SG/PL saw more important 3S’, and nih-noohob-einoo ‘less important 3S saw more important 1S’.
The elements -oo- and -ei- specify direction of action, not speciﬁc persons or numbers of participants.
some of these sufﬁxes produce systematic ambiguity, as shown in Table

Some “direction-of-action” markers generate ambiguity in person and number of the verb’s arguments.
Thus, for example, in nih-noohob-eit ‘less important 3SG/PL saw more important 3SG’ the /-eit/ sufﬁx
is systematically ambiguous as to the number of the less important/obviative 3rd-person participant.

4 Finite-State Model

A morphological analyzer is a prerequisite for many NLP tasks. It is even more crucial to have such
a parser for morphologically complex languages such as Arapaho. A ﬁnite state transducer (FST) is
the standard technology for creating morphological analyzers. The FST is bidirectional and able to
simultaneously parse given inﬂected word forms and generate all possible word forms for a given stem
(Beesley and Karttunen, 2003).

The Arapaho FST model used in this paper was constructed with the foma ﬁnite-state toolkit (Hulden,
2009). The FST is constructed in two parts, the ﬁrst being a speciﬁcation of the lexicon and morphotactics
using the ﬁnite-state lexicon compiler (lexc). This is a high-level declarative language for effective
lexicon creation, where concatenative morphological rules and morphological irregularities are addressed
(Karttunen, 1993).

The second part implements the morphophonological rules of the language using “rewrite rules” that
apply the appropriate changes in speciﬁed contexts. This way, the generated inﬂected word form is not
merely a bundle of morphemes, but the completely correct form in accord with the morphophonological
rules of the language. So, by applying, in a particular order (speciﬁed in the grammar of the language),
the rewrite rules to the parsed forms generated in the lexc ﬁle, the result is a single FST able to both
generate and parse. Figure 1 shows how the FST is designed to generate and parse an example.

Figure 1: Composition in an FST illustrating the underlying (input) parsed forms and the resulting sur-
face (output) inﬂected forms after mapping morpheme tags to concrete morphemes and subsequently
undergoing morphophonological alternations.

The generalized application of rewrite application such that a FST or a neural model based on an

14FST which is described below may seem like a “manufacturing” of the language, applying grammatical
rules to verbal stems in order to create artiﬁcial forms. However, a morphological analyzer works with
inﬂections and various kinds of preﬁxes; it does not build new verb stems. For the most part, it is the
stems themselves that encode culture-sensitive information and perspectives.

5 Training a recurrent neural network from an FST

Description

Tag
1PL-EXCL First Person Plural Exclusive
3
II
TI
IC

Tag
1PL-INCL First Person Plural Inclusive
Third Person Proximate
4
Inanimate Subject Intransitive Verb AI
Inanimate Object Transitive Verb
TA
Initial Change

Third Person Obviative
Animate Subject Intransitive Verb
Animate Object Transitive Verb

Description

Table 1: Description of non-self-explanatory tags used in the parser

For training data, we extract inﬂected word forms and their corresponding parsed forms generated
by the FST model for Arapaho, i.e. pairs such as the one seen at the top of Figure 1. These pairs
serve as supervised examples to train a recurrent neural network (RNN) encoder-decoder. The set of
FST-extracted input-output pairs contains 584,574 examples; however, a few forms had been incorrectly
stored in the database and had to be identiﬁed and ﬁltered before training. We trained on 60% of the
ﬁltered pairs. Another 20% was withheld for validation and an additional 20% as the test set. We
evaluate the ability of the RNN to provide correct parses to unseen inﬂected word forms.

Since the currently strongest performing models for the related task of morphological inﬂection (Cot-
terell et al., 2017; Kann et al., 2017; Makarov et al., 2017) use an LSTM-based sequence-to-sequence
(seq2seq) model (Sutskever et al., 2014), we follow this design in our work. Following Kann et al.
(2017) who found that adding an attention mechanism (Bahdanau et al., 2015) improved performance,
we always include attention as well. We treat parsing as a translation task of input character sequences
from the fully-inﬂected surface forms to an output sequence of morphosyntactic tags plus the character
sequences of the verbal root, i.e. we treat the root as the citation form to be retrieved. We implement the
bidirectional LSTM-based sequence to sequence model with OpenNMT (Klein et al., 2017), using the
default parameters that employ 2 layers for both the encoder and decoder, a hidden size of 500 for the
recurrent unit, and a maximum batch size of 64. We train the model until the perplexity converges (at
1.02 or 1.01 for ambiguous and combined data, and 1.00 for unambiguous data), which usually occurs
within 5 epochs and generally does not improve signiﬁcantly with additional epochs. We experimented
adding additional layers but without noticeable difference in the results.

As previous authors (Sutskever et al., 2014) have documented a sensitivity to element ordering, we
experimented with training the model using various relative orders of morphosyntactic tags and the root
morpheme: Tags+Root, Root+Tags, Tags+Root+Tags. These orders are shown in Table 2.
(Table 1 provides the description of tags used in the parser that may not be self-explanatory).

Only the Tags+Root order was able to produce a model that parses any single inﬂected form com-
pletely correct. Examining the results of the Tags+Root predictions revealed that a majority of the
mistakes involve the ﬁnal letter of the root. The model often incorrectly predicts the last letter of the root
morpheme, leaves it out completely, or adds an additional letter. Using an end-of-sequence marker does
not affect this tendency, which we did not investigate further as we were able to avoid its effect by simply
altering the order of the Tags+Root elements and the evaluation process. First, we trained the model
with a Tags+Root+Tags4 order, duplicating the morphosyntactic tags on both sides or the root, in the
order that they were generated by the FST. After training, we removed the set of tags following the root
and evaluated the neural encoder-decoder’s predictions only against Tags+Root ordering of the test
set.

4Repeating the Tags

15Order
Tags+Root

Root+Tags

Tags+Root+Tags

Example
[VERB][TA][ANIMATE-OBJECT][AFFIRMATIVE][PRESENT][IC][1PL-EXCL-
SUBJ][2SG-OBJ]noohow
noohow[VERB][TA][ANIMATE-OBJECT][AFFIRMATIVE][PRESENT][IC][1PL-
EXCL-SUBJ][2SG-OBJ]
[VERB][TA][ANIMATE-OBJECT][AFFIRMATIVE][PRESENT][IC][1PL-
EXCL-SUBJ][2SG-OBJ]noohow[VERB][TA][ANIMATE-
OBJECT][AFFIRMATIVE][PRESENT][IC][1PL-EXCL-SUBJ][2SG-OBJ]

Table 2: Examples of orders of morphosyntactic tags and roots used for training the neural model. For
encoder-decoder training, spaces were placed between square brackets and individual letters of the root.
Thus, tags and letters were treated as single units for “translation”.

Once high accuracy was reached on inﬂected word forms with only one possible parse, the ambiguous
wordforms were added to the data. With no adjustments made to the output of the FST, the model
parsed 46% of the test data completely correct. Removing all ambiguous surface forms which have
than one possible parse increased the accuracy to 60%. With this setup, the accuracy for parsing full
words did not exceed 60% without adjustments made for ambiguous words, the overall F1-scores on
individual tags and characters averaged over 0.9, indicating that, although 40% of the predicted parses
contained at least one mistake, very few mistakes were made per wordform. Ambiguous forms were
“disambiguated” for parsing by altering the tagset. Multiple morphosyntactic tags that are generated
by one morpheme became a single tag containing generic information. For example, the word nih-
noohob-eit ‘less important 3SG/PL saw more important 3SG’ has two possible parses. Its /-eit/ sufﬁx
is systematically ambiguous as to the number of the less important/obviative 3rd-person participant. So
the tagset substituted the two alternative parses—[3SG-SUBJ][3SG-OBJ] or [3PL-SUBJ][3SG-OBJ]—
with a single new tag [3-SUBJ.3SG-OBJ]. Altering the tagset like this makes the predicted parsed forms
less informative, since morphosyntactic information is lost for the sake of generalization. However, the
predicted parses are no less ambiguous than are the corresponding fully-inﬂected Arapaho words when
removed from context.

6 Results

Ambiguous and unambiguous word forms combined produce a training data size of about 245,600 su-
pervised pairs. A little over half of those have unambiguous parses, but the actual percentage of unam-
biguous forms proffered by Arapaho’s polysynthetic verbal inﬂection is probably closer to 75% because
repeated ambiguous forms were not eliminated from the data. The RNN model was trained to produce
root morphemes and morphosyntactic tags from fully-inﬂected word forms. The most accurate results
came from training the model with morphosyntactic tags repeated before and after the root morpheme and
removing the ﬁnal set of tags before evaluating the model’s prediction on the test set (Tags+Root+Tags
⇒ Tags+Root). Training only on unambiguous wordforms resulted in a ﬁnal accuracy of 98.68%. After
ambiguous forms were added to the data and the tagset was altered to “disambiguate” systematic alter-
native parses, the model’s accuracy dropped from to 92.90%. This is better than the model’s predictions
of the ambiguous pairs on their own: 88.06%. The results of the model’s prediction on individual tags
and letters are broken down in the Appendix.

The nearly 93% accuracy is obtained by minimal disambiguation of ambiguous word forms. We
removed speciﬁcation of person and number from some arguments to account for the ambiguity of
“direction-of-action” morphemes. The relatively low scores on certain tags, as shown in the Appendix,
indicate that this accounts for only part of Arapaho’s verbal morphological ambiguity. Other morphosyn-
tactic information is ambiguous or, at least, more difﬁcult to identify. For example, the difference be-
tween some transitive and intransitive verbs. Also, even some of the altered “direction-of-action” tags
could be altered to become even less generic. Pre-processing should identify these morphemes and re-

16place the alternative parses with as accurate a super-tag as the language’s ambiguity allows. Such further
disambiguation is a longer tail for future work, undoubtedly complicated by morphophonemic changes.

7 Discussion

Since even an endangered language expands and changes, a morphological analyzer that generalizes to
unseen inﬂected forms is more useful than one that does not. Handwritten rules cannot reach into the
long tail of lexicon expansion and difﬁcult corner cases. The neural encoder-decoder model described
in this paper overcomes the limitations of FST and handwritten rules. One advantage of an FST is
the large number of surface and parsed pairs it generates for supervised training of our neural model.
We paid attention to the best ordering of the morphosyntactic tags and verbal roots in the training data
and found the best combination was training on Tags+Root+Tags and evaluating on Tags+Root. Our
neural model can generalize with nearly 93% accuracy beyond what is explicitly encoded. This result
comes in part from the lack of systematic ambiguity in a polysynthetic language such as Arapaho, but
future work should increase the usefulness of the parses by handling ambiguities beyond person/number,
and handling those with more precision. Although some of our experiments trained on random small
percentages of the FST-generated data, further reﬁnement and reduction of the data would demonstrate
how the neural model performs on an incomplete selection of word forms, a situation not uncommon
from hand-written descriptions of endangered languages.5

References
Adrian Akmajian and Stephen Anderson. 1970. On the use of fourth person in Navajo, or Navajo made harder.

International Journal of American Linguistics, 36(1):1–8.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to

align and translate. In ICLR.

Kenneth R. Beesley and Lauri Karttunen. 2003. Finite State Morphology. CSLI Publications, Stanford, CA.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman, David Yarowsky, Jason Eisner, and Mans Hulden. 2016.
In Proceedings of the 14th SIGMOR-
The SIGMORPHON 2016 shared task—morphological reinﬂection.
PHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 10–22, Berlin,
Germany, August. Association for Computational Linguistics.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G˙eraldine Walther, Ekaterina Vylomova, Patrick Xia, Man-
aal Faruqui, Sandra K¨ubler, David Yarowsky, Jason Eisner, and Mans Hulden. 2017. CoNLL-SIGMORPHON
2017 shared task: Universal morphological reinﬂection in 52 languages. In Proceedings of the CoNLL SIG-
MORPHON 2017 Shared Task: Universal Morphological Reinﬂection, pages 1–30. Association for Computa-
tional Linguistics.

Andrew Cowell and Alonzo Moss Sr. 2008. The Arapaho Language. University Press of Colorado.

Mans Hulden. 2009. Foma: a ﬁnite-state compiler and library. In Proceedings of the 12th Conference of the Eu-
ropean Chapter of the Association for Computational Linguistics, pages 29–32. Association for Computational
Linguistics.

Katharina Kann, Ryan Cotterell, and Hinrich Sch¨utze. 2017. Neural multi-source morphological reinﬂection. In
Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics:
Volume 1, Long Papers, pages 514–524. Association for Computational Linguistics.

Lauri Karttunen. 1993. Finite-state lexicon compiler. Xerox Corporation. Palo Alto Research Center.

Ghazaleh Kazeminejad, Andrew Cowell, and Mans Hulden. 2017. Creating lexical resources for polysynthetic
languages—the case of Arapaho. In Proceedings of the 2nd Workshop on the Use of Computational Methods in
the Study of Endangered Languages, pages 10–18, Honolulu, March. Association for Computational Linguis-
tics.

5We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this

research.

17G. Klein, Y. Kim, Y. Deng, J. Senellart, and A. M. Rush. 2017. OpenNMT: Open-Source Toolkit for Neural

Machine Translation. ArXiv e-prints.

Kimmo Koskenniemi. 1983. Two-level morphology: A general computational model for word-form recognition

and production. Publication 11, University of Helsinki, Department of General Linguistics, Helsinki.

Krister Lind´en, Miikka Silfverberg, and Tommi Pirinen. 2009. HFST tools for morphology—an efﬁcient open-
source package for construction of morphological analyzers. In International Workshop on Systems and Frame-
works for Computational Morphology, pages 28–47. Springer.

Peter Makarov, Tatiana Ruzsics, and Simon Clematide. 2017. Align and copy: UZH at SIGMORPHON 2017
shared task for morphological reinﬂection. In Proceedings of the CoNLL SIGMORPHON 2017 Shared Task:
Universal Morphological Reinﬂection, pages 49–57, Vancouver, August. Association for Computational Lin-
guistics.

Michael Maxwell. 2015. Grammar debugging.

pages 166–183. Springer.

In Systems and Frameworks for Computational Morphology,

Miikka Silfverberg and Mans Hulden. 2018. Initial experiments in data-driven morphological analysis for Finnish.
In Proceedings of the Fourth International Workshop on Computatinal Linguistics of Uralic Languages, pages
100–107, Helsinki, Finland, January. Association for Computational Linguistics.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. In

Advances in Neural Information Processing Systems (NIPS), pages 3104–3112.

Robert Young and William Morgan. 1987. The Navajo Language: a Grammar and Colloquial Dictionary. Uni-

versity of New Mexico Press, Albuquerque.

188 Appendix
Below are the results from training the neural model to produce disambiguated morphosyntactic tags
both before and after a root morpheme, but evaluated only on the ﬁrst set of tags and the root morpheme.
The training model works with a vocabulary of 56 morphosyntactic tags and 16 letters. The 80/20/20
train/dev/test split resulted in 81,883 test examples of both ambiguous and unambiguous forms.

Precision Recall F1-score

Tag or Letter
[1PL-EXCL-SUBJ.2PL-OBJ]
[1PL-EXCL-SUBJ.2SG-OBJ]
[1PL-EXCL-SUBJ.3PL-OBJ]
[1PL-EXCL-SUBJ.3SG-OBJ]
[1PL-INCL-SUBJ.3-OBJ]
[1PL-INCL-SUBJ]
[1PL-SUBJ]
[1SG-SUBJ]
[1SG-SUBJ][2PL-OBJ]
[1SG-SUBJ][2SG-OBJ]
[1SG-SUBJ][3PL-OBJ]
[1SG-SUBJ][3SG-OBJ]
[2PL-SUBJ.3-OBJ]
[2PL-SUBJ]
[2PL-SUBJ][1PL-EXCL-OBJ]
[2PL-SUBJ][1SG-OBJ]
[2SG-SUBJ]
[2SG-SUBJ][1PL-EXCL-OBJ]
[2SG-SUBJ][1SG-OBJ]
[2SG-SUBJ][3PL-OBJ]
[2SG-SUBJ][3SG-OBJ]
[3-SUBJ.1PL-INCL-OBJ]
[3-SUBJ.2PL-OBJ]
[3-SUBJ.4-OBJ]
[3PL-SUBJ.4-OBJ]
[3PL-SUBJ]
[3PL-SUBJ][1PL-EXCL-OBJ]
[3PL-SUBJ][1SG-OBJ]
[3PL-SUBJ][2SG-OBJ]
[3SG-SUBJ]
[3SG-SUBJ][1PL-EXCL-OBJ]
[3SG-SUBJ][1SG-OBJ]
[3SG-SUBJ][2SG-OBJ]
[4-SUBJ.3PL-OBJ]
[4-SUBJ.3SG-OBJ]
[4-SUBJ.4-OBJ]
[4PL-SUBJ]
[4SG-SUBJ]
[AFFIRMATIVE]
[AI]
[ANIMATE-OBJECT]
[ANIMATE-SUBJECT]
[IC]

0.96
1.00
0.66
1.00
0.98
0.99
1.00
0.98
1.00
0.99
0.85
0.88
0.99
0.98
1.00
0.96
1.00
1.00
0.89
0.99
0.73
0.99
0.99
0.98
0.99
0.99
0.69
0.98
1.00
0.98
0.90
0.98
0.99
0.99
0.99
0.99
0.95
0.93
1.00
0.84
0.99
0.84
1.00

0.99
0.99
0.99
0.50
1.00
0.98
0.99
0.98
1.00
1.00
0.99
0.98
0.99
0.97
1.00
0.98
0.83
1.00
0.95
0.68
0.98
0.99
0.99
0.99
0.99
0.85
0.93
0.99
1.00
0.81
0.57
1.00
1.00
0.99
0.99
1.00
0.98
0.96
1.00
0.90
1.00
0.90
0.99

Instances

1381
1413
1395
1397
2759
712
1396
673
1407
1350
1363
1384
4085
1394
2020
2078
1052
2082
2057
2099
2047
2751
2829
2802
2767
2600
1352
1351
1384
2614
1344
1298
1401
2867
2788
11016
2630
2545
36878
1144
66267
1144
18417

0.98
0.99
0.79
0.66
0.99
0.98
1.00
0.98
1.00
1.00
0.91
0.93
0.99
0.97
1.00
0.97
0.91
1.00
0.92
0.80
0.84
0.99
0.99
0.99
0.99
0.91
0.79
0.98
1.00
0.89
0.70
0.99
1.00
0.99
0.99
0.99
0.97
0.94
1.00
0.87
0.99
0.87
0.99

Continued on next page

19Table 3 – Continued from previous page

Precision Recall F1-score

Tag or Letter
[II]
[IMPERATIVE]
[INANIMATE-OBJECT]
[INANIMATE-SUBJECT]
[INTERROGATIVE]
[NEG]
[NON AFFIRMATIVE]
[PAST]
[PRESENT]
[PROHIBITIVE]
[TA]
[TI]
[VERB]
b
c
e
h
i
k
n
o
s
t
u
w
x
y
'
3
average/total:

0.98
0.95
0.99
0.98
1.00
1.00
1.00
1.00
1.00
1.00
0.99
0.99
1.00
0.95
1.00
0.99
1.00
0.99
1.00
0.99
0.99
1.00
1.00
0.99
0.98
0.99
0.99
1.00
0.99
0.97

0.93
0.98
0.92
0.93
1.00
1.00
1.00
1.00
1.00
1.00
1.00
0.92
1.00
0.99
1.00
0.99
0.99
0.99
1.00
0.99
0.99
0.99
0.99
1.00
0.95
0.99
0.99
1.00
1.00
0.96

Instances

6547
3124
7935
6547
19884
18850
38734
18461
57151
3157
66267
7935
81893
19171
18440
85704
61047
103323
21331
71447
157112
17716
34310
38280
22060
14429
6978
35888
31242

1,280,696

0.95
0.97
0.95
0.95
1.00
1.00
1.00
1.00
1.00
1.00
0.99
0.95
1.00
0.97
1.00
0.99
1.00
0.99
1.00
0.99
0.99
0.99
0.99
0.99
0.96
0.99
0.99
1.00
1.00
0.96

20