A Treebank for the Healthcare Domain 

Oinam Nganthoibi 

Computational Linguist 
ezDI Inc. Kentucky 
oinam.n@ezdi.us 

Diwakar Mishra 

Computational Linguist 
diwakar.m@ezdi.us 

ezDI Inc. Kentucky 

Pinal Patel 

Team Lead, Research 
ezDI Inc. Kentucky 
pinal.p@ezdi.us 

 

Narayan Choudhary 

Lecturer cum Junior Research Officer 
choudharynarayan@gmail.com 

CIIL, Mysore 

Hitesh Desai 

Research Engineer 
ezDI Inc. Kentucky 

hitesh.d@ezdi.us 

 

Abstract 

This paper presents a treebank for the healthcare domain developed at ezDI. The treebank is 
created from a wide array of clinical health record documents across hospitals. The data has 
been de-identified and annotated for constituent syntactic structure. The treebank contains a 
total of 52053 sentences that have been sampled for subdomains as well as linguistic variations. 
The paper outlines the sampling process followed to ensure a better domain representation in 
the corpus, the annotation process and challenges, and corpus statistics. The Penn Treebank 
tagset and guidelines were largely followed, but there were many syntactic contexts that war-
ranted adaptation of the guidelines. The treebank created was used to re-train the Berkeley par-
ser and the Stanford parser. These parsers were also trained with the GENIA treebank for com-
parative quality assessment. Our treebank yielded greater accuracy on both parsers. Berkeley 
parser performed better on our treebank with an average F1 measure of 91 across 5-folds. This 
was a significant jump from the out-of-the-box F1 score of 70 on Berkeley parser’s default 
grammar. 

1  Introduction 
There is severe paucity of data in healthcare due to the confidentiality regulations entailed. However, 
the importance of domain specific training data cannot be denied. It is a well acknowledged fact that 
systems trained on the general domain do not perform well in highly specialized domains like healthcare 
(Jiang et al., 2015; Zhang et al., 2015; Ferraro et al., 2013). The research is further hindered for tasks 
that require a large volume of annotated data such as syntactic parsing. 

Parsing is one of the complex natural language processing (NLP) tasks. Its complexity is inherited 
from syntax. Syntactic annotation is based on phrase structure grammar which posits a universal frame-
work based on well-formedness conditions (Chomsky, 1965, 1993, 1995). However, these frameworks 
are modeled on formal language and therefore fail to account for ungrammaticality or variations in style. 
A universal syntactic framework even for a well-studied language like English is not established due to 
these reasons. Clinical healthcare data is an apposite example. It is populated with ungrammatical frag-
ments  and  domain  specific  idiosyncrasies  that  cannot  be  accounted  by  standard  grammatical  rules. 
Therefore, the annotation task involves a high level of complexity and subjectivity. This paper show-
cases specific examples that justified adoption of new rules that are not postulated under the Penn Tree-
bank guidelines (Bies et al., 1995). This is domain specific annotation. This approach has been reward-
ing. The Berkeley parser (Petrov et al., 2006) trained on this domain specific treebank gave a high F1 
score of 91.58 using ParsEval (Harrison et al., 1991) method of evaluation. This is a remarkable im-
provement from the F1 of 70 that was attained on the parser’s default grammar model. 
 

 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: 
http://creativecommons.org/licenses/by/4.0/ 

ProceedingsoftheJointWorkshopon,LinguisticAnnotation,MultiwordExpressionsandConstructions(LAW-MWE-CxG-2018),pages144–155SantaFe,NewMexico,USA,August25-26,2018.1442  Related work 
There are various types of corpora available in the field of clinical/medical NLP research. Good exam-
ples of raw text corpora include Stockholm corpus (Dalianis et al., 2012) which contains over a million 
patient record documents; Mayo Clinic clinical notes, referred in Wu et al. (2012) which contains 51 
million documents, and a public repository of medical documents available at ClinicalTrials.gov (Hao 
et al., 2014). Zweigenbauma et al. (2001) also created a balanced raw text corpus annotated with meta-
information to represent the medical domain sub-language. 

Some corpora are annotated for part-of-speech (PoS), such as GENIA corpus (Tateisi and Tsujii, 
2004) and the corpus of Pakhomov et al., (2006) while others  are annotated and trained for named entity 
recognition (NER) such as Orgen et al. (2007), who have created a medical NER evaluation corpus that 
contains 160 clinical notes, 1556 annotations of 658 concept codes from SNOMED CT. Wang (2009) 
also  reports  training  an  NER  system  on  a  corpus  of  Intensive  Care  Service  documents,  containing 
>15000 medical entities of 11 types. 

Alnazzawi et al. (2014), GENIA corpus version 3.0 (Kim et al., 2003) and CLEF corpus (Roberts et 
al., 2009) are examples of semantically annotated corpora. The source of GENIA corpus is 2000 research 
abstracts  from  MEDLINE database  and  is  limited  to specific  type  of  documents  while  Alnazzawi’s 
(2014) corpus is limited to covering only congestive heart and renal failure. BioScope corpus (Vinczer 
et al., 2008) is annotated for uncertainty, negation and their scope; THYME corpus (Styler et al., 2014) 
is annotated for temporal ordering using THYME-TimeML guidelines, an extension of ISO-TimeML; 
and Chapman et al. (2012) have annotated a corpus of 180 clinical reports for all anaphora-antecedent 
pairs. Xia and Yetisgen-Yildiz (2012) describe 3 clinical domain corpora, in which, the first corpus is 
annotated at the sentence level; the second corpus is annotated at the document level, for presence of 
pneumonia and infection score in X-ray reports; and the third corpus is annotated for pneumonia detec-
tion per patient in ICU reports. Some researchers have combined parse trees and multiword entities for 
specific tasks such as multiword entity recognition (Finkel and Manning, 2009) and entity relation iden-
tification (Shi et al., 2007). Cohen et al. (2005) list and classify six publically available biomedical 
corpora, namely, PDG, Wisconsin, GENIA, MEDSTRACT, Yapex and GENETAG, according to vari-
ous corpus design features and characteristics. 

Apart of these, work such as Pathak et al. (2015), have customized Unified Medical Language System 

(UMLS) thesaurus for concept unique identifier (CUI) detection as part of disorder detection. 

In literature closely related to the work presented here, there are treebanks (syntactically annotated 
corpora) that use customized or original Penn Treebank guidelines (Bies et al., 1995). Albright et al. 
(2013) have annotated 13091 sentences of MiPECQ corpus for syntactic structure, predicate-argument 
structure and UMLS based semantic information. Fan et al.  (2013) have customized Penn parsing guide-
lines to handle ill-formed sentences and have annotated 1100 sentences for syntactic structure. A subset 
of GENIA corpus, 500 abstracts, is also annotated for syntactic structure (Tateisi et al., 2005) using 
GENIA corpus manual (Kim et al., 2006). This is further extended to 1999 abstracts (GENIA project 
website). These three treebanks have sentences annotated for constituency structure. There are also tree-
banks annotated with dependency structure such as The Prague Dependency Treebank (Hajic, 1998). 
As evident from the work listed above, there has not been any attempt of corpus creation to the ex-
panse of the project presented here. Our corpus exceeds in quantity with 52053 sentences covering a 
variety of sentence structures from various document types and sources. Our work also differs in the 
corpus sampling process. MiPACQ corpus consists of randomly selected clinical notes and pathology 
notes from Mayo Clinic related to colon cancer. GENIA corpus is a set of abstracts from MEDLINE 
database that contain specific keywords. We have followed a sampling procedure that takes into con-
sideration sentence patterns and domain representation. Our corpus sampling method covers the clinical 
domain on a large scale by giving representation to a variety of hospitals, specialties and document 
types. A more detailed comparison of corpus structure between our work and the GENIA Treebank 
(biomedical domain) and Wall Street Journal section of Penn Treebank (general domain) is shown in 
Section 4. 

1453  Creation of the Treebank 
The task of treebank creation can be divided into two major parts - data sampling and annotation/brack-
eting. Section 3.1 describes how the data was sampled from clinical documents of different hospitals 
and specialty clinics. Section 3.2 discusses special cases of annotation that are peculiar to this domain. 
3.1  Data Sampling 
The current corpus has been assembled over time from different databases. The first set was extracted 
from an internal database of 237,100 documents from 10 hospitals in the US from the year 2012-2013. 
These hospitals were selected due to the fact that they were large establishments housing variety of 
specialties and therefore a good resource for different types of documents. These documents were clas-
sified into different work types, service lines and section heads, based on which, 10,000 representative 
documents were manually selected. A graph-based string similarity algorithm was used to find similar 
sentences which resulted in a collection of unique patterns. A sentence clustering algorithm was then 
used to narrow them down into pattern heads that were representative of all the unique patterns. The 
final corpus was selected by giving proportional weight to each pattern head. A detailed discussion of 
the methodology is found in Choudhary et al., (2014). This set was created for the development of a 
part-of-speech (PoS) tagger. 38,000 sentences from this dataset were used as the base for this parsing 
project as well. The Table 1 below shows the sub-domains included in this dataset. 
 

IM_Oncology 
IM_Internal  Medicine 
General 

IM_Occupational 
Medicine 
Anesthesiology  Neurosurgery 
Opthalmology 
Nurse Practitioner 

IM_After Hours Care 
Vascular  and  Thoracic 
Surgery 
Obstetrics 
IM_Pain Management 
IM_Physical  Medicine 
and Rehabilitation 
IM_Nephrology 
IM_Gastroenterology 
IM_Infectious Diseases 
Obstetrics & Gynecology IM_Cardiology 
Podiatry 

IM_Endocrinology  Pathology 
Emergency  Medi-
cine 
Psychiatry 
Family Medicine  Urology 
IM_General  Medi-
cine 
IM_Hematology 
IM_Neurology 
IM_Rheumatology  Hospitalist 
Oncology 
 

Surgery 

IM_Physician  As-
sistant 
IM_Pediatrics 
IM_Geriatrics 

Otorhinolaryngology  
Radiology 
Orthopedics 
Unclassified 
 

Table 1: Subdomains included in Dataset 1 from Database 1 

The second dataset was sampled from a different database of 3 hospitals in the US containing 1,473 
documents dated April to September, 2016. This database was used to update the corpus with current 
clinical data. The need to update arose from the observation that the style of electronic health record 
documentation has changed significantly between 2012 and 2016. It is evident by the relative proportion 
of S nodes (well-formed sentences/clauses) and FRAG nodes (fragments) between the two datasets. 
Dataset 1 contains 29435 S nodes and 15118 FRAG nodes (S-FRAG ratio of 1:0.513), while Dataset 2 
contains 2786 S nodes and 12102 FRAG nodes (S-FRAG ratio of 1:4.343).  

The 1,473 documents from these three hospitals were categorized according to their work types. It 
contained 535 documents of 25 work types from hospital A, 93 documents of 20 work types from hos-
pital B, and 845 documents of 14 work types from hospital C. These work types were grouped into three 
broader  categories  –  Admission,  Progress  and  Discharge.  So,  for  example,  worktypes  “History  and 
Physical”  and  “ER Physician  Document”  were  kept  under  the  ‘Admission’  category;  “Preprocedure 
Checklist” and “Anesthesia postoperative Note” were kept in ‘Progress’ category, and so on. Then, a 
certain number of documents were manually selected from each of the three categories, keeping in mind 
a balanced ratio of the original work types. The following Table 2 shows the number of documents 
selected from each hospital from each category. 

 

 

 
 

 

146 

 

 

Hospitals 
A 
B  
C  
All Hospitals 

Admission 
8 / 36 
4 / 16 
6 / 26 
18 / 78 

Progress 
42 / 457 
20 / 57 
50 / 775 
112 / 1289 

Discharge  Total 

10 / 42 
8 / 20 
8 / 44 
26 / 106 

60 / 535 
32 / 93 
64 / 845 
156 / 1473 

Table 2: Number and type of documents from each category included in Dataset 2 from Database 2 

After a simple algorithm to remove duplicate sentences, this process resulted in a dataset of 19,011 

unique sentences. 12,000 sentences were eventually selected from this source. 

The third sampling stage was done on the basis of ‘rare syntactic pattern’.  Low frequency patterns 
were extracted from the corpus compiled so far. These patterns were identified based on grammatical 
categories, keywords and subject to human judgment in the background of extended interaction with the 
domain. These patterns were then converted to regular expressions, which was used to extract similar 
sentences from Database 1 and 2. For example, sentences with wh-questions have a low distribution in 
clinical texts and were therefore left out during the sampling methods employed so far. These were 
added. Low frequency closed grammatical categories like prepositions were also added to the corpus. 
This method contributed to around 2,000 sentences. The Table 3 below is a summary of the corpus 
creation in the three steps. 
 

Dated  Method  

Dataset 

Source 

No. 
of 
Hospitals 
Database 1 
10 
Database 2 
3 
Database 1 +  2  13 
Total corpus 

 

2012-13 sub-domain selection + sentence clustering  (1) 38,000 sents 
2016 
(2) 12,000 sents 
sub-domain selection + duplicate removal 
(3) 20,53 sents 
2012-16 rare syntactic pattern + regular expression 
 
 52053 sents 

 

Table 3: Source databases, methods and resulting datasets 

3.2  Challenges in annotation 
The corpus was annotated for phrase structure following a customized version of the Penn Treebank 
guidelines (Bies et al., 1995). Null elements and function tags have not been incorporated at this point. 
This section discusses the data structures where deliberate and novel guidelines were adopted. 

3.2.1  Binary branching vs Tertiary branching 
 
Binary branching was adopted in post phrase structure syntactic theories viz. Government and Binding 
(Chomsky, 1993) and Minimalist Program (Chomsky, 1995). In the binary structure, the relations be-
tween parts of the sentences are expressed through hierarchy. This hierarchy is also crucial for the linear 
ordering of the sentence. However, there were many instances where binary branching could not be 
adopted.  For  example, 
therefore  conjunctive 
phrases/clauses/sentences or multiple elements inside the NP were kept in multiple branches, which 
extended beyond 3 tokens or more. For example, Figure (1) has four phrase branches because there are 
four different fragments conjoined by commas and a conjunctive word. Each branch has a composite 
meaning that does not have a hierarchical relationship with the others. The same is true for elements 
inside the noun phrase (NP). In clinical texts, an NP can have a token span of up to 5 and more. There 
is, again, no hierarchical relationship between NP internal elements. Figure (2) shows a typical NP in 
the clinical domain which contains numerals and symbols as part of the NP.  

in  conjunction  and 

is  no  hierarchy 

there 

 

 

147Figure 1: Multiple branch at the clause level 

 

Figure 2: Tertiary branch inside an NP 

 
Tertiary branching is also adopted for moved elements such as sentential adverbs and prepositional 
adjuncts that are topicalized. Other such data include section heads and list symbols that appear at the 
front of the phrase as shown in Figure (3)  

 

Figure 3: Tertiary branch in list items 

 

 
This shows that multiple branching is present at the highest clausal/sentential level as well as at the 
lowest phrase internal elements. Given that there is no theoretical limit to conjunction or NP internal 
elements (especially within this domain), there is no limit to the number of branches as well. 
 
3.2.2  Ambiguous categories 
 
Clinical text contains Latin abbreviations indicating manner of medical dosage or manner of action. We 
adopted a principle to annotate the abbreviation based on the syntactic category of its translation or the 
full-form. For example, ‘q. 8 h’ stands for ‘every 8 hours’ and therefore annotated as an NP. ‘IV’ is 
tagged as JJ (adjectival token) and does not have a maximal projection when it functions as an adjective 
in a phrase like ‘IV (intravenous) fluid’. However, it has a maximal projection ADVP (adverbial phrase) 
when it modifies a verb as in Figure (4). Beyond abbreviations, clinical texts also contain phrases like 
‘x 3’ which stands for ‘times 3’ in the context of the test results such as ‘test is negative/positive x 3’ or 
in the  context of  a  patient’s  condition  as  in  ‘the  patient is  oriented  x  3’. Such phrases  that  have  an 
adverbial flavor but do not explicitly function as adverbs are kept under NP. Such NPs are however 
post-modifiers of the preceding category and therefore they also form a maximal projection of their own 
as shown in Figure (5). 
 

 
                     Figure 4: ‘IV’ forms an ADVP node 

 

 

 Figure 5: ‘x 3’ labelled as NP 

 

148Another form of ambiguity in category arises in clinical texts due to a practice of omitting the head 
of the phrase. This creates a mismatch between the rightmost PoS tag (the head of the phrase) and the 
maximal category. This violates the ‘projection principle’ which states that ‘lexical structure must be 
represented categorically at every syntactic level’ (Chomsky, 1986).  However, this mismatch is delib-
erately maintained in our annotation for accuracy at the phrase level. For example, in Figure (6) ‘celiac’ 
stands for ‘celiac artery’ but the token ‘artery’ is absent. So, rightmost tag is JJ but the phrase label is 
kept as an NP. 

  

 

Figure 6: Mismatch between PoS and phrase labels 

 
3.2.3  Multi-level NPs 
 
Clinical data contains instances of multiple NPs modifying one another. We used right C-adjunction to 
account for these kinds of data. C-adjunction is a syntactic operation in which an element is added to 
the constituent of a category X by moving the element and adjoining it to a mother node above category 
X. Multi-level NP is peculiar to, as well as widely distributed in this domain. It is found mostly in the 
documentation of medical dosages. Each modifier such as the duration, manner or quantity is adjoined 
to the first NP as shown in Figure (7) below. 

 

 

 

 

Figure 7: Multi-level NP  

3.2.4  Multi-word Complementizer 

                   
 
Figure 8: Multi-word complementizer under COMP 

  

 

 

Complementizers/subordinators can be multi-words. This is a phenomenon not peculiar to the clinical 
domain but nevertheless inadequately addressed in theoretical syntax or annotation literature. Some ex-
amples of multi-word complementizers are ‘Even if’, ‘Whether or not’, ‘So that’, ‘As if’, ‘If and when’, 
‘Should if’ etc. To handle such words, we introduced the phrase label COMP which stands for Com-
plemtizer Phrase, a commonly used in generative syntax. This phrase layer is necessary for accurate 
representation of syntactic objects and syntactic relations. Projection principle (Chomsky, 1986) allows 
only one head to project. Without the COMP layer, it would appear that both lexical categories in a 
multi-word complementizer are projecting to be the head of the SBAR. The COMP layer enables only 
one head to project at the phrase level. 
 

3.2.5  FRAG  

FRAG is the label used for fragmented sentences/clauses that arise due to transcription errors, grammat-
ical errors or shorthand documentation. Its abundant occurrence in clinical health data creates much 
unwanted variation within the domain itself. The fragments however fall within identifiable patterns as 
follows: 
 

149