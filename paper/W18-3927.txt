Using Neural Transfer Learning for Morpho-syntactic Tagging of

South-Slavic Languages Tweets

Sara Meftah∗, Nasredine Semmar∗, Fatiha Sadat+, Stephan Raaijmakers∓

∗CEA, LIST, LVIC, F-91191, Gif-sur-Yvette, France

{sara.meftah, nasredine.semmar}@cea.fr

+UQ `AM, Montr´eal, Canada

sadat.fatiha@uqam.ca

∓TNO, The Hague, The Netherlands

stephan.raaijmakers@tno.nl

Abstract

In this paper, we describe a morpho-syntactic tagger of tweets, an important component of the
CEA List DeepLIMA tool which is a multilingual text analysis platform based on deep learning.
This tagger is built for the Morpho-syntactic Tagging of Tweets (MTT) Shared task of the 2018
VarDial Evaluation Campaign. The MTT task focuses on morpho-syntactic annotation of non-
canonical Twitter varieties of three South-Slavic languages: Slovene, Croatian and Serbian. We
propose to use a neural network model trained in an end-to-end manner for the three languages
without any need for task or domain speciﬁc features engineering. The proposed approach com-
bines both character and word level representations. Considering the lack of annotated data in
the social media domain for South-Slavic languages, we have also implemented a cross-domain
Transfer Learning (TL) approach to exploit any available related out-of-domain annotated data.

1

Introduction

Part-of-Speech (POS) tagging is one of the basic and indispensable tasks in any Natural Language Pro-
cessing (NLP) pipeline; it consists of assigning adequate and unique grammatical categories (Part-of-
Speech tags) to words in the sentence. When POS tags are enriched by Morpho-Syntactic Descriptions
(MSDs), such as gender, case, tenses, etc. the task is called Morpho-Syntactic Tagging (MST) (Agi´c et
al., 2013). As an example, we provide a Slovene sentence with its MS tags in Figure 1.

MST is a challenging task especially for languages with rich word inﬂections and free word order like
South-Slavic languages. In addition, MST of informal text like social media content of these languages
is a more complex task, especially conversational texts. This is due to the conversational nature of the
text, the lack of conventional orthography, the noise, linguistic errors, spelling inconsistencies, informal
abbreviations and the idiosyncratic style. Also, social media platforms such as Twitter pose an additional
issue by imposing 280 characters limit for each tweet.

While recent approaches based on end-to-end Deep Neural Networks (DNNs) have shown promising
results for sequence tagging in many languages such as English, much less work has been done on neural
models for MST of Slavic languages. In this paper, we evaluate the effect of using neural networks
techniques for MST of South-Slavic tweets, where we are faced with a large number of possible word-
class tags and only a small hand-tagged in-domain dataset.

NLP neural models with high performance often require huge volumes of annotated data to produce
powerful models and prevent over-ﬁtting. Consequently, in the case of social media content, it is difﬁcult
to achieve the performances of state-of-the-art models based on hand-crafted features by applying neural
models trained on small amounts of annotated data. For this reason, Transfer Learning (TL) was proposed
to exploit annotated out-of-domain data-sets. TL aims at performing a task on a target dataset using
features learned from a source dataset (Pan and Yang, 2010).

The method presented in this work aims to overcome the problem of the lack of annotated data by
signiﬁcantly limiting the necessary data and instead extrapolating the relevant knowledge from another,
related domain. This contribution generalizes previous results for POS tagging of user generated content

This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/.

ProceedingsoftheFifthWorkshoponNLPforSimilarLanguages,VarietiesandDialects,pages235–243SantaFe,NewMexico,USA,August20,2018.235in social media for ﬁve languages: English, French, Italian, German and Spanish (Meftah et al., 2018),
by applying our approach on three Twitter corpora of South-Slavic languages: Slovene, Croatian, and
Serbian.

Figure 1: Example of a morphologically-tagged sentence in Slovene: To ni nobena novost (”This is not
a novelty” in English) .

2 The Model

In this section, we introduce the model we experimented for MS tagging of South-Slavic languages. The
model takes as input a tweet T , separated into a succession of n tokens wi, such as T = {w1, w2, ..., wn}.
The objective is to predict the morpho-syntactic tag ˆyi for each token wi of the tweet.

2.1 System Architecture
We use a similar architecture to that used in (Meftah et al., 2018) for English, French, Spanish, Italian and
German Social Media content’s POS tagging, we propose to use a bi-GRU (bidirectional Gated Recurrent
Unit) sequence labelling model, preceded by a hybrid word representation. The model architecture is the
same among all languages and tasks (Figure 3).

2.1.1 Words Representation
The model learns word-level wei and character-level cei representations respectively for each token xi,
and combines them to get the ﬁnal representation xi.

Character level embedding: To capture morphological features, instead of Convolutional Neural
Networks (CNNs) used in our previous work (Meftah et al., 2018), we apply in this work a bi-GRU
encoder on all characters of each token to induce fully context sensitive character level embedding.

Figure 2 shows the character-level embedding model, a word wi is divided into a succession of l
characters ci, each deﬁned as a one-hot vector, with value 1 at index ci and 0 in all other dimensionality,
such as wi will be represented with a v×l dimensional matrix. Next it’s embedded into a d×l dimensional
matrix, where v is the character’s vocabulary size of the training set, l is the maximal length of words and
d is the character embedding’s dimension. Next, a forward GRUs model reads the character vectors from
left to right and a backward GRUs model reads characters from right to left. The combination between
the last hidden state of the forward GRUs and the last hidden state of the backward GRUs represents cei:
the character level embedding for the word wi.

Word-level embedding: we initialize words vectors wei with FastText (Bojanowski et al., 2016) word

embeddings to accurately capture words’ semantics.

The combination between character-level embedding and word-level embedding xi is fed into the

bi-GRUs layer.

2.1.2 Bidirectional Gated Recurrent Units
Word vectors {x1, x2, ..., xn}, which are constructed as a combination of word-level embeddings and
character-based representations, are given as input to a 100-dimension bi-GRUs layer which iteratively
−→
ht be the GRUs hidden state at time-step t. Formally,
passes through the sentence in both directions. Let
−−→
a forward GRUs model’s unit at a time-step t takes xt and the previous hidden state
ht−1 as input, and
−→
ht. Each GRUs apply the following transformations:
outputs the current hidden state

236Figure 2: Bi-GRUs layer for character-level embedding.

−→rt = σ(Wrxxt + Wrh
−→zt = σ(Wzxxt + Wzh

−−→
ht−1)
−−→
ht−1)

−→
ˆht = tanh(Whxxt + Whh(−→rt ⊗ −−→
ht−1))
ht−1 + (1 − −→zt ) ⊗ −→
−→
ht = −→zt ⊗ −−→
ˆht

(1)

(2)

(3)

(4)
Here, W’s are model parameters of each unit, ˆht is a candidate hidden state that is used to compute ht,
σ is an element-wise sigmoid logistic function deﬁned as σ(x) = 1/(1 + e−x), and ⊗ denotes element-
wise multiplication of two vectors. The update gate zt controls how much the unit updates its hidden
state, and the reset gate rt determines how much information from the previous hidden state needs to be
reset.
−→
ht and
←−
ht from forward and backward units, respectively, are concatenated at every token position, resulting ht
vectors.

In order to take into account the context on both sides of that word, hidden representations

−→
ht;

ht = [

←−
ht]

(5)

2.1.3 Sequence Labelling
Hidden representations at each time-step are fed through a 80 dimension Fully Connected Layer (FCL)
with a ReLU activation, followed by a ﬁnal dense layer with a softmax activation to generate a probability
distribution over the output classes at each time-step.

3 Neural Transfer Learning Methodology

Neural transfer learning is applied to address the problem of the need for annotated data for morpho-
syntactic tagging of social media texts.
It consists of learning a parent neural network on a source
problem with enough data, then transferring a part of its weights to represent data of a target problem
with few training examples.

In this work, we experiment with cross-domain transfer; knowledge is transferred from a source do-
main to a target domain. In our case, the source domain is a standard text corpus of a language and the

237Figure 3: Overall system architecture. First, the system embeds each word of the current sentence into
two representations: a character-level representation using bi-GRUs and a word-level representation.
Then, the two representations are combined and fed into a bi-GRUs layer, the resulting vector is fed to a
fully connected layer and ﬁnally a softmax layer to perform MS tagging.

target domain is the Twitter text of the same language. The source and the target problems are trained
for the same task (MST), even if source and target data-sets do not share the same tag-set.

sets: θp = (θ1

p, θ2

p), and a child network Nc with a set of parameters θc split into two sets: θc = (θ1

As illustrated in Figure 4, we have a parent neural network Np with a set of parameters θp split into two
c ).
c , θ2
(1) We learn the parent network on annotated data from the source problem on a source dataset Ds.
(2) We transfer weights of the ﬁrst set of parameters of the parent network Np to the child network

Nc: θ1

p.
c = θ1

(3) Then, the child network is ﬁne-tuned to the target problem by training it on the target data-set Dc.

Figure 4: Cross-domain transfer learning scheme for morpho-syntactic tagging.

238Language Domain

Corpus Tag-set size

# Sentences

Slovene

Croatian

Serbian

Out of domain All
Train
In
Dev
domain
Test
Out of domain All
Train
In
Dev
domain
Test
Out of domain All
In
domain

Train
Dev
Test

1,304
758
422
598
772
580
363
487
557
575
385
498

27,829
3,934
713
2023
24,611
4,089
791
1,883
3891
3463
737
1,684

# Tokens
586,248
37,756
7,056
19,296
506,460
45,609
8,886
21412
86765
45,708
9581
23327

Table 1: Statistics of the different source and target data-sets.

4 Experiments Setup
4.1 Task and Data Description
Two types of data-sets were provided in the MTT shared task (Zampieri et al., 2018) for each language:
(1) a small manually annotated Twitter data-set (in-domain data) (Erjavec et al., 2017; Ljubeˇsi´c et al.,
2017a; Ljubeˇsi´c et al., 2017b); (2) a large manually annotated raw canonical data-set (out-of-domain
data) (Erjavec et al., 2015; Ljubeˇsi´c and Klubiˇcka, 2014)1.

The statistics of the data-sets are described in table 1. All corpora are in the CoNLL format. They are
already tokenized. Each token in a tweet is associated with a single morpho-syntactic tag using different
alphabetical characters for denoting different category values. The ﬁrst letter represents POS tag, while
other tag positions represent morpho-syntactic categories like case, genre, etc. For instance, the MS tag
Ncfsn of the word novost in the example, provided in ﬁgure 1, would denote a noun, common, feminine,
singular, nominative token.

4.2 Transfer Learning Experiments
Cross-domain TL is evaluated on the three languages: Slovene, Serbian and Croatian, following three
main phases: (1) training the parent network on the source problem on rich out-of-domain data, (2)
transferring weights of the ﬁrst set of parameters to the target problem (these weights are used to initialize
the child model’s ﬁrst set of parameters, rather than starting from a random position2), and ﬁnally (3)
ﬁne-tuning the child network on low-resource in-domain data.
Our experiments have shown that using a smaller learning rate for weights that will be ﬁne-tuned (ﬁrst set
of weights), in comparison to the randomly initialized weights (second set of weights) leads to slightly
improvements.

Implementation Details

4.3
All experiments described in this section are implemented using the PyTorch deep learning library. We
use the Stochastic Gradient Descent (SGD) optimizer with momentum of Nesterov (Sutskever et al.,
2013) in all experiments. We set the character embedding dimension at 50, the dimension of hidden
states of the character level embeddings GRUs layer at 80, 100 for sequence labelling GRUs layer and
FCL dimension at 80. We use dropout training with probability 0.3 before the input to GRUs and FCL
layers in order to avoid overﬁtting.

Tokens are lowercased while the character-level component still retains access to the capitalization
information. Word embeddings were set to size 300, pre-loaded from publicly available FastText pre-
trained vectors on common crawl3. Word level embeddings are ﬁne-tuned during training. The training
was performed in batches of 64 sentences for parent models training and 32 sentences for child networks

1A large automatically annotated web data was also provided by the shared task organizers, but we did not make use of it in

this work.

2The weights of the second set of parameters of the child model are randomly initialized.
3https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md

239training, and was stopped if development set accuracy did not improve for 4 epochs. The best overall
model on the development set was then used to report performance on the test data.
5 Results
In this section, we report the results of our system described in section 3. Firstly, we report the results of
our system submitted to the MTT shared task. Thereafter, we present some improvements done on our
model after the submission of the results for this task.

Language
Acc. without transfer learning (%)
Acc. with transfer learning - A (%)
Acc. with transfer learning - B (%)

Slovene Croatian

Serbian

79.8
82.6
83.36

80.3
82.9
83.87

81.2
82.1
82.54

Table 2: Our system accuracy (acc.) with and without cross-domain transfer learning (A represents the
results of the system submitted to the shared task, and B an improved performance after the submission).

In Table 2, we compare the performances of the neural network model described in section 3 trained
only on target data-set (ﬁrst line) against the neural network trained with TL (second line). We can see
that the TL method signiﬁcantly improves results on all languages. Table 2 further shows that the im-
provements made by cross-domain TL for Slovene and Croatian (+2.8% , +2.7% ) are more important
than improvements made by cross-domain TL for Serbian (+0.9%). This phenomenon can be explained
by the fact that as illustrated in Table 1, the source data-set for Serbian experiments is very small com-
pared to source data-sets for Slovene and Croatian, hence the improvement is less substantial.

In the above experiments submitted to the MTT shared task, we transfer the parameters of the parent
network when they achieve the highest performance on development set of the out-of-domain data-set.
However, as shown in previous studies on TL (Mou et al., 2016), the parameters perfectly trained on
a source data-set may be too speciﬁc to it, hence, the model may underﬁt on the target data-set. We
therefore made more experiments to pick the parent model trained on the ideal epoch for the target data-
sets for further ﬁne-tuning. In the third line in table 2, we give the highest performance of TL on target
data-sets.
6 Discussion
6.1 Ablation Study
In order to assess the importance of embeddings to handle the problem of Out Of Vocabulary words
(OOVs), we have conducted a series of experiments through ablating one layer each time, character-
level embedding and word-level embedding and observing how that affects the performance.

For these experiments, we use the neural model described in section 2 without TL technique (i.e., only

in-domain data).

In table 3, we report the results of our experiments on Slovene data-set. In each column, we provide
the results on a different set of tokens. In the ﬁrst, we used all tokens of the test set, in the second,
only In Training Vocabulary words (ITVs), i.e words that have been seen in the training set, in the third,
Out Of Training vocabulary words (OOTVs), in the fourth, In Embedding Vocabulary words (IEVs), i.e
words that have been found in the FastText pre-trained words vectors, and in the ﬁfth, Out Of Embedding
Vocabulary words (OOEVs).

We provide for each set of tokens, the number of tokens in the ﬁrst line, the vocabulary size in the
second, the simple neural model’s accuracy in the third, the accuracy of the neural network without
character-level embedding in the fourth and the accuracy of the neural network without pretrained word-
level embedding (i.e, words embeddings are randomly initialized) in the ﬁfth.

We notice in table 3 a signiﬁcant gap between the overall accuracy on ITVs (89.78%) and the accuracy
on OOTVs (45.92%). We can also see that removing character-level embedding drops signiﬁcantly the
overall accuracy (-7%). However, the accuracy on OOTVs drops by 27% (33.40% error reduction)
while the one for ITVs drops only by 1.5% (13.7% error reduction), which conﬁrms the effectiveness of
character-level embedding on OOTVs.

240# tokens
Vocabulary size
Neural model (NM) acc. (%)
NM without character embedding acc. (%)
NM without pre-trained words embedding acc. (%)

All tokens

19,296
6,538
79.8
72.16
76.42

ITVs
14,828
2,400
89.78
88.23
88.67

OOTVs
4.468
4,138
45.92
18.80
36.05

IEVs
17,045
4,850
80.86
74.23
77.88

OOEVs
2,251
1,688
70.27
56.46
65.97

Table 3: Ablation study on character-level embedding and pre-trained words embedding for Slovene
tweets MS tagging.

Impact of Transfer Learning

6.2
In the experiments below, we are interested on the impact of using TL on Slovene data-set. In table 4,
we compare the performance of our model on the full MSD features and the performance on only POS
tags. The ﬁrst two columns give token-level and the sentence-level accuracy without using TL, and the
second two columns give token-level and the sentence-level accuracy using TL. The ﬁrst line shows the
accuracies on all MSD features (the overall accuracy), the second one gives the accuracies on only POS
tags.

Table 4 shows that POS accuracy is quite high compared to the full accuracy, this is due to the small
POS tag-set (13 POS tags). In addition to that, POS ambiguity of Slovene words is relatively low con-
versely to the other MSD features. We can observe an improvement of 4.56% brought by TL on the
token-level full accuracy, and 2.16% on POS tags. This means that 50% of the error reduction made by
TL was on POS tags.

Without transfer learning

With transfer learning

Token acc. (%)

Sentence acc. (%) Token acc. (%)

Sentence acc. (%)

All MSD features
Only POS Tags

79.8
89.55

27.92
45.72

83.36
91.71

33.61
53.97

Table 4: Comparison between our model accuracy on Slovene on the full MSD features and on POS tags.

Table 5 gives the results for the Slovene data-set ﬁrst tagged without TL and then using TL. The ﬁrst
two columns give the numbers and the percentage of tokens that have their POS tags changed by the
model using TL compared to the model without TL, and the second two columns give the numbers and
the percentage of tokens with changed morpho-syntactic tags (including POS tags). The ﬁrst line shows
the tags that were wrong, but the TL changed to the correct ones, the second gives the numbers of those
tokens which the standard neural network tagged correctly, but the TL technique falsiﬁed. The third
line shows those instances where the tag was not changed by the TL technique. The last line shows the
number of tokens that have tag assigned that was subsequently changed by the TL technique into a wrong
tag.

# Token

POS tags

Percentage (%)

Corrected
Falsiﬁed
Identical
Confused

949
532

17,459

356

4.91
2.75
9047
1.84

Morphosyntactic descriptions
# Token
1,402
682

Percentage (%)

7.26
3.53
81.82
7.37

15,789
1,423

Table 5: Modiﬁcations made by transfer learning on Slovene data-set.

We can observe that 7.26% of MSD tags were corrected by the TL technique and 3.53% were falsiﬁed.
In table 6, we investigate which POS tags have beneﬁted the most from the cross-domain TL technique.
The ﬁrst column presents the number of tokens of each POS tag on the test-set, the second (the third) set
of columns gives the accuracy, number of true positives (TP), number of false negatives (FN) and false
positives without using TL (with TL). We can observe a signiﬁcant accuracy improvement on adjectives
(+10%), nouns (+6%) and adverbs (+2%), with a drop of accuracy on abbreviations and interjections
(-8%).

241Without transfer learning

With transfer learning

POS tags

# tokens Accuracy (%)

X (Residual)
Q (Particle)
R (Adverb)

Z (Punctuation)

N (Noun)
V (Verb)

P (Pronoun)

C (Conjunction)
A (Adjective)
S (Adposition)
Y (Abbreviation)

M (Numeral)
I (Interjection)

1782
1011
1548
2872
2808
3427
1652
1571
852
1096
107
334
236

88.10
89.02
85.01
99.68
79.98
92.64
88.68
96.37
69.71
96.98
87.85
89.82
76.69

# TP
1570
900
1316
2863
2246
3175
1465
1514
594
1063
94
300
181

# FN # FP Accuracy (%)
212
111
232
9
562
252
187
57
258
33
13
34
55

90.62+
89.61+
87.33+
99.75+
86.36+
94.28+
90.25+
96.05-
79.34+
97.71+
86.91-
90.41+
68.64-

150
78
265
6
551
357
149
59
281
33
23
22
41

# TP
1615
906
1352
2865
2425
3231
1491
1509
676
1071
93
302
162

# FN # FP
217
167
88
105
211
196
5
7
383
379
245
196
129
161
49
62
151
176
25
25
30
14
34
32
74
35

Table 6: The impact of transfer learning on POS tags prediction on Slovene data-set.

6.3

Improvements when Using Conditional Random Fields

In this section, we report new improvements of the performance of our model after the submission to
the MTT shared task. Instead of using a softmax function in the topmost of the model for inference (MS
tagging), as described in the section 2, we use Conditional Random Fields (CRFs) (Lafferty et al., 2001)
layer to decode the best tag sequence from all possible tag sequences with consideration of outputs from
bi-GRUs layer and correlations between surroundings labels.

Indeed, it has been shown that CRFs are more appropriate for sequence labelling tasks and can produce
higher performances (Huang et al., 2015; Ma and Hovy, 2016). Table 7 shows a signiﬁcant improvement
on the performances of our system for all languages, by replacing the softmax function by a CRFs layer
(Ma and Hovy, 2016).

Model + softmax acc. (%)
Model + CRFs acc. (%)

Slovene Croatian
83.36
86.23

83.87
87.47

Serbian
82.54
86.4

Table 7: Comparison between the model’s performances using Softmax and CRFs layers.

7 Conclusion

In this paper, we have presented a neural network model using Transfer Learning (TL) for Morpho-
syntactic (MS) tagging of Twitter texts.
In particular, we have conducted experiments on tweets for
three South-Slavic languages: Slovene, Croatian and Serbian. We have more speciﬁcally used an ap-
proach which combines both character and word level representations. The obtained results show that
TL improves the performance of the MS tagging task for the three involved languages.

This work leaves two important open issues, which certainly deserve further research. First, we intend
to apply our model to other morphologically rich languages like MSA and its dialects. The second
perspective consists in modelling the lexical and syntactic similarities between the source and target
languages (domains) in order to incorporate this external linguistic knowledge in the neural network
model.

8 Acknowledgments

This research work is supported by the ASGARD project. This project has received funding from the
European Unions Horizon 2020 research and innovation programme under grant agreement No 700381.

242References
ˇZeljko Agi´c, Nikola Ljubeˇsi´c, and Danijela Merkler. 2013. Lemmatization and morphosyntactic tagging of croat-
ian and serbian. In Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language
Processing, pages 48–57.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016. Enriching word vectors with

subword information. arXiv preprint arXiv:1607.04606.

Tomaˇz Erjavec, Nikola Ljubeˇsi´c, and Nataˇsa Logar. 2015. The slWaC Corpus of the Slovene Web. Informatica,

39(1):35–42.

Tomaˇz Erjavec, Darja Fiˇser, Jaka ˇCibej, ˇSpela Arhar Holdt, Nikola Ljubeˇsi´c, and Katja Zupan. 2017. CMC

training corpus janes-tag 2.0. Slovenian language resource repository CLARIN.SI.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint

arXiv:1508.01991.

John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random ﬁelds: Probabilistic

models for segmenting and labeling sequence data.

Nikola Ljubeˇsi´c and Filip Klubiˇcka. 2014. {bs,hr,sr}wac - web corpora of bosnian, croatian and serbian. In Pro-
ceedings of the 9th Web as Corpus Workshop (WaC-9), pages 29–35. Association for Computational Linguistics.

Nikola Ljubeˇsi´c, Tomaˇz Erjavec, Maja Miliˇcevi´c, and Tanja Samardˇzi´c. 2017a. Croatian twitter training corpus

ReLDI-NormTagNER-hr 2.0. Slovenian language resource repository CLARIN.SI.

Nikola Ljubeˇsi´c, Tomaˇz Erjavec, Maja Miliˇcevi´c, and Tanja Samardˇzi´c. 2017b. Serbian twitter training corpus

ReLDI-NormTagNER-sr 2.0. Slovenian language resource repository CLARIN.SI.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint

arXiv:1603.01354.

Sara Meftah, Nasredine Semmar, and F Sadat. 2018. A neural network model for part-of-speech tagging of social
media texts. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation,
LREC 2018, Miyazaki, Japan, May 7-12, 2018.

Lili Mou, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, and Zhi Jin. 2016. How transferable are neural

networks in nlp applications? arXiv preprint arXiv:1603.06111.

Sinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Transactions on knowledge and data

engineering, 22(10):1345–1359.

Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. 2013. On the importance of initialization and

momentum in deep learning. In International conference on machine learning, pages 1139–1147.

Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Ahmed Ali, Suwon Shon, James Glass, Yves Scherrer, Tanja
Samardˇzi´c, Nikola Ljubeˇsi´c, J¨org Tiedemann, Chris van der Lee, Stefan Grondelaers, Nelleke Oostdijk, Antal
van den Bosch, Ritesh Kumar, Bornini Lahiri, and Mayank Jain. 2018. Language Identiﬁcation and Mor-
phosyntactic Tagging: The Second VarDial Evaluation Campaign. In Proceedings of the Fifth Workshop on
NLP for Similar Languages, Varieties and Dialects (VarDial), Santa Fe, USA.

243