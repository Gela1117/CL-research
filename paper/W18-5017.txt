Unsupervised Counselor Dialogue Clustering for Positive Emotion

Elicitation in Neural Dialogue System

Nurul Lubis, Sakriani Sakti, Koichiro Yoshino, Satoshi Nakamura

Information Science Division,

{nurul.lubis.na4, ssakti, koichiro, s-nakamura}@is.naist.jp

Nara Institute of Science and Technology, Japan

Abstract

Positive emotion elicitation seeks to im-
prove user’s emotional state through di-
alogue system interaction, where a chat-
based scenario is layered with an im-
plicit goal
to address user’s emotional
needs. Standard neural dialogue system
approaches still fall short in this situa-
tion as they tend to generate only short,
generic responses. Learning from expert
actions is critical, as these potentially dif-
fer from standard dialogue acts. In this pa-
per, we propose using a hierarchical neu-
ral network for response generation that is
conditioned on 1) expert’s action, 2) di-
alogue context, and 3) user emotion, en-
coded from user input. We construct a
corpus of interactions between a counselor
and 30 participants following a negative
emotional exposure to learn expert actions
and responses in a positive emotion elici-
tation scenario. Instead of relying on the
expensive, labor intensive, and often am-
biguous human annotations, we unsuper-
visedly cluster the expert’s responses and
use the resulting labels to train the net-
work. Our experiments and evaluation
show that the proposed approach yields
lower perplexity and generates a larger va-
riety of responses.

Intoduction

1
Emotionally intelligent systems has high poten-
tial as assistive technology in various affective
tasks, such as caring for the elderly, low-cost ubiq-
uitous chat therapy, or providing emotional sup-
port in general. Two of the most studied emo-
tional competences for agents are emotion recog-
nition, which allows a system to discern the user’s

emotions and address them in giving a response
(Forbes-Riley and Litman, 2012; Han et al., 2015;
Tielman et al., 2014), and emotion simulation,
which helps convey non-verbal aspects to the user
for a more believable and human-like interaction,
for example to show empathy (Higashinaka et al.,
2008) or personality (Egges et al., 2004). Acosta
and Ward (2011) have attempted to connect the
two competences to build rapport, by recogniz-
ing user’s emotion and reﬂecting it in the sys-
tem response. Although these competences ad-
dress some of the user’s emotional needs (Picard
and Klein, 2002), they are not sufﬁcient to provide
emotional support in an interaction.

Recently, there has been an increasing inter-
est in eliciting user’s emotional response via di-
alogue system interaction, i.e. emotion elicitation.
Skowron et al.
(2013) have studied the impact
of different affective personalities in a text-based
dialogue system, while Hasegawa et al.
(2013)
constructed translation-based response generators
with various emotion targets. Despite the positive
results, these approaches have not yet paid atten-
tion to the emotional beneﬁt for the users. Our
work aims to draw on an important overlooked po-
tential of emotion elicitation: its application to im-
prove emotional states, similar to that of emotional
support between humans. This can be achieved
by actively eliciting a more positive emotional va-
lence throughout the interaction, i.e. positive emo-
tion elicitation. This takes form as a chat-oriented
dialogue system interaction that is layered with an
implicit goal to address user’s emotional needs.

With recent advancements in neural network re-
search, end-to-end approaches have been reported
to show promising results for non-goal oriented
dialogue systems (Vinyals and Le, 2015; Serban
et al., 2016; Nio et al., 2016). However, appli-
cation of this approach towards positive emotion
elicitation is still very lacking. Zhou et al. (2017)

ProceedingsoftheSIGDIAL2018Conference,pages161–170,Melbourne,Australia,12-14July2018.c(cid:13)2018AssociationforComputationalLinguistics161have investigated 6 categories to emotionally color
the response via the internal state of the decoder.
However, this study has not yet considered user’s
emotion in the response generation process, nor
attempted improve emotional experience of user.
Towards positive emotion elicitation, Lubis et
al.
(2018) have recently proposed a model that
encodes emotion information from user input and
utilizes it in generating response. However, the re-
sulting system is still limited to short and generic
responses with positive affect, echoing the long
standing lack-of-diversity problem in neural net-
work based response generation (Li et al., 2016).
Furthermore, the reported system has not learn
about positive emotion elicitation strategies from
an expert as the corpus construction relied on
crowd-sourcing workers.

This points to another problem: the lack of data
that shows positive emotion elicitation or emotion
recovery in everyday situations. Learning from
expert responses and actions are essential in such
a scenario as these potentially differ from standard
chat-based scenarios. With scarcity of large-scale
data, additional knowledge from higher level ab-
straction, such as dialogue action labels, may be
highly beneﬁcial. However, such high-level infor-
mation must rely on human annotations, which are
expensive, labor intensive, and often ambiguous.
To answer these challenges, ﬁrst, we construct
a corpus containing recordings of a professional
counselor and 30 participants in a positive emotion
elicitation scenario. Second, we extract higher
level information from the expert’s responses via
unsupervised clustering and use the resulting la-
bels to train a neural dialogue system. Lastly,
we propose a hierarchical neural dialogue system
which considers 1) expert’s action, 2) dialogue
context, and 3) user emotion, in generating a re-
sponse by encoding them from user input. Our
evaluations show that the proposed method yields
lower perplexity, elicits a positive emotional im-
pact, and generates longer responses that improves
subjective engagement.

2 Corpus Construction: Positive

Emotion Elicitation by an Expert

Even though various affective conversational sce-
narios have been considered (McKeown et al.,
2012; Gratch et al., 2014), there is still a lack of re-
sources that show common emotional problems in
everyday social settings. Furthermore, a great ma-

jority of existing corpora does not involve any pro-
fessional who is an expert in handling emotional
reactions in a conversation.

To ﬁll these gaps, we design our corpus to 1)
contain recordings of spontaneous dyadic interac-
tions before and after a negative emotion exposure,
and 2) involve a professional counselor as an ex-
pert. In each interaction, a negative emotion in-
ducer is shown to the dyad, and the goal of the
expert is to aid emotion processing and elicit a
positive emotional change through the interaction.
From this point, we will refer to this corpus as the
counseling corpus.

2.1 Negative Emotion Inducer
To induce negative emotion, we opt for short video
clips which are a few minutes in length. This
method is well established and has been studied
for several decades (Gross and Levenson, 1995;
Schaefer et al., 2010). One study shows that
amongst a number of techniques, the use of video
clips is the most effective way to induce both pos-
itive and negative emotional states (Westermann
et al., 1996).
It also offers easy replication in
constrained environmental settings, such as the
recording room.

However, in contrast to previous works (Schae-
fer and Philippot, 2005), we look for clips that de-
pict real life situations and issues, i.e., non-ﬁction
and non-ﬁlms. We select short video clips of
news reports, interviews, and documentary ﬁlms
as emotion inducers to avoid the unpredictability
of subjective emotional response to ﬁctional clips.
Non-ﬁctional inducer also reﬂects real everyday
situations better. We ensure that the clips contain
enough information and context to serve as con-
versation topic throughout the recording session.
We target two emotions with negative valence:
anger and sadness. First, we manually selected 34
of videos with varying relevant topics that are pro-
vided freely online. Two human experts are then
asked to rate them in terms of intensity and the in-
duced emotion (sadness or anger). Finally, we se-
lected 20 videos, 10 of each emotion with varied
intensity level where the two human ratings agree.

2.2 Data Collection
We arrange for the dyad to consist of an expert and
a participant, each with a distinct role. The roles
are based on the “social sharing of emotion” sce-
nario, which argues that after an emotional event,
a person is inclined to initiate an interaction which

162centers on the event and their reactions to it (Rime
et al., 1991; Luminet IV et al., 2000). This form of
social sharing is argued to be integral in process-
ing the emotional event (Rime et al., 1991).

In the interactions, the expert plays the part of
the external party who helps facilitate this process
following the emotional response of the partici-
pant. We recruit a professional counselor as the
expert in the recording, an accredited member of
the British Association for Counseling and Psy-
chotherapy with more than 8 years of professional
experience. As participants, we recruit 30 individ-
uals (20 males and 10 females) that speak English
ﬂuently as ﬁrst or second language.

A session starts with an opening talk as a neu-
tral baseline conversation. Afterwards, we induce
negative emotion by showing an emotion inducer
to the dyad. This is followed by a discussion that
targets at emotional processing and recovery, dur-
ing which the expert is given the objective to facil-
itate the processing of emotional response caused
by the emotion induction, and to elicit a positive
emotional change.

In total, we recorded 60 sessions of interactions,
30 with “anger” inducer and 30 with “sadness”.
The combined duration of all sessions sums up to
23 hours and 41 minutes of material. The audio
and video recordings are transcribed, including a
number of special notations for non-speech sounds
such as laughter, back-channels, and throat noise.

2.3 Emotion Annotation
We follow the circumplex model of affect (Russell,
1980) in annotating emotion occurrences in the
recordings. Two dimensions of emotion are de-
ﬁned: valence and arousal. Valence measures the
positivity or negativity of emotion; e.g., the feeling
of joy is indicated by positive valence while fear
is negative. On the other hand, arousal measures
the activity of emotion; e.g., depression is low in
arousal (passive), while rage is high (active).

For each recording, the participants self report
their emotional state using the FEELtrace system
(Cowie et al., 2000) immediately after the inter-
action. While an annotator is watching a target
person in a recording, he or she is moving a cursor
along a linear scale on an adjacent window to indi-
cate the perceived emotional aspect (e.g., valence
or arousal) of the target. This results in a sequence
of real numbers ranging from -1 to 1 with a con-
stant time interval, called a trace. Statistical anal-

yses of validation experiments have conﬁrmed the
reliability and indicated the precision of the FEEL-
trace system (Cowie et al., 2000).

2.4 Dialogue Triples
Throughout the study and experiments, we uti-
lize the dialogue triple format, i.e. a sequence
of three dialogue turns.
It has been previously
utilized for considering dialogue context (Sordoni
et al., 2015), ﬁltering multi-party conversation
(Lasguido et al., 2014), and observing emotion ap-
praisal (Lubis et al., 2017). In this study, we ex-
ploit it to provide both past and future contexts of
an emotion occurrence

We extend and adapt the two-hierarchy view of
dialogue (Serban et al., 2016). We view a dia-
logue D as a sequence of dialogue turns of arbi-
trary length M between two speakers, i.e. D =
{U1, ..., UM}. Each utterance in the m-th dialogue
turn is a sequence of tokens of arbitrary length
Nm, i.e. Um = {wm,1, ..., wm,Nm}. In a triple,
D = {U1, U2, U3}, where U1 and U3 are uttered
by speaker A, and U2 by speaker B. In particu-
lar, we are interested in triturns with counselor-
participant-counselor speaker sequence. It is prac-
tical to view U1, U2, and U3 as dialogue context,
query, and response, respectively. U1 and U3 are
the contexts of the emotion occurrence in U2.

We deﬁne the end of a dialogue turn as either
1) natural end of the sentence, or 2) turn taking
by the other speaker, whichever comes ﬁrst. Back
channels in the middle of a speaker’s utterance are
not considered as turn taking since they instead
signal active listening. This also prevents overly
fragmented dialogue turns. The backchannels are
instead appended into the next dialogue turn once
one of the criteria above is met. We extract a total
of 6,064 dialogue triples from the collected data.
All U2 are aligned with self-report emotion anno-
tation by the participants.

3 Recurrent Encoder-Decoder for

Dialogue Systems

A recurrent neural network (RNN) is a neural net-
work variant that can retain information over se-
quential data. In response generation, ﬁrst, an en-
coder summarizes an input sequence into a vec-
tor representation. An input sequence at time t
is modeled using the information gathered by the
RNN up to time t − 1, contained in the hidden
state ht. Afterwards, a decoder recurrently pre-

163dicts the output sequence conditioned by ht and
its output from the previous time step. This archi-
tecture was previously proposed as neural conver-
sational model in (Vinyals and Le, 2015).

Based on the two-hierarchy view of dia-
logue, the hierarchical recurrent encoder-decoder
(HRED) extends the sequence-to-sequence archi-
tecture (Serban et al., 2016). It consists of three
RNNs. An utterance encoder recurrently pro-
cesses each token in the utterance, encoding it into
a vector respresentation hutt. This information
is then passed on to the dialogue encoder, which
encodes the sequence of dialogue turns into hdlg.
The utterance decoder, or the response generator,
takes hdlg, and then predicts the probability distri-
bution over the tokens in the next utterance.

Recently, the HRED architecture has been ex-
tended to Emo-HRED for the positive emotion
elicitation task, exploiting the hierarchical view of
dialogue to observe the conversational context of
an emotion occurrence (Lubis et al., 2018). Emo-
HRED incorporates an emotion encoder which
predicts user emotional state and passes this in-
formation to the response generation process. The
emotion encoder is placed in the same hierarchy
as the dialogue encoder, capturing emotion infor-
mation at dialogue-turn level hemo and maintain-
ing the emotion context history throughout the di-
alogue.
Improved naturalness and a more posi-
tive emotional impact were reported in the eval-
uations of Emo-HRED, however the resulting sys-
tem is still limited to short and generic responses
with positive affect. This echoes the long standing
lack-of-diversity problem in neural network based
response generation (Li et al., 2016), which is also
shared by other models previously discussed.

4 Proposed Method
4.1 Unsupervised Clustering of Counselor

Dialogue

In constructing an emotionally intelligent system,
learning from expert actions and responses are es-
sential. Although statistical learning from raw
data has been shown to be sufﬁcient in some cases,
it might not be so for positive emotion elicitation
task. Due to the absence of large scale data, ad-
ditional knowledge from higher level abstraction,
such as dialogue action labels, may be highly ben-
eﬁcial. We hypothesize that these labels will re-
duce data sparsity by categorizing counselor re-
sponses and emphasizing this information in the

training and generation process.

However, procuring such labels is not a trivial
task. Human annotation is not a practical solu-
tion as it is expensive, time-consuming, and la-
bor intensive. Especially with subjective aspects
such as dialogue act labels, they are often less reli-
able due to low annotator agreement. On the other
hand, training an automatic classiﬁer from data
with standard dialogue act labels will not cover ac-
tions with speciﬁc emotion-related intent that are
present in the collected data. For example, em-
pathy towards negative affect (“That’s sad.”) and
positive affect (“I’m happy to hear that.”).

We propose unsupervised clustering of coun-
selor dialogue to obtain dialogue act labels of ex-
pert responses. We collected a total of 6384 coun-
selor utterances from the counseling corpus. We
transform the utterances into vectors by obtain-
ing the embeddings of the words in the utterance
and averaging them. We use a word2vec model
pretrained on 100 billion words of Google News
(Mikolov et al., 2013). The word and utterance
embeddings are of length 300. We then apply two
clustering methods to the vectorized utterances:
K-Means and Dirichlet process Gaussian mixture
model (DPGMM).

With K-means, we perform hierarchical cluster-
ing, starting with an initial K of 8. We perform
K-means clustering the second time on the clus-
ters which are larger than half the full data size.
In contrast, DPGMM is a non-parametric model,
i.e. it attempts to represent the data without prior
deﬁnition of the model complexity. We use the
stick-breaking construction for the DPGMM. A
new data point would either join an existing cluster
or start a new cluster following some probabilities.
We use diagonal covariance matrices to compen-
sate for the limited amount of data. Henceforth,
we refer to the result of the clustering as cluster
label.

Cluster Analysis
We visualize the found clusters using T-SNE in
Figure 1. K-Means clustering shows distinct di-
alogue acts characteristic in a number of clus-
ters it found. For example, cluster 0 in Figure
1(a) consists of various utterances signaling ac-
tive listening, such as follow up questions and
short back channels. On the other hand, cluster
2 and 6 contains utterance showing conﬁrmation
or agreement, such as utterances containing the
words “yeah,” “right,” and “yes.” We also obtain

164(a) K-Means clustering.

(b) K-Means sub-clustering on cluster 5.

(c) DPGMM clustering.

Figure 1: T-SNE Representation of the clustering results.

smaller clusters for appreciation or thanking and
non-speech sounds, such as laughter and breath-
ing. The rest of the utterances which are relatively
longer are grouped together in a very large cluster
with 4220 members (cluster 5 in Figure 1(a)).

Second clustering on cluster 5 group these ut-
terances into smaller sub-clusters (Figure 1(b)).
“I” is the most frequent word in sub-cluster 0,
and “you” in sub-cluster 1. Some of the actions
from the ﬁrst clustering are re-discovered during
the second clustering, such as thanking and appre-
ciation in sub-cluster 7, and conﬁrmation in sub-
cluster 6. The largest sub-cluster is sub-cluster 2
with 1324 members which contain longer utter-
ances, a combination of opinion, questions, and
other sentences. In total, we obtained 15 clusters
from K-means clustering.

On the other hand, the DPGMM clustering re-
sults in 13 clusters. DPGMM clustering yield a
similar result, giving one huge cluster for longer
sentences and smaller clusters populated with for
back channel, non-speech sounds, thank you, and
agreement. However, there are several differences
between the results from DPGMM and K-means
that are worth mentioning. First, we notice that the
characteristic of each cluster is less salient com-
pared to that of K-Means; e.g. numerous back
channels can be found in several other clusters.
Second, the class size distribution is more uneven:
there are 6 clusters with less than 100 members,
in contrast to only 1 with K-Means. Third, un-
like K-Means, re-clustering of the biggest cluster
is not possible as it is already represented by one
component in the model.

4.2 Hierarchical Neural Dialogue System

with Multiple Contexts

We propose providing higher level knowledge
about the response to the model, in form of re-
sponse cluster labels (Section 4.1), to aid its re-

sponse generation. We propose a neural dialogue
system which generate response based on mul-
tiple dialogue contexts: 1) dialogue history, 2)
user emotional state, and 3) expert’s action label.
Henceforth we call this model the multi-context
HRED (MC-HRED)

The information ﬂow of the MC-HRED is as
follows. After reading the input sequence Um =
{wm,1, ..., wm,Nm}, the dialogue turn is encoded
into utterance representation hutt.

hutt = hutt

Nm = f (hutt

Nm−1, wm,Nm).

(1)

hutt is then fed into the dialogue encoder to model
the sequence of dialogue turns into dialogue con-
text hdlg.

hdlg = hdlg

m = f (hdlg

m−1, hutt).

(2)

In MC-HRED, the hdlg is then fed into the emo-
tion and action encoders, which will then be used
to encode the emotion context hemo as well as the
expert action label hact.

henc = f (henc
where enc = {emo, act}.

m−1, henc),

(3)

The generation process of the response, Um+1,
is conditioned by the concatenation of the three
contexts: dialogue history, emotion context, and
the expert action label.

Pθ(wn+1 = v|w≤n) =

(cid:80)

exp(g(concat(hdlg, hemo, hact), v))
v(cid:48) exp(g(concat(hdlg, hemo, hact), v(cid:48)))

.

(4)

Figure 2 shows a schematic view of this ar-
chitecture. For each the emotion and action en-
coders, we consider an RNN with gated recurrent
unit (GRU) cells and sigmoid activation function.

1651510505101520151050510152001234567105051015105051015012345671510505101520151050510152002346710111214151617Figure 2: MC-HRED architecture. Emotion en-
coder is shown in dark blue, and action encoder in
dark yellow. Blue NNs are relating to input, and
yellow NNs to response.

Both encoders are trained together with the rest of
the network. Each encoder has its own target vec-
tor, which is the emotion label of the currently pro-
m and expert action label
cessed dialogue turn U emo
of the target response U act
m . We modify the deﬁ-
nition of the training cost to incorporate the cross
entropy losses of the emotion and action encoders.

costenc = ((1 − U enc

m ) · log(1 − f (henc)))
m · logf (henc)),
− (U enc

(5)

where enc = {emo, act}.

The training cost of the MC-HRED is a linear
interpolation between the response generation er-
ror costutt (i.e. negative log-likelihood of the gen-
erated response) and the prediction errors of the
encoders costemo and costact with weights α and
β which decays after every epoch.

cost = (1 − α − β) · costutt

+ α · costemo + β · costact.

(6)

The ﬁnal cost is then propagated to the network
and the parameters are optimized as usual with the
optimizer algorithm.

5 Experimental Set Up

Figure 3 illustrates the experimental set up of this
work. Each of the steps will be explained in this
section. The scope of this study is limited to text
data.

Figure 3: The ﬂow of the experiment.

5.1 Pre-trained model
Previous works have demonstrated the effective-
ness of large scale conversational data in improv-
ing the quality of dialogue systems (Banchs and
Li, 2012; Ameixa et al., 2014; Serban et al., 2016).
In this study, we make use of SubTle (Ameixa
et al., 2014), a large scale conversational corpus
collected from movie subtitles, to learn the syn-
tactic and semantic knowledge for response gen-
eration. The use of movie subtitles is particularly
suitable as they are available in large amounts and
reﬂecting natural human communication.

In our experiments, we utilize the HRED
trained on the SubTle corpus as our starting model.
We follow the data pre-processing method in (Ser-
ban et al., 2016). The processed SubTle corpus
contained 5,503,741 query-answer pairs in total.
The triple format is forced onto the pairs by treat-
ing the last dialogue turn in the triple as empty.
We select the 10,000 most frequent token from the
combination of SubTle and the counseling data as
system vocabulary. The purpose is twofold:
to
help widen the intersection of words between the
two corpora, and to preserve special token from
the counselor corpus such as laughter and other
non-speech sounds.

The model is pre-trained by feeding the Sub-
Tle dataset sequentially into the network until it
converges, taking approximately 2 days to com-
plete. In addition to the model parameters, we also
learn the word embeddings of the tokens. We used
word embeddings with size 300, utterance vectors
of size 600, and dialogue vectors of size 1200.
The parameters are randomly initialized, and then
trained to optimize the log-likelihood of the train-
ing triples using the Adam optimizer.

5.2 Fine-tuning
All the models considered in this study are the re-
sult of ﬁne-tuning the pre-trained model with the

166𝑤1,1𝑤1,𝑁1…𝑤2,1𝑤2,𝑁2…𝑤2,1𝑤2,𝑁2…𝑤3,1𝑤3,𝑁3…ℎ𝑢𝑡𝑡ℎ𝑑𝑙𝑔ℎ𝑎𝑐𝑡ℎ𝑒𝑚𝑜Counseling dataUnsupervised action labelCounselor dialogue clusteringSubTlePre-trainingFine-tuningTestingcounseling corpus (Section 2). The triples from
the corpus are fed sequentially into the network.
To investigate the effectiveness of the proposed
methods, we train multiple models with combina-
tions of set ups.

We consider two different models: Emo-HRED
as baseline model and MC-HRED as the proposed
model. Emo-HRED considers only dialogue his-
tory and emotional context during the response
generation, while MC-HRED considers expert ac-
tion context in addition to the dialogue history
and emotional context. For completeness, we
also train a model that only utilized dialogue his-
tory and action context, which we will call Clust-
HRED for convenience.

As emotional context, we encode the self-
report emotion annotation into a one-hot vec-
tor as follows. We ﬁrst obtain the average va-
lence and arousal values of an utterance. We
then discretize these values respectively into three
classes: positive, neutral, and negative. The in-
tervals for the classes are [−1,−0.07] for nega-
tive, (−0.07, 0.07) for neutral, and [0.07, 1] for
positive. We then encode this class information
into a one-hot vector of length 9, one element
for each of the possible combinations of valence
and arousal classes, i.e. positive-positive, positive-
neutral, neutral-negative, etc. Preliminary experi-
ments showed that on the counselor corpus, this
representation leads to a better performance com-
pared to ﬁxed-length sampling of the emotion
trace.

As action context, we simply encode the cluster
label of U3, obtain as in Section 4.1, into a one-hot
vector. We experimented with two cluster label
sets, one produced by hierarchical K-Means clus-
tering (15 clusters), and one by DPGMM cluster-
ing (13).

To accommodate this additional

information
during ﬁne-tuning, we append new randomly ini-
tialized parameters to the utterance decoder. These
parameters are trained exclusively during the ﬁne-
tuning process. All models are ﬁne-tuned selec-
tively. That is, we ﬁx the utterance and dialogue
encoders parameters, and selectively train only the
proposed encoders as well as the decoder. This
has been shown to result in a more stable model
when ﬁne-tuning with a small amount of data (Lu-
bis et al., 2018).

We partitioned the counseling corpus into 50
recording sessions (5053 triples) for training, 5

(503) for validation, and 5 (508) for testing.

6 Evaluation and Analysis

6.1 Perplexity
We calculate model perplexity, which measures
the probability of exactly regenerating the refer-
ence response in a triple. Since the target re-
sponses are assumed to be expert’s response, its
reproduction by the model is desirable. Perplexity
has also been previously recommended for eval-
uating generative dialogue systems (Pietquin and
Hastie, 2013).

We compute the perplexity for each triple and
average it to obtain model perplexity. The model
perplexities are summarized in Table 1. We com-
pute the average test triple length (59.6 tokens),
and group the test triples into two: those with be-
low average length as “short” (294 triples), and
those above as “long” (186). Average perplexi-
ties are shown for the entire test set (all), the short
group, and the long group, separately.

Emo. Action

Model
Emo-
HRED
Clust-
HRED
MC-
HRED

Yes

No

Yes

all
42.60
No
K-Means
39.57
DPGMM 30.57
29.57
K-Means
DPGMM 32.04

Perplexity

short
35.74
32.30
24.79
23.23
25.00

long
61.17
57.37
42.25
38.73
42.34

Table 1: Model Perplexity of different architec-
tures.

We obtain model with the lowest perplexity
when emotion and K-Means labels are both uti-
lized in the training and response generation pro-
cess. For all models, the perplexity of long triples
is consistently higher than that of short ones. More
signiﬁcant improvement is observed on long test
triples.

Looking at the perplexity on all test triples,
interestingly, the two cluster labels are affected
in starkly different ways when combined with
emotion labels: K-Means gain signiﬁcant im-
provement, while DPGMM slightly suffers. We
found that on long triples, Clust-HRED and MC-
HRED yield similar performances when using the
DPGMM cluster label. In contrast, when using K-
means label, MC-HRED shows further improve-
ment from Clust-HRED.

We separate the test triples based on the aver-
age model perplexity to analyze their properties.

167Aside from triple length, no other signiﬁcant dif-
ference was observed. This signals that the ability
to capture context is one of the deﬁning character-
istic of a strong model for this task.

6.2 Human Subjective Evaluation
We present human judges with a dialogue triple
and ask them to rate the response in terms of three
criteria: 1) naturalness, which evaluates whether
the response is intelligible, logically follows the
dialogue context, and resembles real human re-
sponse, 2) emotional impact, to measure whether
the response elicits a positive emotional impact
or promotes an emotionally positive conversation,
and 3) engagement, to evaluate whether the pro-
posed response shows involvement in the dia-
logue and promotes longer conversation by invit-
ing more response.

We evaluate Emo-HRED and the best perform-
ing MC-HRED utilizing K-Means clustering la-
bels. We evaluate 100 triples from the full test
set, where each is judged by 20 human evaluators.
Each triple is presented in A-B-A format, the ﬁrst
two dialogue turns are held ﬁxed according to the
test set, and the last turn is the response generated
by the evaluated model. Evaluators are asked to
judge the responses by stating their agreement to
three statements: 1) A gives a natural response, 2)
A’s response elicits a positive emotional impact in
B, and 3) A’s response in engaging. The agree-
ment is given using a Likert scale, ranging from 1
(strongly disagree) to 5 (strongly agree). Figure 4
summarizes the subjective evaluation result.

Figure 4: Human subjective rvaluation result.

We observe slight improvement on MC-HRED
in the emotional impact and a more notable one
in the engagement metric. On average, the re-
sponses generated by MC-HRED are 2.53 words
longer compared to that of Emo-HRED. From the
ratings, we also found that engagement is moder-
ately correlated with response length, with an av-
erage Pearson r of 0.41. This signals that MC-

HRED is able to produce longer sentences which
results in higher engagement, while still maintain-
ing naturalness and emotional impact. Dialogue
samples comparing the systems responses are in-
cluded in Table 2.

Table 2: Comparison of system responses for two
triples in test set.
U1
U2
U3 (Target)
Emo-HRED
MC-HRED
U1
U2

oh how do you feel about that one.
yes i heard the story.
you heard it before.
right.
it’s a big thing.
are you a student here?
uh yes, actually I just got, er that’s my
lab over there in social computing yes
(laughter).
oh really. so you’ve been watching us
going by.
oh okay.
(laughter) it’s nice to meet you.

U3 (Target)

Emo-HRED
MC-HRED

7 Conclusion
We construct a corpus containing recordings of a
counselor and 30 participants following a negative
emotional exposure to learn expert responses in a
positive emotion elicitation scenario. We unsuper-
visedly cluster the expert’s responses and use the
resulting labels to train a dialogue system. We pro-
posed a novel hierarchical neural architecture for
response generation that is conditioned on 1) ex-
pert’s action, 2) dialogue context, and 3) user emo-
tion, encoded from user input.

The objective evaluation we conducted show
that the proposed model yields lower perplexity on
a held-out test set. Subsequent human subjective
evaluation shows that MC-HRED is able to pro-
duce longer sentences which improve engagement
while still maintaining response naturalness and
emotional impact. In the future, we would like to
consider emotional impact explicitly for the emo-
tion elicitation in lieu of a data-driven approach of
positive emotion elicitation. We would also like
to consider other modalitiesm such as speech, for
a richer emotion encoding. We acknowledge that
evaluation through real user interaction needs to
be carried in the future to test the system in a more
realistic scenario.

Acknowledgements
Part of
supported by JSPS
KAKENHI Grant Numbers JP17H06101 and
JP17K00237.

this work was

1684.173.793.924.173.83.993.43.63.844.2naturalnessemo_impactengagementEmo-HREDMC-HREDReferences
Jaime C Acosta and Nigel G Ward. 2011. Achieving
rapport with turn-by-turn, user-responsive emotional
coloring. Speech Communication, 53(9-10):1137–
1148.

David Ameixa, Luisa Coheur, Pedro Fialho, and Paulo
Quaresma. 2014. Luke, i am your father: dealing
with out-of-domain requests by using movies subti-
tles. In International Conference on Intelligent Vir-
tual Agents, pages 13–21. Springer.

Rafael E Banchs and Haizhou Li. 2012. Iris: a chat-
oriented dialogue system based on the vector space
In Proceedings of the ACL 2012 System
model.
Demonstrations, pages 37–42. Association for Com-
putational Linguistics.

Roddy Cowie, Ellen Douglas-Cowie, Susie Savvi-
dou, Edelle McMahon, Martin Sawey, and Marc
Schr¨oder. 2000. ‘FEELTRACE’: An instrument for
recording perceived emotion in real time. In ISCA
tutorial and research workshop (ITRW) on speech
and emotion.

Arjan Egges, Sumedha Kshirsagar,

and Nadia
Magnenat-Thalmann. 2004.
Generic personal-
ity and emotion simulation for conversational
agents. Computer animation and virtual worlds,
15(1):1–13.

Kate Forbes-Riley and Diane Litman. 2012. Adapt-
ing to multiple affective states in spoken dialogue.
In Proceedings of the 13th Annual Meeting of the
Special Interest Group on Discourse and Dialogue,
pages 217–226. Association for Computational Lin-
guistics.

Jonathan Gratch, Ron Artstein, Gale M Lucas, Giota
Stratou, Stefan Scherer, Angela Nazarian, Rachel
Wood, Jill Boberg, David DeVault, Stacy Marsella,
et al. 2014. The distress analysis interview corpus
of human and computer interviews. In LREC, pages
3123–3128. Citeseer.

James J Gross and Robert W Levenson. 1995. Emo-
tion elicitation using ﬁlms. Cognition & emotion,
9(1):87–108.

Sangdo Han, Yonghee Kim, and Gary Geunbae Lee.
2015. Micro-counseling dialog system based on
In Natural Language Dialog
semantic content.
Systems and Intelligent Assistants, pages 63–72.
Springer.

Takayuki Hasegawa, Nobuhiro Kaji, Naoki Yoshinaga,
and Masashi Toyoda. 2013. Predicting and elicit-
ing addressee’s emotion in online dialogue. In Pro-
ceedings of Association for Computational Linguis-
tics (1), pages 964–972.

Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki
Isozaki. 2008. Effects of self-disclosure and empa-
In Proceedings
thy in human-computer dialogue.
of Spoken Language Technology Workshop, pages
109–112. IEEE.

Nio Lasguido, Sakriani Sakti, Graham Neubig, Tomoki
Toda, and Satoshi Nakamura. 2014.
Utilizing
human-to-human conversation examples for a multi
domain chat-oriented dialog system. Transactions
on Information and Systems, 97(6):1497–1505.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016. A diversity-promoting objec-
tive function for neural conversation models. In Pro-
ceedings of NAACL-HLT, pages 110–119.

Nurul Lubis, Sakriani Sakti, Koichiro Yoshino, and
Satoshi Nakamura. 2017. Eliciting positive emo-
tional impact in dialogue response selection. In Pro-
ceedings of International Workshop on Spoken Dia-
logue Systems Technology.

Nurul Lubis, Sakriani Sakti, Koichiro Yoshino, and
Satoshi Nakamura. 2018. Eliciting positive emo-
tion through affect-sensitive dialogue response gen-
In Proceed-
eration: A neural network approach.
ings of The Thirty-Second AAAI Conference on Arti-
ﬁcial Intelligence. Association for the Advancement
of Artiﬁcial Intelligence.

Olivier Luminet IV, Patrick Bouts, Fr´ed´erique Delie,
Antony SR Manstead, and Bernard Rim´e. 2000. So-
cial sharing of emotion following exposure to a neg-
atively valenced situation. Cognition & Emotion,
14(5):661–688.

Gary McKeown, Michel Valstar, Roddy Cowie, Maja
Pantic, and Marc Schroder. 2012. The SEMAINE
database: Annotated multimodal records of emo-
tionally colored conversations between a person and
a limited agent. Transactions on Affective Comput-
ing, 3(1):5–17.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
In Advances in neural information processing
ity.
systems, pages 3111–3119.

Lasguido Nio, Sakriani Sakti, Graham Neubig,
Koichiro Yoshino, and Satoshi Nakamura. 2016.
Neural network approaches to dialog response re-
IEICE Transactions on In-
trieval and generation.
formation and Systems.

Rosalind W Picard and Jonathan Klein. 2002. Comput-
ers that recognise and respond to user emotion: the-
oretical and practical implications. Interacting with
computers, 14(2):141–169.

Olivier Pietquin and Helen Hastie. 2013. A survey on
metrics for the evaluation of user simulations. The
knowledge engineering review, 28(1):59–73.

Bernard Rime, Batja Mesquita, Stefano Boca, and
Pierre Philippot. 1991. Beyond the emotional event:
Six studies on the social sharing of emotion. Cogni-
tion & Emotion, 5(5-6):435–465.

James A Russell. 1980. A circumplex model of af-
fect. Journal of personality and social psychology,
39(6):1161.

169Alexandre Schaefer, Fr´ed´eric Nils, Xavier Sanchez,
and Pierre Philippot. 2010. Assessing the effective-
ness of a large database of emotion-eliciting ﬁlms:
A new tool for emotion researchers. Cognition and
Emotion, 24(7):1153–1172.

Alexandre Schaefer and Pierre Philippot. 2005. Se-
lective effects of emotion on the phenomenal char-
acteristics of autobiographical memories. Memory,
13(2):148–160.

Iulian V Serban, Alessandro Sordoni, Yoshua Bengio,
Aaron Courville, and Joelle Pineau. 2016. Building
end-to-end dialogue systems using generative hier-
archical neural network models. In Thirtieth AAAI
Conference on Artiﬁcial Intelligence.

Marcin Skowron, Mathias Theunis, Sebastian Rank,
and Arvid Kappas. 2013. Affect and social pro-
cesses in online communication–experiments with
an affective dialog system. Transactions on Affec-
tive Computing, 4(3):267–279.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. arXiv preprint
arXiv:1506.06714.

Myrthe Tielman, Mark Neerincx, John-Jules Meyer,
and Rosemarijn Looije. 2014. Adaptive emotional
In Proceed-
expression in robot-child interaction.
ings of the 2014 ACM/IEEE international confer-
ence on Human-robot interaction, pages 407–414.
ACM.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-

tional model. arXiv preprint arXiv:1506.05869.

Rainer Westermann, Gunter Stahl, and F Hesse. 1996.
Relative effectiveness and validity of mood induc-
tion procedures: analysis. European Journal of so-
cial psychology, 26:557–580.

Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan
Zhu, and Bing Liu. 2017.
Emotional chatting
machine: Emotional conversation generation with
arXiv preprint
internal and external memory.
arXiv:1704.01074.

170