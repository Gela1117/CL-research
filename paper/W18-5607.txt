Investigating the Challenges of Temporal Relation Extraction from

Clinical Text

Diana Galvan 1 Naoaki Okazaki 2 Koji Matsuda 1 Kentaro Inui 1,3

1 Tohoku University

2 Tokyo Institute of Technology

3 RIKEN Center for Advanced Intelligence Project

{dianags,matsuda,inui}@ecei.tohoku.ac.jp

okazaki@dc.titech.ac.jp

Abstract

Temporal reasoning remains as an unsolved
task for Natural Language Processing (NLP),
particularly demonstrated in the clinical do-
main. The complexity of temporal represen-
tation in language is evident as results of the
2016 Clinical TempEval challenge indicate:
the current state-of-the-art systems perform
well in solving mention-identiﬁcation tasks of
event and time expressions but poorly in tem-
poral relation extraction, showing a gap of
around 0.25 point below human performance.
We explore to adapt the tree-based LSTM-
RNN model proposed by Miwa and Bansal
(2016) to temporal relation extraction from
clinical text, obtaining a ﬁve point improve-
ment over the best 2016 Clinical TempEval
system and two points over the state-of-the-
art. We deliver a deep analysis of the results
and discuss the next step towards human-like
temporal reasoning.

1

Introduction

Temporal Information Extraction (TIE) is an ac-
tive research area in NLP, where the ultimate
goal is to be able to represent the development
of a story over time. TIE is a key to text pro-
cessing tasks including Question Answering and
Text Summarization and follows the traditional
pipeline of named entity recognition (NER) and
relation extraction separately. Research on this
area has been led by TempEval shared tasks (Ver-
hagen et al., 2007, 2010; UzZaman et al., 2013)
but in recent years, the target domain has been
shifted to the clinical domain. The resulting Clin-
ical TempEval challenges (Bethard et al., 2015,
2016, 2017) introduced the adoption of narrative
containers to their annotation schema, based on
the widely used TIE annotation standard ISO-
TimeML (Pustejovsky et al., 2010). Narrative con-
tainers were deﬁned by Pustejovsky and Stubbs

Figure 1: Example temporal relation annotation with
and without using narrative containers.

(2011) as an effort to reduce the scope of temporal
relations between pairs of events and time expres-
sions. As illustrated in Figure 1, narrative contain-
ers can be thought of as temporal buckets in which
an event or series of events may fall. They help vi-
sualize the temporal relations within a text and fa-
cilitate the identiﬁcation of other temporal relation
types. Until now, the only corpus annotated with
narrative containers is limited to clinical texts.

Results of the systems participating in Clinical
TempEval suggest that they perform well on time-
entity identiﬁcation tasks. Nevertheless, tempo-
ral relation extraction has shown to be the most
difﬁcult. UTHealth (Lee et al., 2016), the best
ranked system in 2016 Clinical TempEval, showed
a signiﬁcant gap of 0.25 when compared to hu-
man performance even with gold-standard entity
annotations. Recent work by Lin et al. (2016)
and Leeuwenberg and Moens (2017) improved
UTHealth's results further but the gap with respect
to humans is still around 0.21. Regardless of the

Proceedingsofthe9thInternationalWorkshoponHealthTextMiningandInformationAnalysis(LOUHI2018),pages55–64Brussels,Belgium,October31,2018.c(cid:13)2018AssociationforComputationalLinguistics55increase in annotation agreement of temporal rela-
tions by relying on narrative containers, there is a
consensus within the research community regard-
ing TIE difﬁculty. Still, the reasons of the uneven
results between entity and temporal relation pre-
dictions remain unclear.

We attribute the complexity of temporal repre-
sentation in natural language as the main cause of
the low performance on temporal relation tasks.
Tense and aspect are the two grammatical means
to express the notion of time in English but lit-
tle has been discussed about the latter on clinical
text. Furthermore, the focus of previous work on
temporal relation extraction is set on narrative con-
tainers, which have proved to be useful to locate
and relate two events on a timeline. Identiﬁcation
of other temporal relation types has been less fre-
quently tackled. We believe is key to look at the
whole set of temporal types to achieve the ultimate
goal of developing systems that automatically cre-
ate a timeline of a patient's health care.

In this paper, we describe the process followed
to adapt the neural model proposed by Miwa and
Bansal (2016) on TIE, which has already shown
competitive results on semantic relation extrac-
tion. In our pursuit of understanding the nature of
the challenges that characterize the processing of
temporal relations, we continue with an error anal-
ysis of our system's overall performance and not
only on the identiﬁcation of narrative containers.
Our ﬁnal goal is to shed some light on the difﬁ-
culties of temporal relation extraction and the nec-
essary efforts to improve further current state-of-
the-art systems performance with that of humans
on completing the same task.

2 Related Work

Due to the recent shift of TIE to the clinical do-
main, most related work has been done by Clin-
ical TempEval participating systems. This chal-
lenge uses a corpus annotated with ﬁve different
temporal relation (TLINK) types between events
and times (“TIMEX3” in this schema): BEFORE,
BEGINS-ON, CONTAINS, ENDS-ON and OVER-
LAP. However, this challenge only evaluates the
identiﬁcation of a narrative container, marked with
the CONTAINS type.

Until 2016 edition of Clinical TempEval, clas-
sic machine learning algorithms for classiﬁcation
such as conditional random ﬁelds (CRF), sup-
port vector machines (SVM) and logistic regres-

In fact,

sion with a variety of features (lexical, syntac-
tic, morphological, and many others) were the
predominant approach.
the best per-
formance was achieved by UTHealth team (Lee
et al., 2016) using an end-to-end system based
on linear and structural Hidden Markov Model
(HMM)-SVM. Just a few teams tried a neu-
ral based method, including RNN-based models
(Fries, 2016) and CNN-based models (Chikka,
2016), (Li and Huang, 2016). Furthermore, among
those teams just Chikka (2016) participated in the
CONTAINS identiﬁcation task, being around 0.30
below UTHealth's top performance.

Recent work by Lin et al. (2016), Dligach et al.
(2017) and Leeuwenberg and Moens (2017) fol-
lowed the settings of 2016 Clinical TempEval
challenge but they did not participate in the com-
petition. Out of these, our results are only di-
rectly comparable to those of Lin et al. (2016) and
Leeuwenberg and Moens (2017) since the work of
Dligach et al. (2017) was not evaluated using the
Clinical TempEval ofﬁcial scorer.

Even though Leeuwenberg and Moens (2017)
established a new state-of-the-art in temporal re-
lation extraction, their result is still below human
performance. Moreover, none of the aforemen-
tioned works provides a detailed discussion of why
is current performance so low and how can we
improve further the results on temporal relation
extraction, except from Leeuwenberg and Moens
(2016), which in their ﬁrst attempt on tackling this
task on 2016 Clinical TempEval identiﬁed false
negatives as their major problem.

Our contribution is a deep error analysis taking
into account the performance of our model on pre-
dicting all TLINK types. As a result, we were able
to identify important clues on temporal relation
extraction and based on these ﬁndings, we discuss
the next step towards human-like temporal reason-
ing performance.

3 Method

We adapted the tree-based bidirectional LSTM-
RNN end-to-end neural model of Miwa and
Bansal (2016) to intra-sentential temporal rela-
tion extraction from clinical text. This three-layer
model (embedding, sequence and dependency lay-
ers) jointly identiﬁes entities and relations be-
tween them. For relation classiﬁcation, the model
heavily relies on the dependency structure around
the target word pair and the output of the sequence

56TLINK

Train

Test

CONTAINS
NONE

8653
43643

4554
20465

Total

52296

25019

Table 1: Label distribution of pre-processed dataset for
binary classiﬁcation.

layer. When tested on nominal relation classiﬁca-
tion (Hendrickx et al., 2009), it showed competi-
tive results against the state-of-the-art.

We followed the ofﬁcial 2016 Clinical TempE-
val settings for phase 2 of evaluation, where given
the raw text and manual event and time annota-
tions, the task is to identify the temporal relation
between a directed pair pe1, e2q, if any. e1 and e2
are entities of either EVENT or TIMEX3 type. For
relation classiﬁcation, Miwa and Bansal (2016)
model takes as an input a sentence and a anno-
tation ﬁle with a word pair. The output contains
the predicted relation type and the directionality
of the entities:pe1, e2q when e1 is the source and
e2 the target and pe2, e1q otherwise.
4 Experimental settings

4.1 Dataset
Similar to 2016 Clinical TempEval, we used the
THYME corpus (Styler IV et al., 2014) for eval-
uation, a dataset of 600 clinical notes and pathol-
ogy reports from colon cancer patients at the Mayo
Clinic. The corpus is annotated at the document
level and identiﬁed entities are given a set of at-
tributes depending on their type: DocTimeRel,
Type, Polarity, Degree, Contextual Modality and
Contextual Aspect for EVENTs and Class for
TIMEX3. Temporal relation annotations specify
source and target entities along with one of the fol-
lowing TLINK types: BEFORE, BEGINS-ON, CON-
TAINS, ENDS-ON and OVERLAP.

Sentence-level annotations are necessary to
meet Miwa and Bansal (2016)’s input require-
ments. Therefore, we used the Clinical Language
Annotation, Modeling and Processing (CLAMP)
toolkit1 for tokenization and sentence boundary
detection. We matched all entities spans from
the gold standard with the sentence offsets on the
CLAMP output to identify those within the same
sentence. As a result, the new annotations con-

1http://clinicalnlptool.com/index.php

TLINK

Train

Test

BEFORE
1839
BEGINS-ON 717
8653
CONTAINS
ENDS-ON
334
2388
OVERLAP
NONE
43643

982
363
4554
138
1186
20465

Total

57574

27688

Table 2: Label distribution of pre-processed dataset for
multi-class classiﬁcation.

System

P

R

F1

(Lee et al., 2016)
(Lin et al., 2016)
(Leeuwenberg and Moens, 2017)
Our model

0.588
0.669
-
0.983

0.559
0.534
-
0.462

0.573
0.594
0.608
0.629

Human performance

-

-

0.817

Table 3: Performance of systems and humans on iden-
tifying CONTAINS relations.

tain a pair of words, their offsets in the sentence,
the temporal relation between them marked on the
gold standard and the directionality of the argu-
ments. Example 1 shows an example annotation
of the TLINK CONTAINS(lifelong, nonsmoker) in
the sentence He is a lifelong nonsmoker.

(1)

Term 8 16
Term 17 26

T1
T2
R1 ContainsSource-ContainsTarget Arg1:T1
Arg2:T2

lifelong
nonsmoker

Since any two EVENT/TIMEX3 can be a can-
didate pair, we took all entities in a sentence
to generate all pair combinations as candidates.
Pairs that do not have any temporal relation were
labeled as NONE. Due to the large number of
negative instances produced by this procedure,
it was applied only to CONTAINS. No negative
instances were generated for the remaining TLINK
types and we did not extend the set of TLINKs to
its transitive closure (i.e. A CONTAINS B ^ B
CONTAINS C Ñ A CONTAINS C). Table 1 and
Table 2 detail the resulting datasets.

57Binary classiﬁcation

Multi-class classiﬁcation

Wikipedia word emb

Wikipedia word emb

PubMed word emb

PubMed word emb + FNE

TLINK

BEFORE
BEGINS-ON
CONTAINS
ENDS-ON
OVERLAP

P

-
-

R

-
-

F1

-
-

0.983

0.462

0.629

-
-

-
-

-
-

P

R

F1

P

R

F1

P

R

0.698
0.585
0.905
0.520
0.504

0.185
0.062
0.472
0.086
0.134

0.292
0.112
0.621
0.148
0.211

0.708
0.615
0.908
0.704
0.504

0.198
0.103
0.471
0.126
0.134

0.310
0.177
0.620
0.213
0.211

0.683
0.608
0.889
0.760
0.497

0.202
0.116
0.479
0.126
0.140

F1

0.312
0.195
0.623
0.216
0.218

Table 4: Results of our four experiments on the THYME test set. FNE refers to ﬁltered negative examples.

4.2 Experiments
We followed the same experimental settings de-
scribed in Miwa and Bansal (2016). Additional to
the model's default Wikipedia word embeddings,
we trained word vectors of 200 dimensions using
word2vec (Mikolov et al., 2013) on a subset of
journal abstracts in Oncology and Gastroenterol-
ogy from PubMed20142. PubMed data can be eas-
ily downloaded without application approval that
clinical corpus like MIMIC II (Saeed et al., 2011)
require.

We conducted four experiments at the intra-
sentential level. The ﬁrst experiment follows 2016
Clinical TempEval, focusing only on the identiﬁ-
cation of the CONTAINS type. The remaining ex-
periments include the ﬁve annotated TLINKs. Fur-
ther detail of each experiment is given below:

1. TLINK:CONTAINS binary classiﬁcation:

In
order to obtain results comparable to Lee
et al. (2016),
the best ranked system in
2016 Clinical TempEval, we only consid-
ered TLINK:CONTAINS instances. The model
chooses between CONTAINS and NONE rela-
tions.

2. Multi-class classiﬁcation: To test the model
in a real-world setting, we added to train and
test sets the remaining pairs in the gold stan-
dard that have any of the other TLINK types.
No further negative examples were created
for the additional types.

3. Multi-class classiﬁcation with PubMed word
embeddings: In addition to the previous set-
ting (2), we used word embeddings trained on
the subset of PubMed instead of the default
word vectors trained on Wikipedia.

2https://www.nlm.nih.gov/databases/

download/pubmed_medline.html

4. Multi-class classiﬁcation with PubMed word
embeddings and ﬁltered negative examples:
In addition to the previous setting (3), we ﬁl-
tered from the dataset NONE pairs that ac-
cording to the THYME guidelines3 should
never be TLINKed. Thus, we removed a can-
didate pair whenever e1 contextual modality
value4 was ACTUAL or HEDGED and the e2
had HYPOTHETICAL or GENERIC modality,
and vice versa.

5 Results

5.1 TLINK:CONTAINS binary classiﬁcation
Table 3 presents the results of previous approaches
compared to human performance. The ﬁrst row
shows the top performance in 2016 Clinical Tem-
pEval using binary classiﬁcation. The second and
third rows are the latests results outside the compe-
tition. Following the steps of the Clinical TempE-
val narrative container identiﬁcation task, we only
tried to predict TLINKs of CONTAINS type. In do-
ing so we obtained an F1 score of 0.629, outper-
forming UTHealth's system. The model shows a
high precision but lower recall than UTHealth; this
is probably because of NONE relations prevailing
in the dataset. By handling the task as binary clas-
siﬁcation, given a pair of entities we are already
assuming there is some kind of temporal relation
and the classiﬁer's task is to decide whether it is
CONTAINS or not. We performed this experiment
in order to have results comparable with those of
UTHealth. However, we cannot compare this re-

3http://savethevowels.org/ﬁles/THYMEGuidelines.pdf,

Section 6.2.5

4Entity attributes introduced in Section 4.1 were not used
as features in our model. EVENTs marked with HYPOTHET-
ICAL or GENERIC modality are non-real events. Therefore,
they cannot be related to real events marked as ACTUAL or
HEDGED.

58sult to the state-of-the-art since Leeuwenberg and
Moens (2017) was a multi-class classiﬁcation ap-
proach.

5.2 Multi-class classiﬁcation
Table 4 reports our experimental results of a sin-
gle run with the four different settings5. Switch-
ing from binary classiﬁcation to multi-class clas-
siﬁcation we observe a signiﬁcant drop in preci-
sion and a lower F1 score. This is expected since
the classiﬁer now has more TLINK as options from
where to decide. Despite of this change, the model
keeps outperforming both UTHealth and the state-
of-the-art.

5.3 Multi-class classiﬁcation with PubMed

word embeddings

Once we conﬁrmed the adapted model gives com-
petitive results on the narrative container identiﬁ-
cation task, we focused on increasing the system's
recall. Therefore, we changed the word represen-
tations for in-domain word embeddings in com-
parison with the previous experiment, which uses
word vectors trained on Wikipedia. Word repre-
sentation depends on the words in context and be-
cause the clinical domain is a very speciﬁc ﬁeld
with a different vocabulary of that used in the gen-
eral domain, we expected the model to beneﬁt
from a resource like PubMed. However, our re-
sults suggest this does not have a signiﬁcant im-
pact on most TLINKs (OVERLAP did not change at
all). Only BEGINS-ON and ENDS-ON recall con-
siderably improved.

5.4 Multi-class classiﬁcation with PubMed
word embeddings and ﬁltered negative
examples

While we increased recall by using in-domain
word embeddings, we can still witness an imbal-
ance between precision and recall. Moreover, we
are still below UTHealth recall score (highest on
CONTAINS identiﬁcation task). To improve further
the model's recall, around 10% of NONE:EVENT-
EVENT pairs were removed from the dataset based
on a rule of the annotation guidelines that prevents
non-real events (i.e. events that do not actually
appear on the patient's timeline) to be linked with
real events. Recall was further improved for most
TLINKs while it remained the same for ENDS-ON.
Under this setting, our model reached its best F1
5We experimented a couple of additional runs but the re-

sults were always the same.

Figure 2: Confusion matrix of our multi-class classiﬁ-
cation model with PubMed word embedding on the dev
set.

scores for all TLINKs, outperforming the state-of-
the-art on CONTAINS.

6 Error Analysis

We focused our error analysis on the fourth of our
experiments. Systems participating in the Clin-
ical TempEval narrative container identiﬁcation
task only received credit if for a pair of entities,
they correctly identiﬁed the source, target and the
CONTAINS relation between them. Given this set-
ting, we understand that even when using man-
ual event and time annotations the challenge is
not only to predict the TLINK type but also the
correct directionality of the entities. Part of our
analysis is to determine whether type classiﬁca-
tion or directionality identiﬁcation is the most dif-
ﬁcult task or if they are both equally problem-
atic for the model. Confusion matrix on Fig-
ure 2 shows the results on the development set.
Overall, due to the high number of negative in-
stances, most of the false positives fall into the
N onepe1, e2q category. At the same time, we can
observe that this type of relation is the reason why
the system shows high precision. Apart from this,
we can identify the performance on OVERLAP as
our system's main problem. Accuracy in both
Overlappe1, e2q and Overlappe2, e1q is consider-
ably low, with the latter being the lowest among
all types with 0.024. Not even the performance on
Bef orepe2, e1q with 0.34 is as low, even though

59True relation
Overlappe1, e2q
Overlappe1, e2q
Overlappe1, e2q
Overlappe1, e2q
Overlappe1, e2q
Overlappe1, e2q
Overlappe1, e2q

Predicted relation
Containspe1, e2q
Containspe1, e2q
Containspe1, e2q
Containspe1, e2q
Containspe1, e2q
Containspe1, e2q
Containspe1, e2q

Overlappe2, e1q

Containspe2, e1q

Overlappe2, e1q
Overlappe2, e1q

Containspe2, e1q
Containspe2, e1q

Sentence
1. Tumor invades into the muscularis propria.
2. Recurrent rectal adenocarcinoma, previously resected node-negative
3. June 30, 2009: Due to change in stool, patient underwent colonoscopy noting
mass in the right colon.
4. A biopsy obtained was positive for adenocarcinoma, consistent with col-
orectal primary and conﬁrmed by LCC.
5. Pathology from the extended right hemicolectomy was positive for invasive
moderately differentiated adenocarcinoma in the ascending colon.
6. Exploratory surgery with appendicitis many years ago.
7. She was seen by a cardiologist in Idyllwild back in April when she was
hospitalized and had an adenosine sestamibi scan after that hospitalization, but
if surgery is contemplated I would wish her to be seen by cardiology.
8. Does have some constipation with her iron supplementations but denies nau-
sea, vomiting, abdominal distention, or worsening constipation, as she does
have bowel movements once every several days.
9. She is still moving her bowels multiple times a day.
10. The patient smokes cigars about once-a-month.

Table 5: Sample of the analyzed misclassiﬁed sentences by our system. e1 and e2 are shown in bold and italics,
respectively.

can
usually

2 we
observe
is
predicted
and Overlappe2, e1q

they have similar number of instances (290 and
353, respectively). Overlappe1, e2q with 0.14 is
comparable to BeginsOnpe2, e1q, despite of hav-
ing 7 times more instances (1291 vs. 176). For this
reason, we focused our error analysis on OVER-
LAP.
From Figure
that
Overlappe1, e2q
as
Containspe1, e2q
is
predicted as Containspe2, e1q. In both cases the
directionality of the entities was correct but the
system failed to identify the appropriate temporal
For Overlappe1, e2q there were 126
relation.
misclassiﬁed sentences while in Overlappe2, e1q
there were 37.
EVENT-EVENT pairs were the
predominant
type of pair in the former while
TIMEX3-EVENT were for the latter, with 116 and
29 instances, respectively. We took all of the
aforementioned misclassiﬁed sentences for sup-
plementary examination and discuss the reason(s)
of this errors in the following section.

6.1 Temporal relations and Aspectual Classes
Before proceeding further, it is important to under-
stand the deﬁnition of OVERLAP and CONTAINS.
Both temporal relations are closely related since
they encompass the notion of two things happen-
ing at the same time. However, CONTAINS rela-
tions imply that the contained event (i.e. the target)
occurs entirely within the temporal bounds of the
event it is contained within (i.e. the source) while

OVERLAP relations are those where containment is
not entirely sure. Also, OVERLAP is the only sym-
metrical TLINK type since e1 OVERLAP e2 means
the same as e2 OVERLAP e1.

Strictly speaking, every entity occupies time.
An entity's time interval is crucial for understand-
ing its temporal relation with respect to another
entity, specially in the case of CONTAINS and
OVERLAP relations where the end point of the tar-
get is key to determine whether there is complete
containment or not. The temporal relations used
by the THYME project rely on Allen (1990) in-
terval algebra, a precise way to express time pe-
riods using clear start and end points. By com-
paring those, we can easily indicate the position
of two events on the timeline. However, the con-
cept of time is widely discussed across disciplines
and Allen's representation is just one among many
others.
In Linguistics, the expression of time is
understood thanks to two important grammatical
systems:
It is particularly to
our interest the deﬁnition of aspect, the means
with which speakers discuss a single situation,
for example, as beginning, continuation, or com-
pletion (Li and Shirai, 2000). One of the best
known and widely accepted aspect classiﬁcations
is that of Vendler, who distinguished four cate-
gories for verb and verb phrases: activities, ac-
complishments, achievements and states.

tense and aspect.

Figure 3 presents Vendler's classiﬁcation us-
ing (Andersen, 1990) schematization. Arrows are

60used to represent an indeﬁnite time interval, solid
lines indicate a homogeneous duration and dashed
lines indicate a dynamic duration. An X is used to
represent a situation's natural end point.

Figure 3: Vendler’s four-way classiﬁcation. Abbrevia-
tions: C, Clear; NC, Not Clear

Categorizing the source and target entities of a
relation as one of Vendler's types simpliﬁes the
TLINK classiﬁcation task. For example, categories
with no clear end points like activities and states
are more likely to overlap with accomplishments
and achievements, which have clear end points.
Figure 4 illustrates an OVERLAP and CONTAINS
relations using Allen’s and Vendler’s representa-
tion of time periods. Leveraging on aspectual type
for temporal relation extraction is a promising ap-
proach that has already been explored by Costa
and Branco (2012) on TempEval data. However,
this approach is limited since aspect is a property
of verbs.

When analyzing OVERLAP relations that were
mistaken for CONTAINS, we realized that just a
few events are verbs. Events in sentences 1, 3 and
9 in Table 5 are some examples of this (“invades”,
“noting” and “moving”). This pointed out the ne-
cessity of discriminating between verbal and non-
verbal events to understand how they are tempo-
rally related. Our observations suggest that rather
than recognizing an entity semantic type (e.g. sign
or symptoms, diseases, procedures) it is imper-
ative to take into account the action associated
to it. Thus, procedures like colonoscopy, biopsy,
pathology and surgery have to be performed, a dy-
namic verb with a natural end point: an accom-
plishment. Diseases like adenocarcinoma and ap-
pendicitis are present, they exist, and consequently

they fall in the state category. Following this line
of reasoning, it is easier to differentiate an OVER-
LAP relation from CONTAINS in sentence 5 since
we understand the adenocarcinoma was found dur-
ing the performance of the pathology but there is
not enough information to tell whether the adeno-
carcinoma is still present or not. In other words,
its end point is unclear.
In the case of TIMEX3-EVENT pairs like those in
sentences 8 to 10 in Table 5, the nature of the
OVERLAP relation between the entities is due to
the ambiguity of the time expressions combined
with actions that we perceive as ongoing. For ex-
ample, in sentence 9 the action of moving is an ac-
tivity, done indeterminably throughout the day as
multiple times a day imply. In sentence 7, on the
other hand, there is a time expression with a deﬁ-
nite time interval overlapping the patient's state of
being hospitalized.
Temporally locating two events on a timeline re-
quires a high level of reasoning that even for hu-
mans can turn into a complicated task. All of the
aforementioned inferences were done heavily re-
lying on the internal constituency of an event, im-
plying Costa and Branco (2012) claim that tempo-
ral information processing can proﬁt from infor-
mation about aspectual type is valid in the clinical
domain. Due to the high similarity of CONTAINS
and OVERLAP relations it does not come as a sur-
prise that these two types are easily confused by
our system, which performed reasonably well on
identifying other TLINK types with similar number
of instances. This suggests than the main problem
is not the amount of data available but how tempo-
ral properties are encoded in language.
Aspectual information proved useful for differen-
tiating between two of the most frequent and most
similar TLINK types: CONTAINS and OVERLAP.
As previously mentioned in Section 4.1, there is
a contextual aspect attribute available for EVENT
entities with three possible values: N/A (default),
NOVEL and INTERMITTENT. The latter could be
useful to identify an activity or an accomplishment
but just a small portion of EVENTs were annotated
with a value different from the default one. More-
over, aspect is a property of verbs and our analy-
sis insinuates it is more common to ﬁnd nouns as
events. We discuss this ﬁnding in more detail in
the following section.

61Figure 4: Allen’s and Vendler’s interval representation of OVERLAP and CONTAINS relations. A- / B- and A+ /
B+ represent the start and end of an event, respectively. Filled-dots represent clear start points while an empty-dot
represent a not-clear start point.

7 Temporality of nominal events
To deepen our understanding on the complexity
of the temporal relation extraction task, we di-
vided all OVERLAP and CONTAINS false negatives
into the four possible pair types: EVENT-EVENT,
TIMEX3-TIMEX3, EVENT-TIMEX3 and TIMEX3-
EVENT. A signiﬁcant amount of OVERLAP links
were EVENT-EVENT relations and they also made
around half of CONTAINS links. We looked further
into these type of pairs, discriminating between
verb and non-verbal events. Table 6 shows the re-
sults in more detail.

Dev set: Event-Event pairs

TLINK

V-V V-NV NV-V NV-NV

CONTAINS
OVERLAP

Total

6
6

12

47
55

102

24
27

51

103
193

296

Table 6: Distribution of misclassiﬁed CONTAINS and
OVERLAP Event-Event pairs by type of EVENT. Ab-
breviations: V, Verb; NV, Non-Verb

As mentioned by Pustejovsky and Stubbs
(2011) and further discussed in Styler IV et al.
(2014), EVENT-EVENT pairings are a complex and
vital component, particularly in clinical narratives
where doctors rely on shared domain knowledge
and it is essential to read “between the lines”. The
distribution of verb/non-verb entities in Table 6 in-
dicates that most of EVENT-EVENT missclasiﬁed
pairings were either of NV-NV type or include
a NV entity. Time intervals of NV entities like
“pain” or “resection” are more difﬁcult to under-
stand, while V entities like “removed” or “improv-
ing” have their time properties morphologically
encoded. Thus, regardless of the low number of V-

V relations, temporal information from verb predi-
cates usually have more explicit hints. NV entities
are more challenging and require more careful ex-
amination.

The high frequency of NV entities is likely to
be one of the reasons why not only our system but
also previous works in temporal relation extraction
are behind human performance.
In the previous
section we introduced Vendler’s aspectual classiﬁ-
cation and discussed how it helps separate two ex-
tremely similar TLINKs. Unfortunately, this is not
compatible with nominal predicates. Verb/Non-
Verb entities distinction of EVENTs is a ﬁrst step
that could alleviate this problem and positively in-
ﬂuence the temporal relation extraction task.

8 Conclusion and Future work
Clinical language processing represents a special
challenge to NLP systems. The structure of clin-
ical texts range from telegraphic constructions to
long utterances describing a patient's condition
or a suggested diagnosis. The high use of do-
main knowledge to infer temporal relations be-
tween events does not make this task any easier. A
doctor naturally interprets adenocarcinoma (a type
of cancer) as an abnornal, uncontrolled and pro-
gressive growth of tissue which temporally speak-
ing it is and should be thought as an ongoing pro-
cess unless explicitly qualiﬁed (“We resected the
adenocarcinoma, and since margins were clear,
we can say it is gone”). This is a non-trivial task
for a computer even when relying on context in-
formation.

Up to now, there have been several attempts on
tackling temporal relation extraction from clini-
cal text mostly led by the Clinical TempEval chal-
lenges. However, the results are still far from hu-
man performance and there is little information of

62A biopsy obtained was positive for adenocarcinoma,consistent with colorectal primary and conﬁrmed by LCC.{performance of } biopsy{presence of } adenocarcinomaTLINK: biopsy OVERLAP adenocarcinomaDuration: A ­ < B­ < A+B +She is recuperating uneventfully from this most recentsurgery which resected a sidewall tumor compatible withendometrial cancer grade 2. {performance of } surgeryresectedTLINK: surgery CONTAINS resectedDuration: (A­ < B ­) AND (A+ > B+)A+B -A -Patient's timelineA -A+XPatient's timelineB -B +XXthe reasons behind. This encouraged our work to
adapt a state-of-the-art system and do a detailed
error analysis, which pointed out that one of the
major challenges is how to handle the eventive
properties of nominals, the predominant type of
events on the most frequent type of pairs: EVENT-
EVENT.

Existing knowledge bases like the Uniﬁed Med-
ical Language System (UMLS) Metathesaurus
help to classify entities into semantic types like
Therapeutic or Preventive procedure, Sign or
Symptom or Disease or Syndrome. Still, the as-
sociated events and actions cannot be found in this
or any other knowledge base. We hypothesize that
a resource containing aspectual information of the
actions associated to common nominals like pro-
cedures or diseases can further improve temporal
relation extraction in the clinical domain. With
that in mind, we plan to analyze further EVENT-
EVENT relations differentiating events as verbal
and non-verbal events.

Acknowledgments

This work was supported by JST CREST Grant
Number JPMJCR1513, Japan. We thank the
anonymous reviewers for their insightful com-
ments and suggestions.

References
James F Allen. 1990. Maintaining knowledge about
temporal intervals. In Readings in qualitative rea-
soning about physical systems, pages 361–372. El-
sevier.

Roger W. Andersen. 1990. Unpublished lecture in the

seminar on the acquisition of tense and aspect.

Steven Bethard, Leon Derczynski, Guergana Savova,
James Pustejovsky, and Marc Verhagen. 2015.
In Pro-
Semeval-2015 task 6: Clinical tempeval.
ceedings of the 9th International Workshop on Se-
mantic Evaluation (SemEval 2015), pages 806–814.

Steven Bethard, Guergana Savova, Wei-Te Chen, Leon
Derczynski, James Pustejovsky, and Marc Verhagen.
2016. Semeval-2016 task 12: Clinical tempeval. In
Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016), pages 1052–
1062.

Steven Bethard, Guergana Savova, Martha Palmer,
and James Pustejovsky. 2017. Semeval-2017 task
the
12: Clinical
11th International Workshop on Semantic Evalua-
tion (SemEval-2017), pages 565–572.

In Proceedings of

tempeval.

Veera Raghavendra Chikka. 2016.

Cde-iiith at
semeval-2016 task 12: Extraction of temporal in-
formation from clinical documents using machine
In Proceedings of the 10th
learning techniques.
International Workshop on Semantic Evaluation
(SemEval-2016), pages 1237–1240.

Francisco Costa and Ant´onio Branco. 2012. Aspectual
In Pro-
type and temporal relation classiﬁcation.
ceedings of the 13th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 266–275. Association for Computa-
tional Linguistics.

Dmitriy Dligach, Timothy Miller, Chen Lin, Steven
Bethard, and Guergana Savova. 2017. Neural tem-
poral relation extraction. In Proceedings of the 15th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics: Volume 2, Short
Papers, volume 2, pages 746–751.

Jason Alan Fries. 2016. Brundleﬂy at semeval-2016
task 12: Recurrent neural networks vs. joint infer-
ence for clinical temporal information extraction.

Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid ´O S´eaghdha, Sebastian
Pad´o, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2009.
Semeval-2010 task 8:
Multi-way classiﬁcation of semantic relations be-
In Proceedings of
tween pairs of nominals.
the Workshop on Semantic Evaluations: Recent
Achievements and Future Directions, pages 94–99.

Hee-Jin Lee, Hua Xu, Jingqi Wang, Yaoyun Zhang,
Sungrim Moon, Jun Xu, and Yonghui Wu. 2016.
Uthealth at semeval-2016 task 12: an end-to-end
system for temporal information extraction from
clinical notes. In Proceedings of the 10th Interna-
tional Workshop on Semantic Evaluation (SemEval-
2016), pages 1292–1297.

Artuur Leeuwenberg and Marie-Francine Moens.
2016. Kuleuven-liir at semeval 2016 task 12: De-
tecting narrative containment in clinical records. In
Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016), pages 1280–
1285.

Artuur Leeuwenberg and Marie-Francine Moens.
2017. Structured learning for temporal relation ex-
traction from clinical records. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics.

Peng Li and Heng Huang. 2016. Uta dlnlp at semeval-
2016 task 12: deep learning based natural language
processing system for clinical information identiﬁ-
cation from clinical notes and pathology reports. In
Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016), pages 1268–
1273.

Ping Li and Yasuhiro Shirai. 2000. The acquisition of
lexical and grammatical aspect, volume 16. Walter
de Gruyter.

63Chen Lin, Timothy Miller, Dmitriy Dligach, Steven
Bethard, and Guergana Savova. 2016.
Improving
temporal relation extraction with training instance
augmentation. In Proceedings of the 15th Workshop
on Biomedical Natural Language Processing, pages
108–113.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efﬁcient estimation of word represen-
tations in vector space. CoRR abs/1301.3781.

Makoto Miwa and Mohit Bansal. 2016. End-to-end re-
lation extraction using lstms on sequences and tree
structures. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 1105–1116. Asso-
ciation for Computational Linguistics.

James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-
Iso-timeml: An international
In LREC, vol-

rent Romary. 2010.
standard for semantic annotation.
ume 10, pages 394–397.

James Pustejovsky and Amber Stubbs. 2011. Increas-
ing informativeness in temporal annotation. In Pro-
ceedings of the 5th Linguistic Annotation Workshop,
pages 152–160.

Mohammed Saeed, Mauricio Villarroel, Andrew T
Reisner, Gari Clifford, Li-Wei Lehman, George
Moody, Thomas Heldt, Tin H Kyaw, Benjamin
Moody, and Roger G Mark. 2011. Multiparameter
intelligent monitoring in intensive care ii (mimic-ii):
a public-access intensive care unit database. Critical
care medicine, 39(5):952.

William F Styler IV, Steven Bethard, Sean Finan,
Martha Palmer, Sameer Pradhan, Piet C de Groen,
Brad Erickson, Timothy Miller, Chen Lin, Guergana
Savova, et al. 2014. Temporal annotation in the clin-
ical domain. Transactions of the Association for
Computational Linguistics, 2:143.

Naushad UzZaman, Hector Llorens, Leon Derczyn-
ski, James Allen, Marc Verhagen, and James Puste-
jovsky. 2013. Semeval-2013 task 1: Tempeval-3:
Evaluating time expressions, events, and temporal
In Second Joint Conference on Lexical
relations.
and Computational Semantics (* SEM), Volume 2:
Proceedings of the Seventh International Workshop
on Semantic Evaluation (SemEval 2013), volume 2,
pages 1–9.

Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 task 15: Tempeval tempo-
In Proceedings of the
ral relation identiﬁcation.
4th international workshop on semantic evaluations,
pages 75–80.

Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In Proceedings of the 5th international
workshop on semantic evaluation, pages 57–62.

64