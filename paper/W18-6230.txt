DataSEARCH at IEST 2018: Multiple Word Embedding based Models

for Implicit Emotion Classiﬁcation of Tweets with Deep Learning

Yasas Senarath

University of Moratuwa,

Sri Lanka

Uthayasanker Thayasivam

University of Moratuwa,

Sri Lanka

wayasas.13@cse.mrt.ac.lk

rtuthaya@cse.mrt.ac.lk

Abstract

This paper describes an approach to solve im-
plicit emotion classiﬁcation with the use of
pre-trained word embedding models to train
multiple neural networks. The system de-
scribed in this paper is composed of a sequen-
tial combination of Long Short-Term Memory
and Convolutional Neural Network for feature
extraction and Feedforward Neural Network
for classiﬁcation.
In this paper, we success-
fully show that features extracted using multi-
ple pre-trained embeddings can be used to im-
prove the overall performance of the system
with Emoji being one of the signiﬁcant fea-
tures. The evaluations show that our approach
outperforms the baseline system by more than
8% without using any external corpus or lex-
icon. This approach is ranked 8th in Im-
plicit Emotion Shared Task (IEST) at WASSA-
2018.

1

Introduction

Emotion classiﬁcation is a major area of interest
within the ﬁeld of Sentiment Analysis (SA). So-
cial media is a great source of emotional content
since people are willing to publish their views on
them. Twitter is one such platform which enables
users to publish micro-blogs otherwise known as
Tweets. Although, the tweets are limited by the
number of characters, when viewed as a group it
can be very signiﬁcant. Every day, on average,
around 500 million tweets are tweeted on Twit-
ter. This has attracted much interest from both
academia and industries to study about opinions
in tweets.

Tweets can generally be considered to contain
textual content. However, tweet text is usually in-
formal containing much casual forms and emoji,
thus bringing challenges in research.

Implicit emotions play a major challenge in
emotion identiﬁcation process in tweets. This is

due to the informal nature of the tweet and lack of
methods to properly model such sentences. Here
the term “implicit emotion” can be deﬁned as the
emotion conveyed in the text without stating the
words denoting the emotion directly.

There is an effect of implicit emotions on opin-
ion analysis tasks such as emotion identiﬁca-
tion and emotional intensity prediction. How-
ever, techniques for modeling implicit emotions
in tweets lack the sufﬁcient performance. There-
fore, this study makes a major contribution to re-
search by exploring methods for properly model-
ing a tweet.

Implicit Emotion Shared Task (IEST) (Klinger
et al., 2018) hosted by WASSA-20181 poses a sim-
ilar task of ﬁnding the emotion expressed in a
tweet out of six basic emotions without the use
of the word denoting the emotion. This paper
presents our approach to solve the above problem.
We were ranked 8th in the competition related to
this task.

Artiﬁcial Neural Networks (ANN) has shown to
perform better than conventional machine learn-
ing algorithms and has been used in variety of
Natural Language Processing tasks (Young et al.,
2017). One of the primary objectives of using neu-
ral networks is to model the non-linear relation-
ships in data, which is observed in textual content
frequently. Up to now, a number of studies con-
ﬁrmed the effectiveness of neural networks as fea-
ture extractors rather than the ﬁnal classiﬁer for
opinion mining. A variety of neural network clas-
siﬁers has been applied to similar tasks such as
emotion identiﬁcation, polarity classiﬁcation, and
other text classiﬁcation tasks. Feedforward Neural
Networks (FNN), Convolutional Neural Networks
(CNN) (Kim, 2014), Long Short-Term Memory
(LSTM) (Tran and Cheng, 2018; Socher et al.,

1http://implicitemotions.wassa2018.com

Proceedingsofthe9thWorkshoponComputationalApproachestoSubjectivity,SentimentandSocialMediaAnalysis,pages211–216Brussels,Belgium,October31,2018.c(cid:13)2018AssociationforComputationalLinguisticshttps://doi.org/10.18653/v1/P172112013) networks are commonly used in recent re-
lated work. Furthermore, researchers have studied
much complex forms of Neural Networks by com-
bining CNN and LSTM in different ways.

The rest of the paper is organized as follows:
Section 2 will provide a brief description on the
dataset, Section 3 describes the system architec-
ture, Section 4 reports the results and analysis of
our system, ﬁnally we conclude our work in Sec-
tion 5 along with a discussion on further improve-
ments.

2 Dataset
The dataset is labeled based on the emotion word
present in the tweet before replacing that emotion
word in the text with a placeholder. The dataset
is labeled for six basic emotions: Anger, Sad, Joy,
Fear, Disgust and Surprise. The complete details
of the dataset can be found in the task description
paper (Klinger et al., 2018).

3 System Description
The system consists three different components:
the preprocessor, feature extractor and classiﬁer.
In this study we considered that effective classi-
ﬁer trained on the training dataset could be used
as a feature extractor as well. This section will
be subdivided to accommodate the stated compo-
nents separately.

3.1 Preprocessing
The tweets contained in the dataset are prepro-
cessed to an extent. In the dataset, the URLs were
replaced with “http://url.removed”, mentions with
“@USERNAME” and new lines with “[NEW-
LINE]”. Additionally, we have performed follow-
ing preprocessing on the dataset: changing target
term “[#TRIGGERWORD#]” to “ trigger ” and
“[NEWLINE]” to “ newline ”. These changes
were performed to correct the tokenization. We
have used TweetTokenizer 2 available in python
NLTK library for tokenization.
In addition to
NLTK tokenizer we evaluated our system using a
dictionary based tokenizer.

3.2 Feature Extraction
A number of techniques have been developed to
extract features for the classiﬁer, some of which
are trained on the dataset in order to create fea-
tures explicitly. The most basic feature unit is the

2https://www.nltk.org/api/nltk.tokenize.html

Model

GW2V Word2Vec

ID
Corpus
TW2V Word2Vec Twitter
Google
News
Wiki
Wiki
Subword
Glove
Twitter
Word2Vec Twitter

TGv
E2V

fastText

fastText

WSFT

WFT

Corpus Size Dim
400M tweets
400

100B words

16B tokens

16B tokens

2B tweets
1661 emoji

300

300

300

200
300

Table 1: Embedding Models used in Experiments

words. We used words to obtain the Word Vectors
from multiple word embedding models trained on
different corpses. Although our best performing
system was based on word embeddings we devel-
oped and evaluated other features as well. In this
section we will describe all the features that we
have tried out.

Word Vectors: Table 1 summarizes all of the
word embedding models we used in our imple-
mentation. It illustrates the word embedding tech-
niques and the dataset it is trained on and its spe-
ciﬁc features as well. Additionally, it provides
an identiﬁer which we will be using to identify
that word embedding in the next sections. Tweets
can be represented as a word vector using the
word2vec approach (Mikolov et al., 2013). GW2V
has been obtained by training Word2vec on part
of Google News dataset3. Similarly, Godin et al.
(2015) has provided a word2vec model trained
on twitter dataset (TW2V)4. Furthermore, fast-
Text (Joulin et al., 2016) models are trained on
trained on UMBC webbase corpus and statmt.org
news dataset with and without subword infoma-
tion (WSFT and WFT)5 (Mikolov et al., 2018).
Glove (Pennington et al., 2014) embedding (TGv)
has been trained on twitter corpus containing two
billion tweets6. Eisner et al. (2016) has released
emoji2vec (E2V)7 a pre-trained embedding model
for all Unicode emoji. Intended means of using
E2V is as an extension to GW2V.

Transfer Features: Features generated by
training a neural classiﬁer on the training dataset,
obtained from the last layer (layer before the out-
put later).

3https://code.google.com/archive/p/word2vec/
4https://www.fredericgodin.com/software/
5https://fasttext.cc/docs/en/english-vectors.html
6https://nlp.stanford.edu/projects/glove/
7https://github.com/uclmr/emoji2vec

212Figure 1: High-level LSTM-CNN Architecture

Section
LSTM

CNN

Pooling

Dense Layer

Output Layer

Parameter
Num. of units
Num. of ﬁlters
Kernel Sizes
Method
Num. of units
Activation
Num. of Units
Activation

Value
250
350
2, 3, 5
Max
50
ReLU
6
Softmax

Table 2: Network Parameters for LSTM-CNN

3.3 Classiﬁers
The trial data provided in the competition is rea-
sonably large for evaluating the model perfor-
mance. As described in Section 3.2, different com-
binations of feature extractors were used. Follow-
ing the feature extraction process, extracted fea-
tures were used to train various neural networks.

3.3.1 LSTM-CNN
Two of the commonly used techniques to model
text documents are Convolutional Neural Net-
works (CNN) and Long short-term memory
(LSTM) networks. Rather than developing the
neural network with CNN and LSTM separately,
the proposed system is developed using a combi-
nation of CNN and LSTM. Figure 1 illustrates the
proposed LSTM-CNN architecture. The hyper pa-
rameters selected for this network are tabulated in
Table 2.

The network parameters are learned by opti-
mizing the categorical cross-entropy between ac-
tual and predicted category. Optimization is per-

Section

Hidden Layer 1

Hidden Layer 2

Parameter
Num. of Units
Activation
Num. of Units
Activation

Value
50
ReLU
25
ReLU

Table 3: Network parameters for FNN

formed through back propagation via mini-batch
gradient descent. A batch size of 256 was used
with 5 epochs to train the network. Furthermore, a
dropout layer with dropout rate 0.2 is used before
the dense layer when training. Adam optimization
algorithm (Kingma and Ba, 2014) is used in this
study for optimization . We have trained and eval-
uated the system with each of the word embedding
models stated in Table 1.

Figure 2: High-level FNN Architecture

3.3.2 Feed-forward neural network
Previous studies has shown that feed-forward neu-
ral network (FNN), can be used for modeling text

213ID

Features

T W 2V
GW 2V + E2V

MT W 2V
ME2V
MGW 2V GW 2V
MW T F W T F
MW ST F W ST F
MT Gv

T Gv

Baseline

Macro
Precision
65.9
63.7
64.4
65.3
62.5
63.4
60.1

Trial Set
Macro
Recall
65.5
63.6
62.6
64.1
62.0
63.2
60.1

Macro

F1
65.5
63.6
62.9
64.3
62.0
63.2
60.1

Macro
Precision
67.1
65.6
65.4
65.5
63.9
63.9
-

Test Set
Macro
Recall
67.0
65.1
63.7
65.1
62.2
63.9
-

Macro

F1
67.0
65.2
63.8
65.2
62.5
63.9
59.8

Table 4: Evaluation of LSTM-CNN for different word embeddings

Features

F (MT W 2V )
++ F (ME2V )
F (MT W 2V )
++ F (MW T F )
F (ME2V )
++ F (MW T F )
F (ME2V )
++ F (MT W 2V )
++ F (MW T F )
Baseline
IEST@WASSA
2018 Best

Macro
Precision

Macro
Recall

Macro

F1

68.0

67.9

67.1

67.8

67.8

66.7

67.8

67.8

66.8

68.3

68.1

68.1

-

-

-

-

59.8

71.45

Table 5: Results of FNN for different feature combina-
tions

documents (Bengio et al., 2003). Furthermore,
Tang et al. (2014) has used deep neural network
for learning sentiment-speciﬁc word embedding.

The proposed architecture of FNN is shown in
Figure 2 and related hyper-parameters used in ﬁnal
system are provided in Table 3.

Training parameters of the FNN is similar to
that of LSTM-CNN model. Dropout layers were
used in training after each hidden layer with
dropout rate of 0.5. Features used to train the FNN
are transfered from dense layer of LSTM-CNN
models trained with different embedding mod-
els. Several feature vectors obtained from LSTM-
CNN are concatenated and provided as input to
FNN. The ﬁnal system used features from LSTM-
CNN models trained with embeddings: TW2V,
GW2V + E2V and WFT.

3.3.3 Optimization
Hyper-parameters of the neural networks should
be optimized to gain better performance. They
were selected based on the results on the trial
set and were optimized with both manual pro-
cesses and with Tree of Parzen Estimators
(TPE) (Bergstra et al., 2011). However, due to the
lack of processing power and time limitations we
were not able to perform a comprehensive analysis
on different hyper-parameter variations.
3.3.4
Python is used to implement the system with
Keras
al., 2015) with Tensor-
ﬂow (Abadi et al.)
the backend and
Scikit-learn (Pedregosa et al., 2011) being the
mostly used external libraries. Hyper-parameter
optimization is performed with Hyperopt
li-
brary (Bergstra et al., 2013). Any hyper-parameter
not mentioned in Section 3 defaults to their default
values in respective library. Furthermore, we made
our source code and trained models available on-
line 8.

Implementation Details

(Chollet

as

et

4 Evaluation and Discussion

The ﬁrst set of analyses examined the impact of
LSTM-CNN models trained with different word
embedding models. The results of the LSTM-
CNN analysis are set out in Table 4. The train
set evaluation is performed by training model on
training dataset evaluating on trial set. Test set
training data comprised of both training data and
trial data.

It is apparent from this Table 4 that the model
has performed similarly for both trial dataset and
test dataset, achieving similar/ better F1 scores and
variations from one feature to another. We observe

8https://github.com/ysenarath/opinion-lab

214the best performance of the system when using
Word2vec trained on twitter. This could be due
to the fact that it contains in-domain vocabulary.
What stands out in the table is the improvement of
results of MGW 2V with inclusion of Emoji2Vec.
It can thus be suggested that Emoji provide a sub-
stantial support to ﬁnding emotion in implicit con-
text. Furthermore, we observe that MW T F per-
forms better than MW ST F and can be suggested
that sub-word information provided by the embed-
ding is not important in crating the model. An-
other noteworthy observation is that all the mod-
els indicated in Table 4 outperforms the baseline
model in both trial and test cases, thus proving the
effectiveness of the proposed model itself for im-
plicit emotion prediction task.

In the next part of the analysis we used FNN
trained using features extracted from LSTM-CNN
models. Table 5 provides the evaluation results of
these models on the test set. ‘++’ is used to repre-
sent vector concatenation operation and f (M ) de-
notes a function that extracts the learned features
form model M from the last dense layer in the
neural network for a given input text. The evalua-
tions are performed using the three best perform-
ing LSTM-CNN models: MT W 2V , MW T F and
ME2V . We have omitted MGW 2V for this anal-
ysis since the word vector used to train MGW 2V is
already contained in ME2V .

Results from Table 4 can be compared with the
results in Table 5 which shows that the perfor-
mance (precision, recall and F1) of models in the
latter has improved than the individual model vari-
ants. Closer inspection of the Table 5 shows that
the best models are obtained when features from
MT W 2V and ME2V are used together. The overall
best performance is obtained when features from
MT W 2V , ME2V and MW T F are concatenated to-
gether.

5 Conclusion

This study is set out to propose a system for im-
plicit emotion classiﬁcation with state-of-the-art
neural network classiﬁers. Additionally we in-
vestigate the effectiveness of combinations of dif-
ferent pre-trained embedding for implicit emotion
classiﬁcation of Tweets. In this study, a LSTM and
a CNN are combined sequentially and trained with
different pre-trained word embeddings to be used
as a feature generator for a secondary feedforward
neural network classiﬁer to make the ﬁnal classi-

ﬁcation. The results of this study indicate that the
system performs well in implicit emotion identiﬁ-
cation and beats the baseline system by about 8%
on the test set.

Furthermore the experiments support the idea
that features extracted from several pre-trained
word embedding models can be effectively com-
bined to improve the overall classiﬁcation per-
formance . The most obvious ﬁnding to emerge
from this study are that in-domain word embed-
dings and Emoji embeddings contribute in im-
proving performance of implicit emotion classi-
ﬁcation. The generalisability of these results is
subject to certain limitations. For instance, this
research does not focus on ﬁne-tuning the model
architectures to different word-embeddings. Al-
though this gives a general ground in comparing
word-embeddings for this task, it does not provide
the justiﬁcation for individual capabilities. Further
research will have to be conducted in order to de-
termine the best conﬁgurations for individual word
embeddings and feature combinations to improve
the overall performance of the system.

Acknowledgments

The research was supported by the DataSEARCH
research centre for data science, engineering, and
analytics at University of Moratuwa, Sri Lanka.
We thank all the contributions made by the group
to this research. We would also like to thank the
organizers of IEST at WASSA-2018 for organiz-
ing this shared task.

References
Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng
Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard,
et al. Tensorﬂow: a system for large-scale machine
learning.

Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. Journal of machine learning research,
3(Feb):1137–1155.

James Bergstra, Dan Yamins, and David D Cox. 2013.
Hyperopt: A python library for optimizing the
hyperparameters of machine learning algorithms.
Citeseer.

James S Bergstra, R´emi Bardenet, Yoshua Bengio, and
Bal´azs K´egl. 2011. Algorithms for hyper-parameter
In Advances in neural information
optimization.
processing systems, pages 2546–2554.

215Franc¸ois Chollet et al. 2015. Keras. https://

github.com/fchollet/keras.

empirical methods in natural language processing,
pages 1631–1642.

Duyu Tang, Furu Wei, Bing Qin, Ting Liu, and Ming
Zhou. 2014. Coooolll: A deep learning system for
In Proceedings of
twitter sentiment classiﬁcation.
the 8th international workshop on semantic evalua-
tion (SemEval 2014), pages 208–212.

Nam Khanh Tran and Weiwei Cheng. 2018. Mul-
tiplicative tree-structured long short-term memory
networks for semantic representations. In Proceed-
ings of the Seventh Joint Conference on Lexical and
Computational Semantics, pages 276–286.

Tom Young, Devamanyu Hazarika, Soujanya Poria,
and Erik Cambria. 2017. Recent trends in deep
learning based natural language processing. arXiv
preprint arXiv:1708.02709.

Ben Eisner, Tim Rockt¨aschel, Isabelle Augenstein,
Matko Boˇsnjak,
and Sebastian Riedel. 2016.
emoji2vec: Learning emoji representations from
their description. arXiv preprint arXiv:1609.08359.

Fr´ederic Godin, Baptist Vandersmissen, Wesley
De Neve, and Rik Van de Walle. 2015. Multimedia
lab @ acl wnut ner shared task: Named entity recog-
nition for twitter microposts using distributed word
representations. In Proceedings of the Workshop on
Noisy User-generated Text, pages 146–153.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2016. Bag of tricks for efﬁcient text
classiﬁcation. arXiv preprint arXiv:1607.01759.

Yoon Kim. 2014.

works for sentence classiﬁcation.
arXiv:1408.5882.

Convolutional neural net-
arXiv preprint

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Roman Klinger, Orph´ee de Clercq, Saif M. Moham-
mad, and Alexandra Balahur. 2018.
Iest: Wassa-
2018 implicit emotions shared task. In Proceedings
of the 9th Workshop on Computational Approaches
to Subjectivity, Sentiment and Social Media Anal-
ysis, Brussels, Belgium. Association for Computa-
tional Linguistics.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
Efﬁcient estimation of word
arXiv preprint

frey Dean. 2013.
representations in vector space.
arXiv:1301.3781.

Tomas Mikolov, Edouard Grave, Piotr Bojanowski,
Christian Puhrsch, and Armand Joulin. 2018. Ad-
vances in pre-training distributed word representa-
In Proceedings of the International Confer-
tions.
ence on Language Resources and Evaluation (LREC
2018).

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learning
in Python. Journal of Machine Learning Research,
12:2825–2830.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
In Proceedings of the 2013 conference on
bank.

216