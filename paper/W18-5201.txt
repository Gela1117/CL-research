Argumentative Link Prediction using Residual Networks and

Multi-Objective Learning

Andrea Galassi1, Marco Lippi2, and Paolo Torroni1

1Department of Computer Science and Engineering DISI
{a.galassi, paolo.torroni}@unibo.it
2Department of Sciences and Methods for Engineering

University of Bologna

University of Modena and Reggio Emilia

marco.lippi@unimore.it

Abstract

We explore the use of residual networks for ar-
gumentation mining, with an emphasis on link
prediction. The method we propose makes no
assumptions on document or argument struc-
ture. We evaluate it on a challenging dataset
consisting of user-generated comments col-
lected from an online platform. Results show
that our model outperforms an equivalent deep
network and offers results comparable with
state-of-the-art methods that rely on domain
knowledge.
Introduction

1
Argumentation mining is a growing sub-area of ar-
tiﬁcial intelligence and computational linguistics
whose aim is to automatically extract arguments
from generic textual corpora (Lippi and Torroni,
2016a). The problem is typically broken down
into focused sub-problems such as the identiﬁca-
tion of sentences containing argument components
like claims and premises, of the boundaries of ar-
gument components within such sentences, and
the prediction of the argumentative structure of the
document at hand.

In spite of signiﬁcant results achieved in com-
ponent identiﬁcation tasks, such as claim/evidence
detection (Rinott et al., 2015; Lippi and Torroni,
2015; Park and Cardie, 2014; Park et al., 2015b;
Stab and Gurevych, 2014), classiﬁcation (Eckle-
Kohler et al., 2015; Niculae et al., 2017) and
boundary detection (Sardianos et al., 2015; Levy
et al., 2014; Lippi and Torroni, 2016b; Habernal
and Gurevych, 2017), comparatively less progress
has been made in the arguably more challeng-
ing argument structure prediction task (Cabrio and
Villata, 2012; Stab and Gurevych, 2014).

Again due to the challenging nature of the
general argumentation mining problem, solutions
have typically addressed a speciﬁc genre or ap-
plication domain, such as legal texts (Mochales

Palau and Moens, 2011), persuasive essays (Stab
and Gurevych, 2017), or Wikipedia articles (Levy
et al., 2014; Rinott et al., 2015) and have heav-
ily relied on domain knowledge. One particu-
lar aspect of the domain is the argument model.
While argumentation as a discipline has devel-
oped rather sophisticated argument models, such
as Toulmin’s (1958), the majority of the available
argumentation mining data sets refer to ad-hoc,
usually simpler argument models, often in an ef-
fort to obtain a reasonable inter-annotator agree-
ment. Another crucial aspect is the document
structure. For instance, in some domains, certain
argument components occupy a speciﬁc position
in the document.

Moreover, until

recently, approaches have
mostly used traditional methods such as support
vector machines,
logistic regression and naive
Bayes classiﬁers. Only in the last couple of years
the ﬁeld has started to look more systematically
into neural network-based architectures, such as
long short-memory networks and convolutional
neural networks, and structured output classiﬁers.
The aim of this study is to investigate the appli-
cation of residual networks–a deep neural network
architecture not previously applied to this domain–
to a challenging structure prediction task, namely
link prediction. Our ambition is to deﬁne a model
that does not exploit domain-speciﬁc, highly en-
gineered features, or information on the underly-
ing argument model, and could thus be, at least
in principle, of general applicability. Our results
match those of state-of-the-art methods that rely
on domain knowledge, but use much less a-priori
information.

The next section reviews recent applications of
neural networks to argumentation mining. Sec-
tion 3 presents our model, Section 4 the bench-
mark, and Section 5 discusses results. Section 6
concludes.

Proceedingsofthe5thWorkshoponArgumentMining,pages1–10Brussels,Belgium,November1,2018.c(cid:13)2018AssociationforComputationalLinguistics12 Related work

The application of neural network architectures
in argumentation mining is relatively recent. A
study most closely related to ours was presented
by Niculae et al. (2017) and will be described
in greater detail in Section 4. The authors pro-
pose a structured learning framework based on
factor graphs. Their approach imposes constraints
to the graph according to the underlying argu-
ment model, and it includes a joint optimiza-
tion method based on the AD3 algorithm (Mar-
tins et al., 2015), structured Support Vector Ma-
chines (Tsochantaridis et al., 2005) and Recurrent
Neural Networks (Rumelhart et al., 1986). Link
prediction and argument component classiﬁcation
are performed jointly, reaching state-of-the-art re-
sults on two distinct corpora.
In contrast to our
method, Niculae et al.’s heavily relies on a-priori
knowledge.

In the domain of persuasive essays, Eger et al.
(2017) consider several sub-tasks of argumenta-
tion mining, making use of various neural archi-
tectures. These include neural parsers (Dyer et al.,
2015; Kiperwasser and Goldberg, 2016), LSTMs
for joint entity and relation extraction (LSTM-
ER) (Miwa and Bansal, 2016), and Bidirectional
LSTM coupled with Conditional Random Fields
and Convolutional Neural Networks (BLCC) (Ma
and Hovy, 2016) in a multi-task learning frame-
work (Søgaard and Goldberg, 2016). Eger et al.
conclude that neural networks can outperform
feature-based techniques in argumentation mining
tasks.

Convolutional Neural Networks and LSTMs
have been used by Guggilla et al. (2016) to per-
form claim classiﬁcation, whereas bidirectional
LSTMs have been exploited by Habernal and
Gurevych (2016) to assess the persuasiveness of
arguments. More recently, neural networks have
been applied to the task of topic-dependent ev-
idence detection (Shnarch et al., 2018), improv-
ing the performance on a manually labelled corpus
through the use of unsupervised data. Potash et al.
(2017) have applied Pointer Networks (Vinyals
et al., 2015) to argumentation mining.

Looking beyond argumentation mining, Lei
et al. (2018) reviews the application of several
deep learning techniques for sentiment analysis,
while Conneau et al. (2017) for the ﬁrst time ap-
plies very deep residual networks to NLP-related
task and successfully performs text classiﬁcation

at the character level. Small residual convolu-
tional networks have been successfully applied
by Zhang et al. (2018) to multi-label classiﬁcation
on medical notes and by Huang and Wang (2017)
to distantly-supervised relation extraction, where
a knowledge base is used to generate a noisy set of
positive relations among unlabeled data.

3 Residual networks for argument

mining

Residual networks (He et al., 2016a,b) are a recent
family of deep neural networks that achieved out-
standing results in many machine learning tasks,
in particular in computer vision applications such
as medical imaging (Yu et al., 2017), computa-
tional linguistics (Bjerva et al., 2016), crowd ﬂow
prediction (Zhang et al., 2017), and game play-
ing (Cazenave, 2018; Chesani et al., 2018).

The core idea behind residual networks, illus-
trated by Figure 1, is to create shortcuts that link
neurons belonging to distant layers, whereas stan-
dard feed-forward networks typically link neurons
belonging to subsequent layers only. This kind of
architecture usually results in a speedier training
phase, and it usually allows to train networks with
a very large number of layers. The original ar-
chitecture exploits convolutional layers, but it can
be generalized to dense (fully-connected) layers.
The motivation behind residual networks is that if
multiple non-linear layers can asymptotically ap-
proximate a complex function H(x), they can also
asymptotically approximate its residual function
F (x) = H(x) − x. The original function is there-
fore obtained by simply adding back the residual
value: H(x) = F (x) + x.

The architecture we propose in this paper makes
use of the dense residual network model, along
with an LSTM (Hochreiter and Schmidhuber,
1997), to jointly perform link prediction and argu-
ment component classiﬁcation. More speciﬁcally,
our approach works at a local level on pairs of sen-
tences, without any document-level global opti-
mization, and without imposing model constraints
induced, e.g., by domain-speciﬁc or genre-speciﬁc
hypotheses. For that reason, it lends itself to inte-
gration with more complex systems.

3.1 Model description
One of our aims is to propose a method that ab-
stracts away from a speciﬁc argument model. We
thus reason in terms of abstract entities, such as

2that connect a to b or b to a. In other words, its
domain is composed, according to the underlying
argument model, not only by all the possible link
types (e.g., attack and support), but also by their
opposite types (e.g., attackedBy and supportedBy)
as well as by a category, none, meaning absence
of link in either direction.1

One objective is to establish the value of the link
label La→b for each possible input pair of propo-
sitions (a, b) belonging to the same document D.
Such a link prediction task can be considered as
a sub-task of argument structure prediction. An-
other objective is the classiﬁcation of propositions
and relations, i.e., the prediction of labels Pa, Pb,
Ra→b. That is also jointly performed, as in (Nic-
ulae et al., 2017). Notice, however, that Niculae
et al. do not predict Ra→b relations, but only link
and proposition labels.

3.2 Embeddings and features
Since the purpose of this work is to evaluate deep
residual networks as an instrument for argumen-
tation mining, without resorting to domain- or
genre-speciﬁc information, the system relies on a
minimal set of features that do not require elabo-
rate processing.

Any input token is transformed into a 300-
dimensional embedding by exploiting the GloVe
pre-trained vocabulary (Pennington et al., 2014).
Input sequences are zero-padded to the length of
the longest sequence (153 tokens). The distance
between two propositions could also be relevant to
establishing whether two components are linked.
We thus employed the number of propositions that
separate two given propositions as an additional
feature. Following previous works in the game do-
main, where scalar values have been encoded in
binary form (Silver et al., 2016; Cazenave, 2018;
Chesani et al., 2018), we represented distance us-
ing as a 10-bit array, where the ﬁrst 5 bits are
used in case that the source precedes the target,
and the last 5 bits are used in the opposite case.
In both cases, the number of consecutive “1” val-
ues encodes the value of the distance (distances
are capped by 5). For example, if the target pre-
cedes the source by two sentences, the distance is
−2, which produces encoding 0001100000; if the
source precedes the target by three sentences, the
distance is 3, with encoding 0000011100. In this

1Given the none category, label La→b could, in principle,
be induced by label Ra→b, but it is still convenient to keep
both during the optimization process.

Figure 1: General schema of a residual network with a
single residual block with three hidden layers.

argumentative propositions and the links among
them. Such abstract entities are instantiated into
concrete categories, such as claims and premises,
supports or attacks, as soon as we apply the
method to a domain described by a speciﬁc dataset
whose annotations follow a concrete argument
model. In particular, in this work we instantiate
our model with the categories proposed by Nicu-
lae et al. (2017) for the annotation of the CDCP
corpus.

In general, a document D is a sequence of to-
kens, i.e., words and punctuation marks. An ar-
gumentative proposition a is a sequence of con-
tiguous tokens within D, which represents an ar-
gument, or part thereof. A labeling of propositions
is induced by the chosen argument model. Such a
labeling associates each proposition with the cor-
responding category of the argument component it
contains.

Given two propositions a and b belonging to the
same document, a directed relation from the for-
mer (source) to the latter (target) is represented as
a → b. Reﬂexive relations (a → a) are not al-
lowed.

Each relation a → b is characterized by two la-
bels: a (Boolean) link label, La→b, and a relation
label, Ra→b. The link label indicates the presence
of a link, and is therefore true if there exists a di-
rected link from a to b, and false otherwise. The
relation label instead contains information on the
nature of the link connecting a and b. In particu-
lar, it represents the direct or inverse relation be-
tween the two propositions, according to the links

3way, the Hamming distance between two distance
value encodings is equal to the difference between
the two distance values.

3.3 Residual Network Architecture
The network architecture is illustrated in Figure 2.
It is composed by the following macro blocks:

• two deep embedders, one for sources and
one for targets, that manipulate token embed-
dings;

• a dense encoding layer for feature dimension-

ality reduction;

• an LSTM to process the input sequences;
• a residual network;
• the ﬁnal-stage classiﬁers.

Source and target propositions are encoded sepa-
rately by the ﬁrst three blocks, then they are con-
catenated together, along with the distance, and
given as input to the residual network.

The deep embedders reﬁne the token embed-
dings, thus creating new, more data-speciﬁc em-
beddings. Relying on deep embedders instead
of on pre-trained autoencoders, aims to achieve a
better generality, at least in principle, and avoid
excessive specialization, thus limiting overﬁtting.
The dimensionality reduction operated by the
dense encoding layer allows to use an LSTM with
fewer parameters, which has two positive effects:
it reduces the time needed for training, and again
it limits overﬁtting.

The deep embedders are residual networks
composed by a single residual block, composed by
4 pre-activated time-distributed dense layers. Ac-
cordingly, each layer applies the same transforma-
tion to each embedding, regardless of their posi-
tion inside the sentence. All the layers have 50
neurons, except the last one, which has 300 neu-
rons.

The dense encoding layer reduces the size of
the embedding sequences by applying a time-
distributed dense layer, which reduces the em-
bedding size to 50, and a time average-pooling
layer (Collobert et al., 2011), which reduces the
sequence size to 1/10 of the original. The result-
ing sequences are then given as input to a single
bidirectional LSTM, producing a representation of
the proposition of size 50. Thus, for each proposi-
tion, 153 embeddings of size 300 are transformed

ﬁrst into 153 embeddings of size 50, then into 15
embeddings of size 50, and ﬁnally in a single fea-
ture of size 50.

Source and target features, computed this way,
alongside with the distance encoding, are then
concatenated together and given as input to the
residual network. The ﬁrst level of the network
is a dense encoding layer with 20 neurons, while
the residual block is composed by a layer with 5
neurons and one with 20 neurons. The sums of the
results of the ﬁrst and the last layers of the residual
networks are provided as input to the classiﬁers.

The ﬁnal layers of the system are three indepen-
dent softmax classiﬁers used to predict the source,
the target, and the relation labels. The output of
each classiﬁer is a probability distribution along
all the possible classes of that label. The pre-
dicted class is the one with the highest score. All
these three classiﬁers, which predict labels for two
different tasks, contribute simultaneously to our
learning model. The link classiﬁer is obtained by
summing the relevant scores produced by the rela-
tion classiﬁer.2

All the dense layers use the rectiﬁer activa-
tion function (Glorot et al., 2011), and they ran-
domly initialize weights with He initialization (He
et al., 2015). The application of all non-linearity
functions is preceded by batch-normalization lay-
ers (Ioffe and Szegedy, 2015) and by dropout lay-
ers (Srivastava et al., 2014), with probability p =
0.1.

4 Benchmark
4.1 Dataset
We evaluated our model against the Cornell eRule-
making Corpus (CDCP) (Niculae et al., 2017).
This consists of 731 user comments from a eRule-
making website, for a total of about 4,700 proposi-
tions, all considered to be argumentative.3 The ar-
gument model adopted is the one proposed by Park
et al. (2015a), where links are constrained to form
directed graphs. Propositions are divided into 5
classes: POLICY (17%), VALUE (45%), FACT

2For instance, if our model considers attack and support
relations as the only possible links, and the relation classiﬁer
scores are attack = 0.15, support = 0.2, attackedBy = 0.1,
supportedBy = 0.05, none = 0.5, then the link classiﬁer
scores are: true = 0.35, false = 0.65.

3In an effort to obtain comparable results, we applied
same preprocessing steps described in (Niculae et al., 2017),
enforcing transitive closure and removing nested proposition,
even though our approach does not take into account the ar-
gumentation model, nor its properties.

4Table 1: Experimental dataset composition.

Train Valid.

Split
Documents
513
Propositions 3,338
1438
Values
585
Policies
738
Testimonies
Facts
549
28
References
Couples
30,056
Links
923
888
Reasons
Evidences
35

Test

150
973
491
153
204
124
1
9,484
272
265
7

Total

731
4,779
2160
815
1026
746
32
43,384
1,338
1292
46

68
468
231
77
84
73
3
3,844
143
139
4

Figure 2: A block diagram of the proposed architec-
ture. The ﬁgure shows, next to each arrow, the dimen-
sionality of the data involved, so as to clarify the size
of the inputs and the outputs of each block.

(16%), TESTIMONY (21%) and REFERENCE
(1%). Links are divided between REASON (97%)
and EVIDENCE (3%). Figure 3 shows an anno-
tated document from the CDCP corpus.

Link prediction is a particularly difﬁcult task
in the CDCP dataset, where only 3% of all the
possible proposition pairs (more than 43,000) are
linked. A preliminary analysis of the data suggests
that the number of propositions separating source
and target (distance) could be a relevant feature,
since most linked propositions are not far from
each other. Indeed, as Figure 4 shows, around 70%
of links are between adjacent propositions.

We tokenized documents using a hand-crafted
parser based on the progressive splitting of the to-
kens and search within the GloVe vocabulary. We
preferred not to use existing tools because of the
nature of the data, since the CDCP documents of-
ten do not follow proper writing conventions (such
as the blank space after the period mark), leading
in some cases to a wrong tokenization. As a result,
the number of tokens not contained in the GloVe
dictionary dramatically reduced from 384, origi-
nally obtained with the software provided by Nic-
ulae et al. (2017), to 84. Each of these tokens was
mapped into a randomly-generated embedding.

4.2 Structured Learning
The state of the art for the CDCP corpus is the
work described by the corpus authors themselves
(Niculae et al., 2017). They use a structured learn-
ing framework to jointly classify all the proposi-
tions in a document and determine which ones are
linked together. To perform the classiﬁcation, the
models can rely on many factors and constraints.
The unary factors represent the model’s belief in
each possible class for each proposition or link,
without considering any other proposition or link.
For each link between two propositions, the com-
patibility factors inﬂuence link classiﬁcation ac-
cording to the proposition classes, taking into ac-
count adjacency between propositions and prece-
dence between source and target. The second-
order factors inﬂuence the classiﬁcation of pairs of
links that share a common proposition, by mod-
eling three local argumentation graph structures:
grandparent, sibling and co-parent. Furthermore,
constraints are introduced to enforce adherence to
the desired argumentation structure, according to
the argument model and domain characteristics.

The authors discuss experiments with 6 dif-
ferent models, which differ by complexity (the
type of factors and constraints involved) and by
how they model the factors (SVMs and RNNs).
The RNN models compute sentence embeddings,
by exploiting initialization with GloVe word vec-
tors, while the SVMs models rely on many spe-
ciﬁc features. The ﬁrst-order factors rely on the
same features used by Stab and Gurevych (2017),
both for the propositions and the links. These
are, among the others, unigrams, dependency tu-
ples, token statistics, proposition statistics, propo-

5Figure 3: Argumentation structure in one of the documents of the CDCP corpus.

tion is given by the weighted sum of four differ-
ent components: the categorical cross-entropy on
three labels (source and target categories, link re-
lation category) and an L2 regularization on the
network parameters. The weights of these compo-
nents were, respectively, 1, 1, 10, 10−4.

We performed mini-batch optimization using
Adam (Kingma and Ba, 2014) with parameters
b1 = 0.9 and b2 = 0.9999, and by applying pro-
portional decay of the initial learning rate α0 =
5 × 10−3. Training was early-stopped after 200
epochs with no improvements on the validation
data. We chose the numerous hyper-parameters of
the architecture and of the learning model after an
initial experimental setup phase, based on the per-
formance on the validation set for the link predic-
tion task. Results obtained in this phase conﬁrmed
that the presence of the deep embedder block and
of the distance feature lead to better results.

We compared the results of the residual network
model against an equivalent deep network with
the same number of layers and the same hyper-
parameters, but without the shortcut that charac-
terize the residual network block. We applied two
different training procedures for both this deep
network baseline and the residual network. In par-
ticular, as the criterion for early stopping we used
once the error on link prediction and once the error
on proposition classiﬁcation. In the presentation
of our results we will refer to these two models as
link-guided (LG) and proposition-guided (PG).

Following (Niculae et al., 2017), we measured
the performance of the models by computing the
F1 score for links, propositions, and the aver-
age between the two, in order to provide a sum-
mary evaluation. More speciﬁcally, for the links
we measured the F1 of the positive classes (as
the harmonic mean between precision and recall),

Figure 4: Link distribution in the CDCP dataset with
respect to distance. The distance is considered posi-
tive when the source precedes the target, negative oth-
erwise.

sition location, indicators from hand-crafted lex-
icons and handcrafted ones, shared phrases, sub-
clauses, depth of the parse tree, tense of the main
verb, modal verbs, POS, production rules, type
probability, discourse triplets (Lin et al., 2014),
and average GloVe embeddings. The higher-
order factors exploit the following features be-
tween all three propositions and between each
pair: same sentence indicators, proposition order,
Jaccard similarity, presence of any shared nouns,
and shared noun ratios. The overall feature di-
mensionality is reportedly 7000 for propositions
and 2100 for links, not counting 35 second-order
features.

5 Results

5.1 Experimental setting
We created a validation set by randomly select-
ing documents from the original training split with
10% probability. We used the remaining docu-
ments as training data and the original test split
as is. Table 1 reports the statistics related to the
three splits.

We deﬁned the learning problem as a multi-
objective optimization problem, whose loss func-

6whereas for the propositions we used the score
of each class and then we computed the macro-
average. We also reported the F1 score for each
direct relation class, alongside with their macro-
average.

Since each proposition is involved in many
pairs, both as a source and as a target, its classi-
ﬁcation is performed multiple times. To classify
it uniquely, we considered the average probability
score assigned to each class and we have assigned
the most probable class. That is of course not the
only option. Another possibility could be to assign
the class that results to be the most probable in
most of the cases, thus relying on a majority vote.
A further option could be to simply consider the
label with highest conﬁdence. However, this pro-
cedure might be more sensitive to outliers, because
the misclassiﬁcation of a sentence in just one pair
would lead to the misclassiﬁcation of the sentence,
regardless of all the other pairs. A deeper analysis
of different techniques to address this issues is left
to future research.

5.2 Discussion and analysis
Table 2 summarizes the evaluation of baselines
and residual networks,4 also showing the best
scores obtained by the structured learning conﬁg-
urations presented in (Niculae et al., 2017).

Results highlight how the proposed approach
based on residual networks outperforms the state
of the art for what concerns link prediction. In ad-
dition, residual link-guided network training con-
sistently performs better than both deep networks
baselines in all the three tasks.

As for proposition label prediction, the results
obtained through structured approaches still main-
tain a slight advantage over residual networks.
This could be partially explained by the fact that
hyper-parameter tuning was done with the aim
to select the best model for link prediction.
It
should also be considered that we perform propo-
sition classiﬁcation relying on the merging of la-
bels obtained through local optimization, while
the structured learning approach exploits a global
optimization. Nonetheless, the average score of
residual networks is better than that of structured
4We report the results obtained on just one trained model.
As explained in (Reimers and Gurevych, 2017), due to the
non-deterministic behavior of the neural networks, this scores
are inﬂuenced by the random seed of the training. Evaluat-
ing the same model trained many times with different seeds,
and reporting the average scores would clearly yield a more
robust evaluation.

Figure 5: Confusion matrix for proposition prediction.
Top: baseline networks; middle:
residual networks;
bottom: structured prediction by (Niculae et al., 2017).

thus proving the generality of the ap-

RNNs,
proach.

We shall also remark that our approach can
achieve such results without exploiting any spe-
ciﬁc hypothesis or a-priori knowledge of the
genre or domain. This could be an added value
in contexts where arguments may be laid out
freely, without following a pre-determined argu-
ment model, yet it would be interesting to uncover
the underlying argumentation’s structure.

Results also indicate that the most common mis-
take regards the prediction of facts as values (see
Figure 5). That should come as no surprise, since
VALUE is by far the largest class in the corpus,
and it is therefore also affected by many false pos-
itives. Interestingly, baselines completely avoid to
classify any proposition as a FACT.

As far as relation label prediction is concerned,
this model apparently fails to predict the EVI-
DENCE relation. That negative result was also to
be expected, since such a class is scarcely present
in the whole dataset (less than 1%).

6 Conclusion and future work
We presented the ﬁrst application of residual net-
works in the argumentation mining domain. We
proposed a model that outperforms an equivalent
deep network and competes with state-of-the-art
techniques in a challenging dataset.

Considering that the model makes use of only
one simple feature – the argumentative distance
between two proposition – a natural extension of

7Table 2: F1 scores computed on the test set. For each class, the number of instances is reported in parenthesis.
For the comparison with structured learning, the best scores obtained by any of the structured conﬁgurations are
reported.

Metric
Average (Link and Proposition)
Link (272)
Proposition (973)
VALUE (491)
POLICY (153)
TESTIMONY (204)
FACT (124)
REFERENCE (1)
Relation (272)
REASON (265)
EVIDENCE (7)

Deep Baseline Deep Residual
LG

LG

PG

PG

33.18
22.56
43.79
73.77
73.85
71.36

0
0

11.68
23.35

0

42.88
22.45
63.31
74.45
76.09
65.98

0
100
11.52
23.04

0

47.28
29.29
65.28
72.19
74.36
72.86
40.31
66.67
15.01
30.02

0

46.37
20.76
71.99
73.24
76.43
68.63
41.64
100
10.31
20.62

0

Structured

SVM RNN
50.0
26.7
73.5
76.4
77.3
71.7
42.5
100

43.5
14.6
72.7
73.7
76.8
75.8
42.2
100

this study would be its integration in a more struc-
tured and constrained argumentation framework.
Since in argumentation it is often the case that
single propositions cannot contain all the relevant
information to predict argument components and
relations, it could be useful to provide also the
context of argumentation as an input. Hence, an-
other interesting direction of investigation could
be the integration of the whole document text in
the model.

References
Johannes Bjerva, Barbara Plank, and Johan Bos. 2016.
Semantic tagging with deep residual networks.
In
Proceedings of COLING 2016, the 26th Interna-
tional Conference on Computational Linguistics:
Technical Papers, pages 3531–3541.

Elena Cabrio and Serena Villata. 2012. Combining
textual entailment and argumentation theory for sup-
porting online debates interactions. In Proceedings
of the 50th annual meeting of the Association for
Computational Linguistics (ACL 2012), pages 208–
212, Jeju, Korea. Association for Computational
Linguistics.

T. Cazenave. 2018. Residual networks for computer

go. IEEE Transactions on Games, 10(1):107–110.

F. Chesani, A. Galassi, M. Lippi, and P. Mello. 2018.
Can deep networks learn to play by the rules? a case
study on nine men’s morris. IEEE Transactions on
Games, pages 1–1.

Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.

2011. Natural language processing (almost) from
Journal of Machine Learning Research,
scratch.
12(Aug):2493–2537.

Alexis Conneau, Holger Schwenk, Lo¨ıc Barrault, and
Yann Lecun. 2017. Very deep convolutional net-
works for text classiﬁcation. In Proceedings of the
15th Conference of the European Chapter of the As-
sociation for Computational Linguistics: Volume 1,
Long Papers, volume 1, pages 1107–1116.

Chris Dyer, Miguel Ballesteros, Wang Ling, Austin
Matthews, and Noah A Smith. 2015. Transition-
based dependency parsing with stack long short-
In Proceedings of the 53rd Annual
term memory.
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing (Volume 1: Long
Papers), volume 1, pages 334–343.

Judith Eckle-Kohler, Roland Kluge,

and Iryna
Gurevych. 2015. On the role of discourse markers
for discriminating claims and premises in argumen-
In Proceedings of the 2015 Con-
tative discourse.
ference on Empirical Methods in Natural Language
Processing (EMNLP), page to appear, Lisbon, Por-
tugal. Association for Computational Linguistics.

Steffen Eger,

Johannes Daxenberger,

and Iryna
Gurevych. 2017. Neural end-to-end learning for
In Proceed-
computational argumentation mining.
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), volume 1, pages 11–22.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Deep sparse rectiﬁer neural networks. In Pro-
ceedings of the Fourteenth International Conference
on Artiﬁcial Intelligence and Statistics, volume 15 of
Proceedings of Machine Learning Research, pages
315–323, Fort Lauderdale, FL, USA. PMLR.

8Chinnappa Guggilla, Tristan Miller,

and Iryna
CNN-and LSTM-based claim
Gurevych. 2016.
In Pro-
classiﬁcation in online user comments.
ceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 2740–2751.

Ivan Habernal and Iryna Gurevych. 2016. Which ar-
gument is more convincing? analyzing and predict-
ing convincingness of web arguments using bidirec-
tional lstm. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), volume 1, pages 1589–
1599.

Ivan Habernal and Iryna Gurevych. 2017. Argumenta-
tion mining in user-generated web discourse. Com-
putational Linguistics, 43(1):125–179.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2015. Delving deep into rectiﬁers: Surpass-
ing human-level performance on imagenet classiﬁ-
In Proceedings of the IEEE international
cation.
conference on computer vision, pages 1026–1034.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016a. Deep residual learning for image recog-
nition. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages
770–778.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016b. Identity mappings in deep residual net-
In European Conference on Computer Vi-
works.
sion, pages 630–645. Springer.

Sepp Hochreiter and J¨urgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

YiYao Huang and William Yang Wang. 2017. Deep
residual learning for weakly-supervised relation ex-
traction. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1803–1807.

Sergey Ioffe and Christian Szegedy. 2015. Batch nor-
malization: Accelerating deep network training by
In Proceedings
reducing internal covariate shift.
of the 32nd International Conference on Machine
Learning, volume 37 of Proceedings of Machine
Learning Research, pages 448–456, Lille, France.
PMLR.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and accurate dependency parsing using bidirec-
tional LSTM feature representations. Transactions
of the Association for Computational Linguistics,
4:313–327.

Zhang Lei, Wang Shuai, and Liu Bing. 2018. Deep
learning for sentiment analysis: A survey. Wiley In-
terdisciplinary Reviews: Data Mining and Knowl-
edge Discovery, 0(0):e1253.

Ran Levy, Yonatan Bilu, Daniel Hershcovich, Ehud
Aharoni, and Noam Slonim. 2014. Context depen-
dent claim detection. In COLING 2014, Dublin, Ire-
land, pages 1489–1500. ACL.

Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014.
A pdtb-styled end-to-end discourse parser. Natural
Language Engineering, 20(2):151–184.

Marco Lippi and Paolo Torroni. 2015.

Context-
independent claim detection for argument mining.
In Proceedings of the Twenty-Fourth International
Joint Conference on Artiﬁcial Intelligence, IJCAI
2015, Buenos Aires, Argentina, July 25-31, 2015,
pages 185–191. AAAI Press.

Marco Lippi and Paolo Torroni. 2016a. Argumentation
mining: State of the art and emerging trends. ACM
Trans. Internet Technol., 16(2):10:1–10:25.

Marco Lippi and Paolo Torroni. 2016b. Margot. Ex-

pert Syst. Appl., 65(C):292–303.

Xuezhe Ma and Eduard Hovy. 2016.

End-to-end
sequence labeling via bi-directional LSTM-CNNs-
CRF. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), volume 1, pages 1064–1074.

Andr´e FT Martins, M´ario AT Figueiredo, Pedro MQ
Aguiar, Noah A Smith, and Eric P Xing. 2015. Ad 3:
Alternating directions dual decomposition for map
inference in graphical models. The Journal of Ma-
chine Learning Research, 16(1):495–545.

Makoto Miwa and Mohit Bansal. 2016. End-to-end
relation extraction using LSTMs on sequences and
tree structures. In Proceedings of the 54th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2016, August 7-12, 2016, Berlin, Ger-
many, Volume 1: Long Papers.

Raquel Mochales Palau and Marie-Francine Moens.
2011. Argumentation mining. Artiﬁcial Intelligence
and Law, 19(1):1–22.

Vlad Niculae, Joonsuk Park, and Claire Cardie. 2017.
Argument mining with structured SVMs and RNNs.
In Proceedings of the 55th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2017,
Vancouver, Canada, July 30 - August 4, Volume 1:
Long Papers, pages 985–995. Association for Com-
putational Linguistics.

Joonsuk Park, Cheryl Blake, and Claire Cardie. 2015a.
Toward machine-assisted participation in eRulemak-
ing: An argumentation model of evaluability.
In
Proceedings of the 15th International Conference
on Artiﬁcial Intelligence and Law, pages 206–210.
ACM.

9Joonsuk Park and Claire Cardie. 2014.

Identifying
appropriate support for propositions in online user
In Proceedings of the First Workshop
comments.
on Argumentation Mining, pages 29–38, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Anders Søgaard and Yoav Goldberg. 2016. Deep
multi-task learning with low level tasks supervised
at lower layers. In Proceedings of the 54th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers), volume 2, pages
231–235.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. Journal of Machine Learning Re-
search, 15(1):1929–1958.

Christian Stab and Iryna Gurevych. 2014. Identifying
argumentative discourse structures in persuasive es-
says. In EMNLP 2014, Doha, Qatar, pages 46–56.
ACL.

Christian Stab and Iryna Gurevych. 2017. Parsing ar-
gumentation structures in persuasive essays. Com-
putational Linguistics, 43(3):619–659.

Stephen Edelston Toulmin. 1958. The Uses of Argu-

ment. Cambridge University Press.

Ioannis Tsochantaridis, Thorsten Joachims, Thomas
Hofmann, and Yasemin Altun. 2005. Large mar-
gin methods for structured and interdependent out-
put variables. Journal of machine learning research,
6(Sep):1453–1484.

Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly.
2015. Pointer networks. In Advances in Neural In-
formation Processing Systems, pages 2692–2700.

L. Yu, H. Chen, Q. Dou, J. Qin, and P. A. Heng.
2017. Automated melanoma recognition in der-
moscopy images via very deep residual networks.
IEEE Transactions on Medical Imaging, 36(4):994–
1004.

Junbo Zhang, Yu Zheng, and Dekang Qi. 2017.
Deep spatio-temporal residual networks for citywide
crowd ﬂows prediction. In AAAI, pages 1655–1661.

Xinyuan Zhang, Ricardo Henao, Zhe Gan, Yitong Li,
and Lawrence Carin. 2018. Multi-label learning
from medical plain text with convolutional residual
models. arXiv preprint arXiv:1801.05062.

Joonsuk Park, Arzoo Katiyar, and Bishan Yang. 2015b.
Conditional random ﬁelds for identifying appropri-
ate types of support for propositions in online user
comments. In Proceedings of the Second Workshop
on Argumentation Mining. Association for Compu-
tational Linguistics.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global Vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Peter Potash, Alexey Romanov, and Anna Rumshisky.
2017. Here’s my point: Joint pointer architecture for
argument mining. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1364–1373.

Nils Reimers and Iryna Gurevych. 2017. Reporting
score distributions makes a difference: Performance
study of lstm-networks for sequence tagging.
In
Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pages
338–348.

Ruty Rinott, Lena Dankin, Carlos Alzate Perez,
Mitesh M. Khapra, Ehud Aharoni, and Noam
Slonim. 2015. Show me your evidence - an auto-
matic method for context dependent evidence detec-
tion. In Proceedings of the 2015 Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP 2015, Lisbon, Portugal, September 17-21,
2015, pages 440–450. The Association for Compu-
tational Linguistics.

David E Rumelhart, Geoffrey E Hinton, and Ronald J
Williams. 1986. Learning representations by back-
propagating errors. Nature, 323(6088):533.

Christos Sardianos, Ioannis Manousos Katakis, Geor-
gios Petasis, and Vangelis Karkaletsis. 2015. Argu-
ment extraction from news. pages 56–66.

Eyal Shnarch, Carlos Alzate, Lena Dankin, Mar-
tin Gleize, Yufang Hou, Leshem Choshen, Ranit
Aharonov, and Noam Slonim. 2018. Will it blend?
blending weak and strong labeled data in a neu-
ral network for argumentation mining. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), volume 2, pages 599–605.

David Silver, Aja Huang, Chris J Maddison, Arthur
Guez, Laurent Sifre, George Van Den Driessche, Ju-
lian Schrittwieser, Ioannis Antonoglou, Veda Pan-
neershelvam, Marc Lanctot, et al. 2016. Mastering
the game of go with deep neural networks and tree
search. nature, 529(7587):484.

10