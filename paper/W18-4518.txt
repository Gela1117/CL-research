Induction of a Large-Scale Knowledge Graph from the Regesta Imperii

Juri Opitz

Leo Born

Vivi Nastase

Institute for Computational Linguistics

Heidelberg University

69120 Heidelberg

{opitz,born,nastase}@cl.uni-heidelberg.de

Abstract

We induce and visualize a Knowledge Graph over the Regesta Imperii (RI), an important large-
scale resource for medieval history research. The RI comprise more than 150,000 digitized ab-
stracts of medieval charters issued by the Roman-German kings and popes distributed over many
European locations and a time span of more than 700 years. Our goal is to provide a resource for
historians to visualize and query the RI, possibly aiding medieval history research. The resulting
medieval graph and visualization tools are shared publicly.

1

Introduction

We describe here the process of inducing and visualizing a Knowledge Graph (KG) that structures infor-
mation from the Regesta Imperii (RI), an important large-scale resource for medieval history research.
Having important information from the RI in a structured format makes it easier to visualize, and possibly
aid medieval history research.

The Regesta Imperii (RI) comprises documents, regests, that can be seen as abstracts of charters issued
by Roman-German emperors and popes, starting from the Carolingian dynasty to Maximilan I. The
project was initiated in 1829 by a German librarian, Johann Friedrich B¨ohmer, who started to collect
and summarize the charters. Today, more than 175,000 regests have been converted to Unicode and are
stored in a publicly available and continuously increasing online database1 due to the efforts of various
research projects.2

We extract relations and entities from the regest texts and meta information, and build a large-scale
knowledge graph that covers approximately 83% of the documents (Sections 2-3). Information about
the entity types and about the events themselves reveal interesting observations about the behaviour of
emperors and popes with respect to their subjects. The graph can be explored through a web-based
visualization tool (Section 4).

2 Constructing the RI Knowledge Graph
The RI corpus. With regard to the referenced charters,
the RI are unevenly distributed over a large time span (Fig-
ure 1). Many regests reference charters from the later me-
dieval times issued by the emperors Karl IV (1316-1378,
15,595 regests), Friedrich III (1415-1493, 21,477 regests)
and Maximilian I (1459-1519, 22,153 regests) and very of-
ten consist of one, often complicated sentence, describing
an action performed by the issuer (usually an emperor or
pope) towards one or several of his subjects, as can be seen

Figure 1: Distribution of regests over time
with respect to year of charter creation.

This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/

1http://www.regesta-imperii.de/en/home.html.
2Under the umbrella of the German commission for the handling of the Regesta Imperii e. V. (Deutsche Kommission f¨ur die

Bearbeitung der Regesta Imperii e. V.).

ProceedingsofWorkshoponComputationalLinguisticsforCulturalHeritage,SocialSciences,HumanitiesandLiterature,pages159–168SantaFe,NewMexico,USA,August25,2018.159[relverspricht] dem Kurf¨ursten [oarelLudwig von der Pfalz] f¨ur dessen allenfallsige Wahlstimme
ihm alle seine [oaocPrivilegien Reichspfandschaften] (Oppenheim, Gauodernheim, Ober- u. Nieder-
Ingelheim, Winterheim, Dexheim, Nierstein, Schwabsburg, Kaiserslautern, Barr, Ortenberg, Offenburg,
Gengenbach, Zell, Sels) u. s. w. zu [ocbest¨atigen]. Mitsiegler Burggraf Friedrich VI v. N¨urnberg.

[relpromises] the Elector Palatine [oarelLudwig of the Palatinate] that if he gets his vote, that he
[occonﬁrms] all the Palatine Elector’s [oaocprivileges earnests] (Oppenheim, Gauodernheim, Ober- u.
Nieder-Ingelheim, Winterheim, Dexheim, Nierstein, Schwabsburg, Kaiserslautern, Barr, Ortenberg, Of-
fenburg, Gengenbach, Zell, Sels) etc. Also sealed by castle-count Friedrich VI of Nuremberg.

Figure 2: Regest summarizing a charter issued by emperor Sigmund in 1410 and (our) translation. rel is
the main relation, oa (accusative object) indicates whom the emperor is promising something, oc (object
clause) indicates what the emperor is promising. Green/orange indicate named entity persons/locations
found by the automatic tool, which are all accurate in the example.

Kg. Ruprecht gibt seinem kuchenschriber Hermann von M¨ulin und dessen erben f¨ur seine treuen
dienste sein haus und den stall daran zu eigen, “daz gelegen ist in unßer Stad Heidelberg by unsem
marstalle off ein syte an der apoteken und off die andern syten an Zengels des smyts (...)”

King Ruprecht gives to his kitchen-bills-accountant Hermann von M¨ulin and his heirs for his faithful
services his house and barn into his possession “which lies in our city of Heidelberg at the Marstall on
one side the pharmacy and at the other side the blacksmith (...)”

Figure 3: German text and (our) English translation of a regest summarizing a charter issued by king
Ruprecht in 1404. Code is switched to an older German variant in the middle of the text.

in the regest3 in Figure 2. While this regest is syntactically quite complex, it contains only conven-
tional German, where conventional means that syntax and spelling conform with contemporary German.
Other regests, having been created earlier or by different authors, contain words with non-conventional
spelling or nouns in lowercase, which is highly unconventional in contemporary German. An example is
displayed in Figure 3.4 erben (heirs) and dienste (services) are nouns currently written with an uppercase
starting letter; kuchenschriber (kitchen bills accountant) is a (very rare) noun, spelled K¨uchenschreiber
in contemporary German. In the middle of the text the code switches and we ﬁnd a much older variant of
German, a quotation from the original charter of 1404, where spelling and syntactic constructions differ
signiﬁcantly, e.g. Stadt (city) is written Stad and Seite (side) is spelled syte.

element
regests
issuers
locations
tokens
NPs
NEs

sum
179,320
179,320
179,320
16,525,042
4,097,632
1,977,866

Corpus statistics are summarized in Table 1.5
We ﬁnd more than 16 million tokens and al-
most 2 million named entity mentions in the RI.
Because the RI stem from different authors and
times, the spelling of words can be very variable.
For example, there are many spelling variants of
the Austrian city Innsbruck (Ynnsbrug, Ynsbrug,
Innsbruck, Insprugk, etc.). Code-switching is
ubiquitous not only from author to author but
also inside a regest, where the text often contains quotes in Latin and medieval German, taken from
the original charter. Named entities in the RI can be rather complex, for example Adelheid, tochter wei-
land Ulrichs von Minzenberg (English: “Adelheid, daughter of former Ulrich of Minzenberg”) includes
a sub-named entity (Ulrich von Minzenberg). tochter, as a noun, should start with an uppercase letter
and weiland is an outdated and uncommon German adverb, used in the sense of “formerly”.

types
-
419
13,656
488,619
903,383
363,162

σ
-
-
-
150.7
34.7
15.7

Table 1: Corpus statistics.

µ
-
-
-
92.2
22.9
11.0

˜µ
-
-
-
56
14
7

3URI: http://www.regesta-imperii.de/id/1410-08-05_4_0_11_1_0_4_4.
4URI: http://www.regesta-imperii.de/id/1404-06-26_1_0_10_0_0_3588_3584.
5Linguistic annotation was performed with spacy’s German model v2.0.0: https://spacy.io/models/de.

160Preprocessing. We use a state-of-the-art German preprocessing pipeline. The preprocessing model
was trained on contemporary German texts, so it naturally makes more errors on the RI. We manually
examine the outputs for 100 randomly chosen regests, and ﬁnd that, particularly on the ﬁrst sentence, all
steps yield reasonably good results on named entity recognition, and the syntactic dependency parse is
often correct in detecting the ﬁnite main verb and its object, or parts of it.6

Some errors are caused by non-conventional spelling (e.g. lowercased nouns tagged as verbs). We
will address this type of errors in future work, mainly because countless rare nouns and a high rate of
spelling variations make classical normalization techniques very challenging. Applying such techniques,
e.g. techniques based on lexical lookups and minimum edit distance computations (Ristad and Yianilos,
1998; Yujian and Bo, 2007), may even introduce many new errors and manipulate the historic data in
unwanted and difﬁcult-to-detect ways.

We ﬁnd, however, a speciﬁc type of error which is due to an eager sentence splitting model: e.g. a
sentence split often is performed on title preﬁxes. In the RI a title – abbreviated with a period – often
preﬁxes a named entity: e.g. Gf. – Graf (count), Bf. – Bischof (bishop), Eb. – Erzbischof (archbishop).

title/function
queen
king, emperor
duke
duchess
various counts

abbreviation
Kgin.
Kg., Ks.
Hz., Hrz., Hzg.
Hzn., Hzin.
Mgf., Pfgf., Ldgf.,
Pfgr., Mgff., Bggf.
Eb., EB., Bf., BF.,
Erzb.

We introduce three processing steps to minimize
this type of error: (1) iterate through 15,000 ran-
domly sampled regests and aggregate the tokens
occurring directly in front of named entities; (2)
compute their frequencies; (3) ﬁlter instances start-
ing with an uppercase letter, ending with a period,
having a minimum frequency of 5 and a maximum
length of 5 characters. Taking into account only
the preﬁxes starting with an uppercase letter has
the advantage of increased precision (verbs are not
counted). Recall can be increased afterwards by
taking into account the preﬁxes’ lowercase variants
as well (sometimes bishop was abbreviated bf. and
at other times Bf.). After obtaining the possible ab-
breviations a historian helped us in manually ﬁlter-
ing out 250 common abbreviations in the RI (false
positives such as Roman numerals – e.g. XI. – were
discarded in this step). After applying these steps, we obtain an interesting vocabulary of historic German
abbreviations (Table 2). The amount of erroneous sentence splits was reduced by 10%.

Table 2: Some of the automatically collected me-
dieval title abbreviations and their frequency in a
random sample of 15,000 regests.

freq.
7
1,125
369
8
252

(arch-)bishop

121

Edges and vertices. Based on the assumption that the ﬁrst (and often only) sentence contains the
relevant relation information, we process only this sentence. We rely on the fact that the main relation
(edge) between a ruler and its subject entities (the vertices) very frequently occur in a subject-verb-
object format with respect to the ﬁrst ﬁnite verb. As arguments of the relation we consider the ﬁrst
occurring named entity and the named entity which acts as the accusative or dative object of the ﬁrst
ﬁnite verb. Named entities in a comma-separated list or appearing in and-conjunctions of which at
least one has an object dependency relation to the main verb, are all added to the graph separately.
The source is the issuer or emperor, which we assume
to be the subject of the ﬁrst ﬁnite verb and which we
extract from the metadata as it is often omitted in the
regest text (cf. Figure 2). The KG will thus contain two
types of vertices: (i) the issuers (emperor or pope) and
(ii) named entities found by the NLP tool.

oa: Pfalzgrafen Ludwig

root: verspricht

oc: best¨atigen

Edges are weighted: if a named entity is mentioned
ﬁrst after the ﬁnite verb or has an object dependency to
it, the weight of the edge is increased by 0.5; if a named
entity is mentioned ﬁrst after the main verb and lies in

6The ﬁrst two authors are German native speakers.

oa: Reichspfandschaften

Figure 4: Dependency parse for Figure 2.

161translation
conﬁrms
commands
bestows

relation
best¨atigt
beﬁehlt
verleiht
schreibt writes
schenkt
fordert
gew¨ahrt
bittet

donates
demands
permits
asks

count
15,811
8,408
5,796
5,427
2,652
1,619
1,425
1,004

coverage
0.11
0.06
0.04
0.04
0.02
0.01
0.01
0.01

Figure 5: 400 out of 4,948 relations cover over 90%
of the relations induced into our KG.

Table 3: The most frequent relations in our
KG, with (our) English translations.

the object dependency of it, the weight is incremented by 1.0. For example, from Figure 2 (dependency
tree: Figure 4) we retrieve the tuple (Sigmund, promises, Ludwig of the Palatinate), and insert the subject
and object into the graph (if not already contained). If the relation promises already exists between these
entities in the KG, we increment the edge weight by 1.0, since, as can be seen in the example, Ludwig of
the Palatinate was detected both as object of promises (+0.5) and as the ﬁrst named entity (+0.5).

The more promise-events are instantiated between these two entities, the higher the weight of the edge.
This implies that an edge or relation r with weight w between an emperor and one of its subjects means
that in the data there were 1 ≤ n ≤ w instantiations of r detected between these entities and thus the
edge weight can be interpreted both as a reliability measure of the relation and an indicator for how many
times the relation was instantiated.

While we induced 4,948 distinct relations in the KG, the 400 most common relations cover 90%
of the relations induced in the KG (Table 3 and Figure 5). Edge quality will be analyzed in the next
section. Regests that do not contain verbs in the ﬁrst sentence are discarded, e.g. Geburt Karls, des
j¨ungsten Sohnes Kaiser Ludwigs (d. Fr.) und seiner zweiten Gemahlin Judith (English: “Birth of Karl,
the youngest son of emperor Ludwig (the Pious) and his second wife Judith”).7 Applying these steps,
more than 149,203 regests yield a relation, thus 83% of the RI have found their way into our KG.

Edge attributes. Each edge (relation) in the KG can be seen as representing one or more event(s)
between an emperor and one of his subjects. We can associate an attribute list to each edge: date, time and
location of creation of the event are taken from respective ﬁelds in the XML of the regests. We are also
interested in key phrases associated with each event. For example, at one time king Sigmund may have
promised bestowal of land to duke Ludwig and at another time he might have promised him privileges or
ﬁnancial help. To ﬁnd associated key phrases, we formulate a text classiﬁcation task, where we predict
the main relation of a regest (i.e. the ﬁnite verb of the ﬁrst sentence) using a bag of all contained phrases
represented as a binary vector. We consider all phrases tagged as noun chunks or verbs (except the ﬁnite
verb) as features. We only consider relations that occur more than 25 times, leaving us with 397 classes
plus one catch-all class for the less frequent relations. Having ﬁtted a logistic regression model to the task
in a one-vs.-rest setting, we can rank the phrases describing an instantiation of a relation according to the
learned weights for this relation. For example, given that the relation extracted from the example regest
Sigmund→promises→Ludwig of the Palatinate was instantiated only one time, a list associated with this
edge contains the description of one speciﬁc event. The event took place in 1410 at the location Ofen
and, after having queried the model’s coefﬁcients for the relation promise, we see that highly associated
key phrases of the event are the noun chunks Privilegien (priviliges) and Reichspfandschaften (earnests).
If there was another regest with a promise-relation between those same entities, we add another event
description to the edge attribute list and increment the weight of the edge accordingly. The key phrase
ranking relation-prediction approach is evaluated and examined more closely in the next section.

7URI: http://www.regesta-imperii.de/id/0823-06-13_1_0_1_2_1_1_1.

162Kg. RuprechtN OU N→P ROP N gibt seinem kuchenschriberADJ→N OU N HermannN OU N→P ROP N
von M¨ulin und dessen erbenV ERB→N OU N f¨ur seine treuen diensteADJ→N OU N sein haus und den
stallX→N OU N daran zu eigen.
[Kg.]P ERSON [Ruprecht]ORG gibt seinem kuchenschriber [Hermann von M¨ulin]P ERSON und dessen
erben f¨ur seine treuen dienste sein haus und den stall daran zu eigen.

Figure 6: Part-of-speech (top) and NER annotations (bottom). Severe errors are marked in red. An arrow
indicates the correct tag.

root: gibt

sb: Ruprecht

da: seinem

mo: kuchenschriber

oa: erben

mo: sein haus

Figure 7: The erroneous dependency parse for Figure 3. kuchenschriber (kitchen bills accountant) is
mislabeled as the relation modiﬁer (mo) and erben (heirs) is mislabeled as accusative object (oa) – sein
haus (his house) would have been the correct accusative object.

3 Problem Analysis

Despite syntactic parse errors due to the text complexity, we ﬁnd that many named entities are being
captured and the syntactic parse is often partially correct with respect to detecting the direct object of the
ﬁnite verb, as can be seen in Figure 4. In some cases, however, we obtain very erroneous parse trees.

The regest in Figure 3 gets an erroneous dependency tree (Figure 7). The main reasons for this seem to
be errors from preceding pipeline steps (Figure 6): even when disregarding the quote in the older variant
of German, the text is annotated with false part-of-speech tags, propagating errors through the rest of
the pipeline and into the dependency parse. Nevertheless, the relation is correctly induced with a weight
of 0.5 because Hermann von M¨ulin is correctly detected as the ﬁrst named entity after the verb. On the
other hand, the regest in Figure 2, mostly written in today’s conventional German, is correctly parsed
with respect to the main relation, its accusative object and even the distant object clause.

For future work we want to experiment with ﬁne-tuning the preprocessing models for the RI data.
This is a non-trivial task because manual annotation would require domain experts. Other means such
as bootstrapping the NER-pipeline by ﬁltering and crawling part-of-speech patterns may introduce new
errors, possibly even worsening the overall performance of the system, which is difﬁcult to assess with-
out manually labeled data. For further graph reﬁnement one could consider disambiguating the named
entities and merging their nodes. The KG could also be improved by identifying the (minority of) cases
where the regest is not an event description of the emperor unidirectionally interacting with other entities
but vice-versa (e.g. an entity gives a present to the emperor).

Inspection and Evaluation of the Relation Prediction Model. To investigate the performance of the
model on unseen data, we divide the RI into a training set of 100,000 instances and 79,320 test instances,
and use key phrases, issuers, locations and dates as binary features to predict one of the 398 relations
(397 most common with KG-induction frequency of > 25 and one rest-class). This classiﬁcation task
is difﬁcult because the many classes are also unevenly distributed, varying in frequency from 44,303 to
26, with an average of 450.5 and a median of 76 instances per class. The results are shown in Table
4. The relation classiﬁer achieves an accuracy of 0.487 and macro f1 of 0.141, signiﬁcantly higher than
the baselines (majority baseline: 0.003 f1). Both baselines, majority voter and random baseline (drawing
classes according to estimated class probabilities in the training data), lag behind not only the full-feature
model but also a logistic regression model which uses only location or issuer features. We conclude that
certain issuers and locations are more associated with speciﬁc relations than others. Our model’s learnt
coefﬁcients can also be used to investigate these associations. For example, we ﬁnd that the coefﬁcients
for emperor Friedrich III. have the highest value for the relations quittirt (signs), legitimirt (legitimates),

163feature type
all
key phrase
issuer
year
location
maj. baseline
ran. baseline

#features
447,028
436,508
401
821
9,298
-
-

acc. macro f1
0.141
0.113
0.007
0.005
0.007
0.001
0.003

0.487
0.461
0.267
0.258
0.267
0.247
0.008

Table 4: Evaluation of the 398-class relation pre-
diction task.

scenario
all
conﬁdent (@397)
@1
@5
@25
@125

micro error macro error
0.934
0.174
0.0
0.0
0.0
0.104

0.083
0.052
0.0
0.0
0.0
0.03

Table 5: (Pessimistic) estimates of weighted (mi-
cro) and unweighted error (macro) of induced re-
lations due to false part-of-speech tags.@n: con-
sidering the n relations in the KG which were in-
duced most often.

gibt (gives), gebietet (dictates), beﬁehlt (commands), erlaubt (permits), while for emperor Maximilian I.,
there is a different picture and we ﬁnd many ﬁnancial relations such as schuldet (owes), verbucht (books)
and bezahlt (pays). Maximilian I. was well known for his debts he accumulated due to many wars and a
rather extravagant lifestyle and we can see that this is also statistically reﬂected in the RI.

Inspecting the ﬁtted model’s coefﬁcients for the relation verh¨angt (imposes), we see that among highly
associated phrases are die Reichsacht, die Acht, die Aberacht, Klage, den Bann, die Reichsaberacht, das
Anathem, which are mostly outdated German words for banning (excommunicating) somebody (Acht,
Aberacht, Bann) and also anathema (Anathem). Highly weighted terms for the relation describing ver-
leiht (bestow) are das Pallium (a religous clothing), Regalien (regalian rights), ein Wapen8 (a crest),
Lehens- und Landesrecht (land rights), Gerichtsstandsprivileg (court-right), Doktorw¨urde (doctorate)
and Halsgericht or Blutbann, both old German terms in the context of the relation bestows referring to
the right to speak the death sentence (a right which was granted only to selected cities). We conclude
that our binary, bag-of-phrases representation for relation classiﬁcation is a robust and straightforward
way not only to rank key phrases describing medieval events but also to gain deeper insights into the RI.
Quality of Graph Edges We evaluate the quality of graph edges (ﬁrst detected ﬁnite verb in a regest):
(i) to assess the overall quality of edges and (ii) from the point of view of a user or historian, who
might be interested in the quality of high-conﬁdence edges, e.g. he choses to consider only relations
with weight > w. The relation extraction experiments indicate that a falsely induced relation is due to
false positive verb errors from POS tagging. We manually checked the 397 most commonly induced
relations and found 69 to be incorrectly POS tagged. Examples of errors include wittwe (widow) and
archidiacon (archdeacon). Everything that was erroneously tagged as a verb was labeled an error – an
exception were deverbal nouns.9 We assume a pessimistic scenario of all relations with count equal to or
less than 25 having been misclassiﬁed with false POS tags. This scenario is very pessimistic because we
not only ﬁnd many rare and generally uncommon German verbs with varied spellings in this subset (e.g.
vidimiert, vidimirt – a very rare word meaning “he witnesses”) but also deverbal nouns which can be
useful. Thus, given n distinct relations i = 1, ..., n and fi returns the total number of times this relation
was induced in the KG, and gi returns 1 if the relation was likely falsely inserted and 0 if it likely was
correctly inserted (regarding POS annotation), we estimate the weighted micro error:

(1)
For the unweighted macro error, fi = 1∀i. The results are shown in Table 5. The macro error, i.e.
when all relations have the same signiﬁcance, is estimated at 0.17 for scenario (ii), when the manually
annotated relation subset of the most frequent 397 relations was used. When taking into account as errors

.

8Wapen is not a mistake – the word is spelled Wappen in contemporary German but we ﬁnd both forms in the RI.
9Speciﬁcally, those nouns were belagerung (siege), Eintreffen (arrival) and belehnung (mortgage).

(cid:80)n
(cid:80)n
i=1 fi · gi
i=1 fi

164Figure 8: Example graph of the two issuers king Pippin (selected) and Karl Martell (father of Pippin)
between 4/13/707 and 3/31/757 (96/148 nodes, 121/196 edges). Highlighted is an edge for the relation
schenkt (endow). Edge thickness indicates edge weight and nodes are scaled by degree centrality. The
ﬁgure is best seen in color.

all the other, less frequent relations, the macro error is < 0.93, which of course is a very pessimistic
estimate. However, in most cases, assessing the weighted micro-error would be of much more interest
– some relations cover a much larger proportion of induced relations. For example, a historian who is
interested in the most frequent 125 relations (@125 in Table 5) would expect a weighted error of 0.03
and pessimistically an unweighted error of at most 0.104. When choosing the most common 25 relations
(e.g. @25 in Table 5), the error is zero for both micro and macro calculations with regard to falsely
induced relations due to POS tag errors.

4 Visualization: Diving into European Medieval Times

Visualization of textual (meta)-data is crucial both to
make sense of the data itself and also to distribute the
information in a more accessible way. Figure 9 dis-
plays our induced graph, where modularity clusters
are colored differently.
Inspecting the main clusters
shows that some clusters roughly represent the uni-
verses of single emperors (violet: Friedrich III. (14.3%
of all nodes), blue: Sigmund (9.54%), black: Karl
IV. (6.14%)), while other clusters encapsulate multi-
ple emperors (pink: the Palatine emperors Ruprecht I.,
Ruprecht II., and Ruprecht III. (7.45%)) and addition-
ally there appear to be clusters which subsume the uni-
verses of less prevalent and especially earlier emperors
(orange: Otto III., Otto I., Karl the Great, etc. (7.14%)).
Interactive visualization is a methodological tool to assist researchers in exploring the data, allowing for
non-destructive data manipulation and ﬁltering. For the Regesta Imperii we aim to provide an easy-

Figure 9: RI-graph with colored modularity
clusters (Brandes et al., 2008) after applica-
tion of ForceAtlas2 (Jacomy et al., 2014) in
Gephi (Bastian et al., 2009).

165to-use exploration tool of the extracted knowledge graph for historians. We built a web application to
visualize the data. The application is JavaScript-based and uses AngularJS 1 as the frontend framework.
Visualization is done using vis.js,10 an open-source tool aimed at network and timeline visualizations.

Our KG contains 68,726 nodes and 154,797 edges. The average outdegree of nodes is 380 and average
indegree is 2.65, showing that the KG is highly uni-directional with few central nodes (i.e. issuers) and
most peripheral nodes having few incoming and almost no outgoing edges. Structurally speaking, the
knowledge graph is weakly connected, consisting of 14 components with one large component containing
68,692 and the remaining ones containing < 5 nodes. In the largest component, of the 25 nodes with
highest betweenness centrality, 7 are issuers and 18 are persons. This indicates that in terms of shortest
paths between all node pairs, persons are especially important in establishing the connectivity of the
graph. However, when looking at the 70 cut vertices of the component that are named entities,11 we see
that 55 are persons, but 11 denote place or region names (e.g. Frankreich or Reutlingen), indicating that
certain regions also play a critical role in connecting multiple sub-networks.12

An example network is shown in Figure 8. Although the sheer size of the KG prohibits it from being
visualized in its entirety, we use optimizations and ad-hoc querying to visualize sub-networks of the
KG. With these, we were able to create interactive visualizations for networks of up to 12,000 nodes in
practice. On the settings page, a user can choose one or more issuers. Based on the selected issuers, a
network with all other nodes with which they interacted gets created. Furthermore, there are a number
of additional settings, which can be divided into limiting constraints and network enhancements.
Limiting constraints. These limit the resulting network on an ad-hoc basis. Speciﬁcally, we allow to
set a threshold X (≤ X; = X; ≥ X) for the number of connections to display for a named entity and
the number of relation instances. With these settings, speciﬁc requirements can be made, e.g. “show the
network of Friedrich III. with relations that appear at least 40 times”. A combination of constraints is
also possible but per default, we set all constraints ≥ 1 so that the full graph will be rendered.

Network enhancements. These apply to the way the network gets rendered and can be interacted
with. The ﬁrst option visualizes the intensity of edges by their associated edge weights. The second
option visualizes the importance of persons by means of a selected node centrality measure. Currently,
we support degree, eigenvector, and betweenness centrality. The last option enables the time slider that
allows for ﬁltering the network by event dates. Per default, all three options are disabled.

To further reduce rendering speed, we implemented a decay factor to the number of iterations of the
underlying physics solver used to calculate the graph layout. Starting with a network containing more
than 150 nodes or 250 edges, the default number of iterations (1,000) is reduced by a factor of 0.1 for
every additional 150 nodes or 250 edges.13 We set the lower-bound to 100 iterations to give the solver
some time to calculate the layout. Using this decay factor and the above-mentioned constraints drastically
reduces the load times for very large networks. For example, the network of Karl IV. containing 7,359
nodes and 13,760 edges takes a couple of minutes to render. With the decay factor and the constraint that
named entities have exactly 2 edges, the graph is reduced to 785 nodes and 1,568 edges, and is rendered
in 80 seconds with 576 iterations.14 Furthermore, we allow to save graphs as JSON ﬁles that can later be
re-uploaded, further reducing load times. These are promising results as in a later production stage, the
application can be supplemented by a database containing pre-calculated network layouts.

5 Related Work
Historical Text Processing. Piotrowski (2012) gives an overview of the many challenges arising when
applying NLP to historical documents. The idea of normalization is often explored, yet we encountered
the same problem as the author who reports that the effectiveness of normalization to a large degree
depends on text type and language – most satisfying results are achieved only on more recent texts. For

10visjs.org.
11We exclude issuers from this analysis as cutting them almost always increases the number of components because of their

central role.

12The remaining four are generic entities such as Roman numerals.
13Furthermore, if the node-edge difference is > 900, we consider the edge number to be determining the decay factor.
1440 seconds of that are needed to process the data from our KG ﬁle, the remaining time is the rendering time.

166this reason, we applied little and careful normalization to the regests. We concur that “the highly variable
spelling found in many historical texts has remained one of the most troublesome issues for NLP” (p.
83), a fact that may be especially true with regard to the RI. Due to these issues, the research conducted
in processing of (German) historical texts has been diverse and very task-speciﬁc, see i.a. (Massad et al.,
2013; Mero˜no-Pe˜nuela et al., 2015; Seemann et al., 2017; Hench, 2017; Schulz and Keller, 2016).

Regesta Imperii. Not much NLP research has been conducted on the RI. Kuczera (2015), in an
example experiment, projects attributes and relations between entities from the times of Friedrich III.
(i.e. a subset of the RI) into a graph database. He applies no NLP in these steps, but relies on the
manually created person registers for the universe of Friedrich III. While currently only the registers for
Friedrich III. are available, we think that they may be used in future work to ﬁne tune the NER system
to achieve better performance not only on the sub-corpus of Friedrich III. but also on the whole RI. A
caveat is that the regests of the other emperors differ signiﬁcantly not only in named entities but also in
linguistic variety and thus such a system may fail to generalize. Opitz and Frank (2016) manually labeled
500 randomly sampled regests with 12 medieval themes and players of interest (e.g. nobles, spiritual
institutions, war and peace or justice) and trained binary classiﬁers to in the end label all regests and
compute statistics about the importance of the medieval themes and players with regard to time.

Relation Extraction For relation extraction from the Regesta Imperii we work in an ”extreme” en-
vironment – no annotated data; few language resources (particularly because of the German language
variations used in the corpus); no tools like named entity taggers or chunkers that would help in iden-
tifying relations and relation arguments; and low or no redundancy in relation instances (for comput-
ing extraction reliability scores). Because of this, the inspiration for the applied methods comes from
open information extraction (Open IE), particularly work where relations are described through POS and
grammatical patterns (Banko et al., 2007), and using the assumption that binary relations often appear
in a subject-verb-object format. Wu and Weld (2010) extend a previous distantly supervised system that
learns using Wikipedia infobox relations, and describe relations (through POS and dependency patterns)
as phrases consisting of at least one verb and/or a preposition. To counter noisy extractions (often phrases
that are too long and too speciﬁc to constitute a relation), Fader et al. (2011) introduce ReVerb, where
lexical and syntactic constraints on relation expressions serve to produce cleaner extractions, with less
uninformative or incoherent expressions. To increase recall, Mausam et al. (2012) expand the patterns
by allowing relational nouns (e.g. Bill Gates, co-founder of Microsoft ...). Patterns are gathered and gen-
eralized (e.g., from words to parts-of-speech), which boosts recall. All these relation extraction methods
rely on redundancy in the data to verify the relation patterns and the extracted candidates through vari-
ous reliability scores. This cannot be applied to the RI corpus. We rely instead on the relatively simple
structure of the regest texts and the grammatical information obtained from a parser.

6 Conclusions

We induced a Knowledge Graph from the medieval Regesta Imperii corpus. Nodes represent medieval
named entities, the (weighted) edges indicate relations between those entities, which may have occurred
at multiple times in history. High linguistic variation and code switching within single regests pose chal-
lenges for modern-day NLP systems, despite their seemingly simple structure. We added preprocessing
heuristics to prevent erroneous sentence splitting, and in the process acquired a list of nobility titles. We
explored relation classiﬁcation as multi-class classiﬁcation based on a binary bag-of-phrases represen-
tation of the regests. This not only gives us an option to inject further useful information into the KG
describing the encapsulated events more closely, but also allows us to explore phrases highly associated
with speciﬁc relations. The resulting Knowledge Graph was embedded in an isolated web application,
enabling the visualization and querying of the data. The data and application are shared publicly.15

For future work we are planning to further reﬁne the Knowledge Graph, introduce more structure using
nobility titles and entity types and develop and evaluate it together with historians to adjust visualization
and querying methods to their needs.

15https://gitlab.cl.uni-heidelberg.de/born/ri-visualization.

167References
Michele Banko, Michael Cafarella, Stephen Sonderland, Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the Web. In Proceedings of the 22nd Conference on the Advancement of Artiﬁcial
Intelligence, Vancouver, B.C., Canada, 22-26 July 2007, pages 2670–2676.

Mathieu Bastian, Sebastien Heymann, and Mathieu Jacomy. 2009. Gephi: An Open Source Software for Explor-

ing and Manipulating Networks.

Ulrik Brandes, Daniel Delling, Marco Gaertler, Robert Gorke, Martin Hoefer, Zoran Nikoloski, and Dorothea

Wagner. 2008. On Modularity Clustering. IEEE Trans. on Knowl. and Data Eng., 20(2):172–188, February.

Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction.
In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, UK,
26-29 July 2011, pages 1535–1545.

Christopher Hench. 2017. Phonological Soundscapes in Medieval Poetry. In Proceedings of the Joint SIGHUM
Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature,
pages 46–56, Vancouver, Canada, August. Association for Computational Linguistics.

Mathieu Jacomy, Tommaso Venturini, Sebastien Heymann, and Mathieu Bastian. 2014. ForceAtlas2, a continuous
graph layout algorithm for handy network visualization designed for the Gephi software. PloS one, 9(6):e98679.

Andreas Kuczera. 2015. Graphdatenbanken f¨ur Historiker. Netzwerke in den Registern der Regesten Kaiser

Friedrichs III. mit neo4j und Gephi. Mittelalter. Interdisziplin¨are Forschung und Rezeptionsgeschichte.

D Massad, E Omodei, C Strohecker, Y Xu, J Garland, M Zhang, and LF Seoane. 2013. Unfolding History:

Classiﬁcation and analysis of written history as a complex system.

Mausam, Michael Schmitz, Robert Bart, Stephen Soderland, and Oren Etzioni. 2012. Open language learning
for information extraction. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language
Processing, Jeju Island, Korea, 12-14 July 2012, pages 523–534.

Albert Mero˜no-Pe˜nuela, Ashkan Ashkpour, Marieke van Erp, Kees Mandemakers, Leen Breure, Andrea Scharn-
horst, Stefan Schlobach, and Frank van Harmelen. 2015. Semantic technologies for historical research: A
survey. Semantic Web, 6(6):539–564.

Juri Opitz and Anette Frank. 2016. Deriving Players & Themes in the Regesta Imperii using SVMs and Neural
In Proceedings of the 10th SIGHUM Workshop on Language Technology for Cultural Heritage,

Networks.
Social Sciences, and Humanities, pages 74–83. Association for Computational Linguistics.

Michael Piotrowski. 2012. Natural Language Processing for Historical Texts. Synthesis Lectures on Human

Language Technologies. Morgan & Claypool Publishers.

Eric Sven Ristad and Peter N. Yianilos. 1998. Learning String-Edit Distance. IEEE Trans. Pattern Anal. Mach.

Intell., 20(5):522–532, May.

Sarah Schulz and Mareike Keller. 2016. Code-Switching Ubique Est - Language Identiﬁcation and Part-of-Speech
Tagging for Historical Mixed Text. In Proceedings of the 10th SIGHUM Workshop on Language Technology
for Cultural Heritage, Social Sciences, and Humanities, pages 43–51, Berlin, Germany, August. Association
for Computational Linguistics.

Nina Seemann, Marie-Luis Merten, Michaela Geierhos, Doris Tophinke, and Eyke H¨ullermeier. 2017. Annota-
tion Challenges for Reconstructing the Structural Elaboration of Middle Low German. In Proceedings of the
Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and
Literature, pages 40–45, Vancouver, Canada, August. Association for Computational Linguistics.

Fei Wu and Daniel S. Weld. 2010. Open information extraction using Wikipedia. In Proceedings of the 48th
Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 11-16 July 2010, pages
118–127.

Li Yujian and Liu Bo. 2007. A Normalized Levenshtein Distance Metric. IEEE Trans. Pattern Anal. Mach. Intell.,

29(6):1091–1095, June.

168