March 2018

Neural Won:
Now What? 
Alex Yanishevsky
Senior Manager
MT and NLP Deployments

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 84Our History

1997. 

    2000. 

    2005. 

    2006. 

 2007. 

    2008. 

Company Started

Expanded Market into 
Germany (Acquisition)

Established European 
Headquarters in Dublin 
(Acquisition)

Opened APAC 
Services in Jinan and 
Beijing, China 
(Acquisitions)

US Acquisitions Including 
Global Sight Technology, 
Leading Open Source 
Training Management 
System

Added to APAC 
Presence with 
Tokyo Office 
(Acquisition)

2010. 

    2012. 

    2014. 

    2015. 

  2016.

Major Expansion in 
Europe with UK 
Acquisition of Lloyd 
International

Added Legal Services 
with Market Leader Park 
IP Translations 
(Acquisition)

Acquired CD Language 
Solutions in Houston, TX

Significant Investment from 
Norwest Equity Partners

Acquired Agostini 
Associati in Milan, Italy

Acquired Adapt Worldwide 
(Traffic Optimiser) in London, 
United Kingdom

11th Year on Inc. 5000 Fastest 
Growing Private Companies

Nova Language Services 
Acquisition Expands Regulated 
Industry Solutions in Life Sciences 
(Acquisition)

Global Language Solutions (GLS) 
Acquisition Strengthens Life 
Sciences Market Leadership 
(Acquisition)

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 85The Facts

Welocalize is one of the largest language service 
providers in the world.

175+
Languages

1500+
Employees

20+
Global Offices

72,859
Projects 2016

1,946
Global Clients

1.16 Billion 
Words Translated 2016

4th Largest 
Language Services Provider in the US

7th Largest
Worldwide*

*Source: Common Sense Advisory, 2015

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 86Agenda

⦿ Did NMT really win?

⦿ Migration path

∙

∙

∙

Build or buy? 

Infrastructure and Cost

TMS and Connectors

∙ Additional Use Cases – CMS, applications using MT such 

as chat, KB, forums

Training and Maintenance

Supply Chain 

∙

∙

⦿ Case studies

⦿ What else can we do with neural technology? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 87Did NMT Really Win? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 88Did NMT Really Win? /1

Generally, yes, and the future lies in NMT, but…

Locale variants such as ES-ES>ES-MX: consider 
transformation tables or Apertium (RBMT)
Related language pairs such as ES-ES>PT-PT: 
consider Apertium (RBMT) or SMT

Rare, long-tail language translation directions: 
consider SMT
In some cases, well trained SMT engine in 
Romance languages 
can be preferred to NMT 
In some cases, SMT better at short sentences

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 89Did NMT Really Win? /2

SMT better for DE for accuracy and edit 
distance
SMT better for PTBR for edit distance

SMT better for RU for edit distance

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 90Did NMT Really Win? /3

The NMT engines scores better in human 
ranking
NMT engine has a lot of omissions, 
duplications and unusual mistranslations
Results for auto-scoring are mixed 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 91Did NMT Really Win? /4

Hub in last place in all rankings

NMT1 in first place in all 
rankings
NMT technology better overall

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 92Now What?

P A I N   P O I N T S
Raw MT, PE, both

N U M B E R   O F   E N G I N E S
How many domains and engines do you have and for how many 
languages?

S T R A T E G Y
What is your migration path and strategy?

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 93Migration Path 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 94Migration Path

B U I L D   O R   B U Y ?

T M S   A N D   C O N N E C T O R S

A D D I T I O N A L   U S E   C A S E S :   C M S ,   C H A T,   K B ,  
F O R U M S

T R A I N I N G   A N D   M A I N T E N A N C E

S U P P LY   C H A I N

C A S E   S T U D I E S

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 95Build or Buy /1

BUILD

BUY

◦
◦
◦

◦
◦

Customized needs
Internal expertise
Flexibility

BUILD

Competitive advantage
Build from scratch or 
adapt open source 
solutions

◦
◦
◦

◦

◦
◦

Lack of time
Lack of expertise
Lack of customizability

BUY

Lack of influence over 
product roadmap
Reliable tech support
Reliable solutions 
available out of the box

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 96Build or Buy /2

BUILD

BUY

◦ Modern MT
◦ Open NMT
◦
Tensor Flow
◦ Nematus
◦ Marian
◦ Moses

◦ Google, Amazon, Bing –

not customizable

◦ MS Hub SMT, Globalese, 
Kantan, Omniscien, SDL, 
Systran, Iconic, etc. -
customizable

BUILD

BUY

◦
◦

Limited baseline
Difficult to enforce 
terminology

◦

Robust or limited 
baseline based on 
provider

◦ Generally difficult to 

enforce terminology, but 
based on provider

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 97BUILD

BUY

◦ More options to control 
(epochs, layers, baseline 
vs domain data)

◦ Quality of documentation 
and code samples may be 
more uneven

◦
◦

Less options to control
Very good documentation 
and code samples

Build or Buy /3

BUILD

BUY

◦ Unlimited usage 
◦

$3/hr for cloud for 
processing MT requests
2K per engine for training 
per month for 20 epochs
at 4 hours an epoch

◦

◦

◦

$10-20 for 1 million 
characters – not 
customizable and MS Hub 
SMT
Several hundred to 
several thousand per 
engine – customizable 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 98TMS and CAT Tool Considerations

Availability and additional cost of connectors 
depends on TMS or CAT tool
Tag handling

Pre and post processing scripts

Tags as sentence breakers 

Capabilities for providing feedback 

Interacting with Adaptive MT

Ideally, the TMS has several MT connectors so 
you can pick and choose and migrate when 
results are conclusive and/or run several MT 
providers in parallel. 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 99Additional Use Cases of MT 

KB
Forums

Rewrite connectors for 
•
•
• Chat 
• Any other applications

6 points of MT integration!

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 100Training and Maintenance /1

Initial training
Computational costs of building NMT vs SMT are higher 

Maintenance
Computational cost of enforcing specific patterns from linguistic feedback 
is higher; it’s not a matter of modifying phrase tables or language models 
as with SMT or rules/dictionaries with RBMT.

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 101Training and Maintenance /2

• Data availability

✓ Some NMT systems with restricted options require a lot more 

training data than comparable SMT or RBMT systems

 5-7 million TUs (sometimes 10-11 million) overall to match the 
quality of an SMT engine in MS Hub with 500-600K TUs and MS 
Models

 Client data ranged from 50K to 700K TUs
✓ Possible to train decent engine with 1-2 million TUs in a 

different framework with more options available

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 102Training and Maintenance /3

Uneven or misaligned TUs

Data Quality
Bad for both 
•
• Wrong target language
•
•

Poor, unreliable or inconsistent translations
Really long segments (NMT – attention mechanism keeps track for 
only so long due to vanishing gradients, SMT – can’t focus on long 
term dependencies, e.g. English with relative clauses)

Bad for NMT only 
•
• High ratios of DNT if you do not have method to enforce dictionary

Short segments (1-3 words)

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 103Training the Supply Chain

NMT output is remarkably more fluent. 

However, this fluency does not guarantee 
accuracy. The cognitive load can be higher for a 
post-editor to review the source and suggested 
target. 
OOVs and DNT mistranslations

Source

Hypothosis

Reference

6 Div(Low)

6、、

Source

6 分割(低)

Hypothesis

Reference

a04JwiqW9El4hce/Z3+nOHOckWJ0VSCFoqox1FVpYW4fXSeHfuQ0ktVn
yIyMz/vYTAWrnj493YIY
Examples: file:///remote/file/system/mount/point, \\\\server\\path or 
nfs://server:/path

X/Z3+Delete/bbr

示例：、或更高版本

a04JwiqW9El4hce/Z3+nOHOckWJ0VSCFoqox1FVpYW4fXSeHfuQ0kt
VnyIyMz/vYTAWrnj493YIY
示例: file:///remote/file/system/mount/point、\\\\server\\path 或
nfs://server:/path

Source

Hypothosis

Reference

<proxyAddress:port>
GuestRpc:

<>
：

<proxyAddress:port>
GuestRpc:

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 104Case Studies 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 105Case Study 1: Internal Dept, MTPE

MemoQ as CAT tool
Numerous MT connectors
Currently on MS Hub SMT
EN<>FR, IT, DE, ES, PTBR
One domain, life sciences
Any SMT or NMT solution must be 
customizable 
OpenNMT adaptation shows markedly 
improved scores

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 106ITEM

COST

SAVINGS

0

0

$8000

Connector

MT Usage 

Engine Cost ($1000 
per locale pair per 

year)

Vendor discounts 
(100K new words 
per year* 8 locale 

pairs* .01 per 

word)

$8000

Case Study 1
ROI 
Calculations

By how much does NMT need to win in order to move now? 

How can we put a price on this? 

How much volume? What languages? 
NOTE: How likely is additional .01 per word for each locale pair? What additional discount does it represent? 
For rate of .15, that’s an additional 7%.

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 107Case Study 2, Tech Support, Raw MT

All possible language combinations, i.e. over 50 
languages
UGC – prone to slang, typos, incorrect 
formatting
MT embedded into chat application
How important is lexical coverage? 
How many MT connectors does the chat 
application support? 
If several, can you mix and match? 
If you deploy several, what’s the administrative 
overhead of licensing and retraining from 
several different MT providers? 
Is normalization taking place? 

What is the minimum allowable level of quality 
for the lowest cost? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 108Case Study 3, Enterprise, MTPE 

Enterprise level TMS
Currently on MS Hub
Each MT connector costs money and has to be 
vetted by TMS provider
Many (but not all) languages do better in NMT

What business problem are we solving – TAT, 
quality, cost of delivery? How will the move to 
NMT be a game changer? 
Split the languages amongst the connectors or 
only move when you can do all of them? 
As in case study 1, what’s the cost of each 
connector relative to the expected volume, 
increased quality and expected discount by 
moving to neural? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 109What Else Can We Do 
with Neural Technology? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 110NLG (Natural Language Generation) with 
subsequent NMT

Sentiment analysis 

Predictive analytics for localization program 
management and linguist selection

Predictive input

Virtual assistants

Machine learning for LQA and evaluation of source

Document summarization

What Else Can We 
Do? 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 111+

Thank you

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 112