Jump to better conclusions: SCAN both left and right

Joost Bastings1 Marco Baroni2

Jason Weston2 Kyunghyun Cho2,3,4 Douwe Kiela2

1ILLC, University of Amsterdam

2Facebook AI Research
3New York University
4CIFAR Global Scholar

bastings@uva.nl {mbaroni,jase,kyunghyuncho,dkiela}@fb.com

Abstract

Lake and Baroni (2018) recently introduced
the SCAN data set, which consists of simple
commands paired with action sequences and is
intended to test the strong generalization abil-
ities of recurrent sequence-to-sequence mod-
els. Their initial experiments suggested that
such models may fail because they lack the
ability to extract systematic rules. Here, we
take a closer look at SCAN and show that it
does not always capture the kind of generaliza-
tion that it was designed for. To mitigate this
we propose a complementary dataset, which
requires mapping actions back to the original
commands, called NACS. We show that mod-
els that do well on SCAN do not necessarily do
well on NACS, and that NACS exhibits prop-
erties more closely aligned with realistic use-
cases for sequence-to-sequence models.
Introduction

if

(i.e.,

recurrent

constituent parts

1
In a recent paper, Lake and Baroni (2018) (L&B)
investigate
sequence-to-sequence
models can exhibit the same strong generalization
that humans are capable of, by virtue of our
capacity to infer the meaning of a phrase from
its
compositionality),
providing empirical tests for this long-standing
goal (Fodor and Pylyshyn, 1988). Compositional
generalization might be a fundamental component
in making models drastically less sample-thirsty
than they currently are. L&B introduce the SCAN
data set (§2), meant to study such generaliza-
tion to novel examples.
It consists of simple
command-action pairs, in which more complex
commands are composed of simpler ones (see
Figure 1 for examples).

SCAN comprises several tests of generaliza-
tion, namely with respect to (1) a random sub-
set of the data (‘simple’), (2) commands with ac-
tion sequences longer than those seen during train-
ing (‘length’), and (3) commands that compose a

jump
JUMP
turn around left
LTURN LTURN LTURN LTURN
jump thrice and turn left twice
JUMP JUMP JUMP LTURN LTURN
jump opposite left after walk twice
WALK WALK LTURN LTURN JUMP

Figure 1: SCAN maps commands to actions

primitive in novel ways that was only seen in isola-
tion during training (‘primitive’). In the latter case,
the training set would for example only include the
command ‘jump’, after which the test set includes
all other commands containing ‘jump’, e.g. ‘jump
opposite left after walk twice’.

In this paper we take a closer look at SCAN.
We start with the observation (§3) that there are
few target-side dependencies in the data, a conse-
quence of SCAN being generated from a phrase-
structure grammar. We show (§6) that this allows
simple sequence-to-sequence models (§5) to ob-
tain good accuracies e.g. on tasks involving a new
primitive, even without access to previous out-
puts. However, these simple models do not use
composition in any interesting way, and their per-
formance is therefore not a realistic indicator of
their generalization capability. We hence propose
NACS (§4) as a more realistic alternative: SCAN
with commands and actions ﬂipped, i.e., mapping
actions back to their original commands. This is
harder, because different commands may map to
the same action sequence, and it introduces target-
side dependencies, so that previous outputs need
to be remembered. We show in particular that
well-tuned attention-based models do achieve a
certain degree of generalization on SCAN, and, as

Proceedingsofthe2018EMNLPWorkshopBlackboxNLP:AnalyzingandInterpretingNeuralNetworksforNLP,pages47–55Brussels,Belgium,November1,2018.c(cid:13)2018AssociationforComputationalLinguistics47predicted, simpler models do better there. How-
ever, the models still struggle in the more demand-
ing NACS setup, which we offer as a challenge for
future work.

Our contributions can be summarized as fol-

lows:

1. we provide an analysis of SCAN and make
the important observation that it does not test
for target-side dependencies, allowing too
simple models to do well;

2. we propose NACS to introduce target-side

dependencies and remedy the problem;

3. we repeat all experiments in Lake and Ba-
roni (2018) using early-stopping on valida-
tion sets created from the training data.

2 SCAN

SCAN stands for Simpliﬁed version of the Com-
mAI Navigation tasks (Mikolov et al., 2016). Each
example in SCAN is constructed by ﬁrst sam-
pling a command X = (x1, . . . , xT ) from a ﬁnite
phrase-structure grammar with start symbol C:
C → S and S | S after S | S
S → V twice | V thrice | V
V → D[1] opposite D[2] | D[1] around D[2] | D | U
D → U left | U right | turn left | turn right
U → walk | look | run | jump

For each command, the corresponding target ac-
tion sequence Y = (y1, . . . , yT (cid:48)) then follows by
applying a set of interpretation functions, such as:

(cid:74)jump(cid:75) = JUMP
(cid:74)u around left(cid:75) = LTURN(cid:74)u(cid:75) LTURN(cid:74)u(cid:75)
LTURN(cid:74)u(cid:75) LTURN(cid:74)u(cid:75)
(cid:74)x1 after x2(cid:75) =(cid:74)x2(cid:75)(cid:74)x1(cid:75)

of which only the last function requires global
reordering, which occurs at most once per com-
mand. See the supplementary materials for the full
set. Figure 1 shows examples of commands and
their action sequences as obtained by the interpre-
tation functions. The commands can be decoded
compositionally by a learner by discovering the in-
terpretation functions, enabling generalization to
unseen commands. The total data set is ﬁnite but
large (20910 unambiguous commands).

3 SCAN prefers simple models
We observe an important property of the data set
generation process for SCAN: temporal depen-
dencies of the action sequence are limited to the
phrasal boundaries of each sub-phrase, which span
at most 24 actions (e.g. jump around left thrice).
Crucially, even rules that require repetition (such
as ‘thrice’) as well as global reordering, can be re-
solved by simple counting and without remember-
ing previously generated outputs, due to the lim-
ited depth of the phrase-structure grammar (see
e.g. Rodriguez and Wiles (1998)).

This observation has two important implica-
tions. First, because SCAN is largely a phrase-to-
phrase conversion problem, any machine learning
method that aims at solving SCAN needs to have
an alignment mechanism between the source and
target sequences. Such an alignment mechanism
could work fairly accurately by simply advanc-
ing a pointer. Somewhat contrary to the observa-
tion by Lake and Baroni (L&B), we therefore hy-
pothesize that an attention mechanism (Bahdanau
et al., 2015) always helps when a neural con-
ditional sequence model (Sutskever et al., 2014;
Cho et al., 2014) is used to tackle any variant of
SCAN. Second, we speculate that any algorithm
with strong long-term dependency modeling ca-
pabilities can be detrimental in terms of gener-
alization, because such an approach might inap-
propriately capture spurious target-side regulari-
ties in the training data. We thus hypothesize
that less powerful decoders generalize better on
to unseen action combinations on SCAN when
equipped with an attention mechanism.

To summarize: good performance on SCAN
does not necessarily indicate the capability of a
model to strongly generalize. SCAN favors sim-
pler models that need not capture target-side de-
pendencies, which might not work well on more
realistic sequence-to-sequence problems, such as
machine translation, where strong auto-regressive
models are needed for good results (Bahdanau
et al., 2015; Kaiser and Bengio, 2016).

4 NACS: actions to commands
By simply ﬂipping the source X and target Y
of each example, we obtain a data-set that sud-
denly features strong target-side dependencies.
Even when the mapping p(Y |X) from the source
the opposite p(X|Y ) ∝
to target
p(Y |X)p(X) is non-trivial due to the complexity

is simple,

48eyi−1

e

t

e

s

yi

oi

o
t

ti

t
s

si−1

ss

si

t
c

s
c

ci

Figure 2: The decoder of Bahdanau et al. (2015)

of the prior p(X). The inclusion of p(X) naturally
induces strong dependencies among the output to-
kens, while maintaining the original properties of
SCAN that were intended to test various aspects
of systematic generalization.

NACS naturally makes the mapping that needs
to be learned stochastic and multi-modal (sensi-
tive to both commands and actions). For instance,

an action sequence of the form (cid:74)x1(cid:75)(cid:74)x2(cid:75) could
be mapped to either(cid:74)x1 and x2(cid:75) or(cid:74)x2 after x1(cid:75),
generated (i.e.,(cid:74)x1(cid:75) or(cid:74)x2(cid:75)).

both of which are correct. In order for a model to
decide whether to output “and” or “after”, it is nec-
essary for it to remember what has already been

Another example is LTURN LTURN LTURN
LTURN, which can be translated into either “turn
around left” or two repetitions of “turn opposite
left”. Deciding whether to output “and” after
the ﬁrst phrase requires the model to remember
whether “around” was generated previously.
In §6 we experimentally evaluate the proposed
NACS task using the same scenarios as SCAN
(simple, length and primitive). We observe that
NACS prefers more advanced models that could
capture long-term dependencies in the output (now
a command sequence) better. However, we notice
that even these powerful models, equipped with
GRUs and attention, cannot systematically gener-
alize to this task, as was also observed by Lake
and Baroni (2018). Based on this observation, we
believe that NACS (or perhaps a combination of
SCAN and NACS) is better suited for evaluating
any future progress in this direction.

5 Sequence-to-sequence models

In this section, we describe the sequence-to-
sequence models we use for evaluating on SCAN
and its proposed sibling NACS.
the probability of a tar-
get sequence given a source sequence p(Y |X).

We directly model

Our encoder-decoder is modeled after Cho et al.
(2014) and our attention-based encoder-decoder
after Bahdanau et al. (2015). The attention-based
decoder is a function that takes as input the previ-
ous target word embedding eyi−1, the context vec-
tor ci, and the previous hidden state si−1 (see also
Figure 2): si = f (eyi−1, ci, si−1).

The prediction for
the current
then made from a pre-output

time step
is
layer ti:
ti = Weeyi−1 + Wcci + Wssi. We do not apply
a max-out layer and directly obtain the output by
oi = Woti. For the encoder-decoder without at-
tention, the prediction is made directly from de-
coder state si. We vary the recurrent cell, exper-
imenting with simple RNN (Elman, 1990), GRU
(Cho et al., 2014), and LSTM cells (Hochreiter
and Schmidhuber, 1997). For conciseness we only
report results with RNN and GRU cells in the main
text, and LSTM results in the appendix.

In this paper, we investigate the properties
of both SCAN and NACS using RNN-based
sequence-to-sequence models for evaluation. We
leave further investigation of alternative architec-
tures (see, e.g., Vaswani et al., 2017; Gehring
et al., 2017; Chen et al., 2018) for the future.

6 Experiments
6.1 Settings
Our models are implemented in PyTorch and
trained using mini-batch SGD with an initial learn-
ing rate of 0.2, decayed by 0.96 each epoch. We
use a batch size of 32, 256 hidden units (64 for
embeddings), and a dropout rate of 0.2. We test
on all SCAN/NACS tasks1, as well as on the Fr-
En Machine Translation (MT) task that L&B used.
The reported results are averaged over three runs
for each experiment. Models with attention are
marked as such with +Attn, e.g. ‘GRU +Attn’.

Validation Set. L&B split each SCAN subtask
into a training set (80%) and a test set (20%). They
train for a ﬁxed number of updates (100k) and
evaluate on the test set. Because any training run
without early stopping may have missed the op-
timal solution (Caruana et al., 2001), we believe
their results may not reﬂect the reality as closely
as they could. We thus augment each of the SCAN
variants with a validation set that follows the train-
ing distribution but contains examples that are not
contained in the corresponding training set. This

1github.com/facebookresearch/NACS

49Simple

Length

Turn left

Jump

GRU
RNN +Attn
RNN +Attn -Dep
GRU +Attn
GRU +Attn -Dep
L&B best
L&B best overall

SCAN
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
99.8
99.7

NACS
99.0 ±0.1
99.8 ±0.1
61.1 ±0.3
99.8 ±0.1
51.2 ±1.2

-
-

SCAN
14.4 ±0.8
9.6 ±0.9
11.7 ±3.2
18.1 ±1.1
17.8 ±1.7
20.8
13.8

NACS
12.9 ±1.2
19.4 ±0.7
0.5 ±0.2
17.2 ±1.9
2.0 ±1.4

-
-

SCAN
NACS
53.4 ±11.7 47.5 ±4.7
81.1 ±14.7 44.1 ±0.9
92.0 ±5.8
18.6 ±1.0
59.1 ±16.8 55.9 ±3.5
90.8 ±3.6
16.9 ±1.2
90.3
90.0

-
-

SCAN NACS
0.0 ±0.0
0.0 ±0.0
1.9 ±1.2
0.3 ±0.3
0.0 ±0.0
2.7 ±1.7
0.0 ±0.0
12.5 ±6.6
0.7 ±0.4
0.0 ±0.0
1.2
0.1

-
-

Table 1: Test scores on the simple, length, and primitive (turn left, jump) tasks. +Attn marks attention, -Dep has the
connections from the previous target word embedding removed (es and et in Figure 2). L&Bbest is the best reported
score for each task by L&B, and L&Bbest overall is the score for their best-scoring model all tasks considered.

allows us to incorporate early stopping in our ex-
periments so that they are better benchmarks for
evaluating future progress. For each experiment
we remove 10% of the training examples to be
used as a validation set.

Accuracy. Following L&B we measure perfor-
mance according to sequence-level accuracy, i.e.,
whether the generated sequence entirely matches
the reference. This metric is also used for early
stopping. For NACS, an output (command) is
considered correct
if its interpretation (‘back-
mapping’) produces the input action sequence.

Ablations. To validate our analysis, we remove
the connections from the previous target word em-
bedding eyi−1 to the decoder state and the pre-
output layer (es and et in Figure 2), so that the
current prediction is not informed by previous out-
If our analysis in §3 is correct, then these
puts.
simpler models should still be able to make the
correct predictions on SCAN, but not on NACS.

6.2 Results and Analysis
Results on the three SCAN and NACS tasks are
listed in Table 1. The full results including mod-
els with LSTM cells and MT experiments may be
found in the supplementary materials. We will
now discuss our observations.

SCAN is not enough. Table 1 shows that all
model variants perform (near) perfectly on the
SCAN simple task. While this is impressive, re-
sults for the severed models (+Attn -Dep) on the
simple task for NACS show that it is possible to
have a perfect accuracy on SCAN, while at the

same time failing to do well on NACS.2 Crucially,
a (near) perfect score on SCAN does not imply
strong generalization. A model can exploit the de-
terminism and lack of target-side dependencies of
SCAN by developing a simple translation strategy
such as advancing a pointer and translating word
by word, and the use of such a simple strategy is
not revealed by SCAN.

NACS is harder. NACS is a harder problem to
solve compared to SCAN, as evidenced by con-
sistently lower accuracies in Table 1 for all tasks.
The discrepancy between SCAN and NACS per-
formance is the most extreme when we look at the
primitive tasks (turn left and jump). For turn left,
the severed models (+Attn -Dep) obtain the high-
est scores on SCAN, but are the worst on NACS.
The ‘turn left’ task beneﬁts from TURNL oc-
curring on the target-side in other contexts dur-
ing training, which is not the case for ‘jump’.3
Since there is no evidence in the training data that
‘jump’ is a verb, Table 2 shows results where addi-
tional (composed) ‘jump’ commands were added
for training. We see that performance quickly goes
up when adding more commands.4 Again here the
simpler models (+Attn -Dep) perform better.

repeat

Machine Translation. We
L&Bs
English-French MT experiment for both direc-
tions. Table 3 shows that models that perform
well on NACS also perform well here, with the
GRU outperforming the other cells (see appendix

2We made similar observations using LSTM cells, as we

show in the appendix.

3See Lake and Baroni (2018) for a discussion.
4L&B performed this experiment without attention,

which we show has a large positive impact.

501

2

4

8

16

32

48.6 ±8.1

SCAN 35.0 ±2.8

RNN +Attn
77.6 ±2.6
RNN +Attn -Dep SCAN 29.5 ±10.5 53.3 ±10.2 82.4 ±4.7
SCAN 58.2 ±12.0 67.8 ±3.4
GRU +Attn
80.3 ±7.0
GRU +Attn -Dep
SCAN 70.9 ±11.5 61.3 ±13.5 83.5 ±6.1
24.7 ±4.2
RNN +Attn
NACS
2.4 ±0.3
RNN +Attn -Dep NACS
GRU +Attn
NACS
11.0 ±1.5
2.0 ±0.2
GRU +Attn -Dep NACS
L&B
SCAN
4.1

2.8 ±0.8
0.4 ±0.1
5.5 ±1.8
0.1 ±0.1
0.1

9.3 ±7.3
0.9 ±0.2
9.2 ±2.8
0.6 ±0.2
0.1

89.2 ±3.8
98.8 ±0.8
88.0 ±6.0
99.0 ±0.4
43.7 ±4.4
3.9 ±0.3
21.9 ±2.4
3.2 ±0.2
15.3

98.7 ±1.3
99.8 ±0.1
98.3 ±1.8
99.7 ±0.2
57.1 ±5.2
9.3 ±0.3
23.5 ±0.6
5.8 ±1.1
70.2

99.8 ±0.1
100.0 ±0.0
99.6 ±0.2
100.0 ±0.0
69.1 ±2.1
15.9 ±1.4
42.0 ±1.5
10.9 ±0.8
89.9

Table 2: Test scores on the ‘jump’ task with additional commands. +Attn marks attention, -Dep has the es and et
connections removed (Figure 2). The test set contains all jump commands except the 32 used for training. Columns
indicate how many commands with ‘jump’ were added to the training set, such as ‘jump around left thrice.’

GRU +Attn
GRU +Attn -Dep

En-Fr
32.1 ±0.3
30.2 ±0.3

Fr-En
37.5 ±0.6
35.9 ±0.3

Table 3: Results (BLEU) on the Machine Translation
experiment for both directions using a GRU. See ap-
pendix for results using SRN and LSTM cells.

for other cell types).
In a setting similar to the
jump task, the sentence pair ‘I am daxy’ (‘je suis
daxiste’) was added to the training set. The goal
is now to test if eight novel sentences that contain
‘daxy’ are correctly translated.

In our setting with mini-batching and early-
stopping, the GRU gets 70.8% (En-Fr) and 54.2%
(Fr-En) of the daxy-sentences right, which is sur-
prisingly good compared to L&B (12.5%).
Other observations. As expected, Table 1
shows that attention always helps. Generalizing
to longer sequences is generally hard, and this re-
mains an open problem.

7 Related Work
Ever since Fodor and Pylyshyn (1988) conjectured
that neural networks are unable to show strong
generalization, many attempts were made to show
that the opposite is true, leading to inconclusive
evidence. For example, Phillips (1998) found that
feed-forward nets and RNNs do not always gen-
eralize to novel 2-tuples on an auto-association
task, while Wong and Wang (2007) and Brakel and
Frank (2009) found that RNNs can show system-
atic behavior in a language modeling task.

In the context of analyzing RNNs, Rodriguez
and Wiles (1998) found that simple RNNs can

develop a symbol-sensitive counting strategy for
accepting a simple (palindrome) context-free lan-
guage. Weiss et al. (2018) show that LSTMs and
simple RNNs with ReLU-activation can learn to
count unboundedly, in contrast to GRUs.

Linzen et al. (2016) probed the sensitivity of
LSTMs to hierarchical structure (not necessarily
in novel constructions). Instead of a binary choice,
with SCAN a sequence-to-sequence model pro-
ductively generates an output string.

Liska et al. (2018) found that a small number
of identical RNNs trained with different initializa-
tions show compositional behavior on a function
composition task, suggesting that more speciﬁc ar-
chitectures may not be necessary.

Finally, Lake and Baroni (2018) introduced the
SCAN data set to study systematic compositional-
ity in recurrent sequence-to-sequence models, in-
cluding gating mechanisms and attention. This
work is a direct response to that and aims to facil-
itate future progress by showing that SCAN does
not necessarily test for strong generalization.

8 Conclusion
In the quest for strong generalization, benchmarks
measuring progress are an important component.
The existing SCAN benchmark allows too simple
models to shine, without the need for composi-
tional generalization. We proposed NACS to rem-
edy this. NACS still requires systematicity, while
introducing stochasticity and strong dependencies
on the target side. We argue that a good bench-
mark needs at least those properties, in order not to
fall prey to trivial solutions, which do not work on
more realistic use-cases for sequence-to-sequence
models such as machine translation.

51Brenden M. Lake and Marco Baroni. 2018. Gen-
eralization without systematicity: On the com-
positional skills of sequence-to-sequence recurrent
International Conference on Machine
networks.
Learning (ICML).

Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg.
2016. Assessing the ability of lstms to learn syntax-
sensitive dependencies. Transactions of the Associ-
ation for Computational Linguistics, 4:521–535.

Adam Liska, Germ´an Kruszewski, and Marco Ba-
roni. 2018. Memorize or generalize?
searching
for a compositional RNN in a haystack. CoRR,
abs/1802.06467.

Tomas Mikolov, Armand Joulin, and Marco Baroni.
2016. A roadmap towards machine intelligence.
In International Conference on Intelligent Text Pro-
cessing and Computational Linguistics, pages 29–
61. Springer.

Steven Phillips. 1998. Are feedforward and recurrent
networks systematic? analysis and implications for
a connectionist cognitive architecture. Connection
Science, 10(2):137–160.

Paul Rodriguez and Janet Wiles. 1998. Recurrent
neural networks can learn to implement symbol-
sensitive counting. In Advances in Neural Informa-
tion Processing Systems, pages 87–93.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems, pages 3104–3112.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, pages 6000–6010.

Gail Weiss, Yoav Goldberg, and Eran Yahav. 2018.
On the practical computational power of ﬁnite pre-
In Proceed-
cision rnns for language recognition.
ings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), Melbourne, Australia. Association for Com-
putational Linguistics.

Francis CK Wong and William SY Wang. 2007. Gen-
eralisation towards combinatorial productivity in
language acquisition by simple recurrent networks.
In Integration of Knowledge Intensive Multi-Agent
Systems, 2007. KIMAS 2007. International Confer-
ence on, pages 139–144. IEEE.

Acknowledgments

We would like to thank Brenden Lake and
Marc’Aurelio Ranzato for useful discussions and
feedback.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural Machine Translation by Jointly
Learning to Align and Translate. In Proceedings of
the International Conference on Learning Represen-
tations (ICLR), San Diego, USA.

Phil´emon Brakel and Stefan Frank. 2009. Strong sys-
tematicity in sentence processing by simple recur-
In 31th Annual Conference of the
rent networks.
Cognitive Science Society (COGSCI-2009), pages
1599–1604. Cognitive Science Society.

Rich Caruana, Steve Lawrence, and C Lee Giles. 2001.
Overﬁtting in neural nets: Backpropagation, conju-
In Advances in
gate gradient, and early stopping.
neural information processing systems, pages 402–
408.

Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin
Johnson, Wolfgang Macherey, George Foster, Llion
Jones, Niki Parmar, Mike Schuster, Zhifeng Chen,
et al. 2018. The best of both worlds: Combining re-
cent advances in neural machine translation. arXiv
preprint arXiv:1804.09849.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. 2014. Learn-
ing Phrase Representations using RNN Encoder–
Decoder for Statistical Machine Translation. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1724–1734, Doha, Qatar. Association for
Computational Linguistics.

Jeffrey L Elman. 1990. Finding structure in time. Cog-

nitive science, 14(2):179–211.

Jerry A Fodor and Zenon W Pylyshyn. 1988. Connec-
tionism and cognitive architecture: A critical analy-
sis. Cognition, 28(1-2):3–71.

Jonas Gehring, Michael Auli, David Grangier, De-
nis Yarats, and Yann N Dauphin. 2017. Convolu-
tional sequence to sequence learning. arXiv preprint
arXiv:1705.03122.

Sepp Hochreiter and J¨urgen Schmidhuber. 1997.
Long Short-Term Memory. Neural Computation,
9(8):1735–1780.

Łukasz Kaiser and Samy Bengio. 2016. Can active
memory replace attention? In Advances in Neural
Information Processing Systems, pages 3781–3789.

52Supplementary Materials

(cid:74)walk(cid:75) = WALK
(cid:74)look(cid:75) = LOOK
(cid:74)run(cid:75) = RUN
(cid:74)jump(cid:75) = JUMP
(cid:74)turn left(cid:75) = LTURN
(cid:74)turn right(cid:75) = RTURN
(cid:74)u left(cid:75) = LTURN(cid:74)u(cid:75)
(cid:74)u right(cid:75) = RTURN(cid:74)u(cid:75)
(cid:74)x twice(cid:75) =(cid:74)x(cid:75)(cid:74)x(cid:75)
(cid:74)x thrice(cid:75) =(cid:74)x(cid:75)(cid:74)x(cid:75)(cid:74)x(cid:75)
(cid:74)turn around left(cid:75) = LTURN LTURN LTURN LTURN
(cid:74)turn around right(cid:75) = RTURN RTURN RTURN RTURN
(cid:74)u around left(cid:75) = LTURN(cid:74)u(cid:75) LTURN(cid:74)u(cid:75) LTURN(cid:74)u(cid:75) LTURN(cid:74)u(cid:75)
(cid:74)u around right(cid:75) = RTURN(cid:74)u(cid:75) RTURN(cid:74)u(cid:75) RTURN(cid:74)u(cid:75) RTURN(cid:74)u(cid:75)
(cid:74)turn opposite left(cid:75) = LTURN LTURN
(cid:74)turn opposite right(cid:75) = RTURN RTURN
(cid:74)u opposite left(cid:75) =(cid:74)turn opposite left(cid:75)(cid:74)u(cid:75)
(cid:74)u opposite right(cid:75) =(cid:74)turn opposite right(cid:75)(cid:74)u(cid:75)
(cid:74)x1 and x2(cid:75) =(cid:74)x1(cid:75)(cid:74)x2(cid:75)
(cid:74)x1 after x2(cid:75) =(cid:74)x2(cid:75)(cid:74)x1(cid:75)

Figure 3: The interpretation functions for translating SCAN commands to actions.

RNN
GRU
LSTM
RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep
L&B best
L&B best overall

Simple
75.6 ±5.4
100.0 ±0.0
99.8 ±0.1
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
100.0 ±0.0
99.8
99.7

Length
0.2 ±0.0
14.4 ±0.8
10.1 ±2.0
9.6 ±0.9
11.7 ±3.2
18.1 ±1.1
17.8 ±1.7
15.6 ±1.6
12.5 ±1.3
20.8
13.8

Jump
Turn left
0.0 ±0.0
26.7 ±12.8
0.0 ±0.0
53.4 ±11.7
0.1 ±0.0
56.5 ±0.8
1.9 ±1.2
81.1 ±14.7
2.7 ±1.7
92.0 ±5.8
59.1 ±16.8 12.5 ±6.6
0.7 ±0.4
90.8 ±3.6
9.7 ±2.9
83.8 ±16.8
57.6 ±3.8
0.8 ±0.5
1.2
90.3
90.0
0.1

Table 4: SCAN test scores on the simple, length, and primitive (turn left and jump) tasks. For ‘+Attn-Dep’ models
we removed the connections from the previous target word embedding to the decoder state and the pre-output layer.

53RNN
GRU
LSTM
RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep

Simple
26.9 ±0.2
99.0 ±0.1
99.1 ±0.1
99.8 ±0.1
61.1 ±0.3
99.8 ±0.1
51.2 ±1.2
99.1 ±0.2
38.9 ±0.9

Length
0.2 ±0.1
12.9 ±1.2
10.9 ±1.3
19.4 ±0.7
0.5 ±0.2
17.2 ±1.9
2.0 ±1.4
17.1 ±2.0
1.0 ±0.5

Turn left
Jump
26.4 ±12.0 0.0 ±0.0
47.5 ±4.7
0.0 ±0.0
0.0 ±0.0
42.9 ±2.9
0.3 ±0.3
44.1 ±0.9
18.6 ±1.0
0.0 ±0.0
0.0 ±0.0
55.9 ±3.5
0.0 ±0.0
16.9 ±1.2
0.0 ±0.0
48.3 ±1.7
17.2 ±1.2
0.0 ±0.0

Table 5: NACS test scores on the simple, length, and primitive (turn left and jump) tasks. For ‘+Attn-Dep’ models
we removed the connections from the previous target word embedding to the decoder state and the pre-output layer.

RNN
GRU
LSTM
RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep
L&B

8

4

2

1

0

16

0.1 ±0.0
2.5 ±1.1
3.8 ±1.8

0.0 ±0.0
0.6 ±0.2
1.3 ±0.2

0.0 ±0.0
0.2 ±0.1
0.3 ±0.2

32
1.4 ±0.3
0.1 ±0.1
0.5 ±0.3
0.0 ±0.0
42.4 ±2.5
3.3 ±0.9 13.1 ±2.4
0.1 ±0.0
21.3 ±1.4
2.5 ±1.1
6.5 ±2.7
0.1 ±0.0
3.5 ±3.0 35.0 ±2.8 48.6 ±8.1 77.6 ±2.6 89.2 ±3.8 98.7 ±1.3
99.8 ±0.1
2.7 ±1.7 29.5 ±10.5 53.3 ±10.2 82.4 ±4.7 98.8 ±0.8 99.8 ±0.1 100.0 ±0.0
12.5 ±6.6 58.2 ±12.0 67.8 ±3.4 80.3 ±7.0 88.0 ±6.0 98.3 ±1.8
99.6 ±0.2
0.7 ±0.4 70.9 ±11.5 61.3 ±13.5 83.5 ±6.1 99.0 ±0.4 99.7 ±0.2 100.0 ±0.0
98.6 ±1.0
7.8 ±0.9 40.2 ±9.3 37.7 ±10.7 50.3 ±13.9 62.2 ±7.7 94.0 ±2.7
99.8 ±0.2
0.8 ±0.6 39.0 ±6.5 43.6 ±17.6 66.0 ±1.6 86.1 ±2.3 98.7 ±1.6
0.1
89.9

15.3

70.2

0.1

0.1

4.1

Table 6: SCAN test scores for jump with additional composed commands.

8

4

2

1

0

16

0.2 ±0.0
0.3 ±0.2
0.7 ±0.0

32
0.4 ±0.0
0.8 ±0.1
0.0 ±0.0 0.1 ±0.0 0.1 ±0.1
RNN
5.8 ±0.1 20.8 ±2.2
0.0 ±0.0 0.3 ±0.2 0.4 ±0.1
GRU
3.7 ±0.4 11.4 ±1.2
0.0 ±0.0 0.6 ±0.4 0.5 ±0.3
LSTM
0.3 ±0.3 2.8 ±0.8 9.3 ±7.3 24.7 ±4.2 43.7 ±4.4 57.1 ±5.2 69.1 ±2.1
RNN +Attn
0.0 ±0.0 0.4 ±0.1 0.9 ±0.2
9.3 ±0.3 15.9 ±1.4
RNN +Attn-Dep
0.0 ±0.0 5.5 ±1.8 9.2 ±2.8 11.0 ±1.5 21.9 ±2.4 23.5 ±0.6 42.0 ±1.5
GRU +Attn
2.0 ±0.2
0.0 ±0.0 0.1 ±0.1 0.6 ±0.2
5.8 ±1.1 10.9 ±0.8
GRU +Attn-Dep
6.6 ±0.5 12.5 ±2.5 21.8 ±2.6 34.2 ±1.7
LSTM +Attn
0.0 ±0.0 2.1 ±0.2 3.7 ±0.9
LSTM +Attn-Dep 0.0 ±0.0 0.4 ±0.2 0.9 ±0.1
1.5 ±0.2
7.4 ±0.9

0.7 ±0.2
1.0 ±0.4
1.0 ±0.3

2.4 ±0.3

3.9 ±0.3

3.2 ±0.2

1.9 ±0.3

3.2 ±0.6

Table 7: NACS test scores for jump with additional composed commands.

54RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep

En-Fr
29.1 ±0.4
27.5 ±0.7
32.1 ±0.3
30.2 ±0.3
31.5 ±0.2
28.7 ±0.2

Fr-En
34.9 ±0.8
32.9 ±0.8
37.5 ±0.6
35.9 ±0.3
36.9 ±1.1
34.0 ±0.1

Table 8: Results (BLEU) on the Machine Translation experiment for both directions.

RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep

En-Fr
Fr-En
79.2 ±15.6 41.7 ±5.9
66.7 ±5.9
41.7 ±5.9
70.8 ±11.8 54.2 ±5.9
58.3 ±5.9
45.8 ±11.8
75.0 ±10.2 41.7 ±15.6
50.0 ±10.2 41.7 ±5.9

Table 9: Machine Translation: accuracy on eight novel sentences containing ‘daxy’ (‘daxiste’).

RNN +Attn
RNN +Attn-Dep
GRU +Attn
GRU +Attn-Dep
LSTM +Attn
LSTM +Attn-Dep

En-Fr
66.7 ±5.9
66.7 ±5.9
62.5 ±0.0
66.7 ±5.9
66.7 ±5.9
62.5 ±0.0

Fr-En
20.8 ±5.9
29.2 ±15.6
33.3 ±5.9
25.0 ±20.4
25.0 ±10.2
25.0 ±17.7

Table 10: Machine Translation: accuracy on eight novel sentences containing ‘tired’ (‘fatigu´e’).

55