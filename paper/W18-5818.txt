Phonological Features for Morphological Inﬂection

Adam Wiemerslage and Miikka Silfverberg, and Mans Hulden

Department of Linguistics
University of Colorado
University of Helsinki

first.last@colorado.edu

Abstract

Modeling morphological inﬂection is an im-
portant task in Natural Language Processing.
In contrast to earlier work that has largely used
orthographic representations, we experiment
with this task in a phonetic character space,
representing inputs as either IPA segments or
bundles of phonological distinctive features.
We show that both of these inputs, some-
what counterintuitively, achieve similar ac-
curacies on morphological inﬂection, slightly
lower than orthographic models. We conclude
that providing detailed phonological represen-
tations is largely redundant when compared
to IPA segments, and that articulatory distinc-
tions relevant for word inﬂection are already
latently present in the distributional properties
of many graphemic writing systems.

Introduction

1
Models of morphology are important to many
tasks in Natural Language Processing, but also
present new challenges of their own. Morpholog-
ically complex languages require analysis that is
often only captured at the morpheme level, but
is essential for syntactic or semantic representa-
tions. This requires effective morphological anal-
ysis, which often receives less attention than other
subﬁelds of Natural Language Processing. One
relevant task in morphology is that of morpho-
logical inﬂection: automatically generating the in-
ﬂected form of a lemma according to a given mor-
phological speciﬁcation. An example of this in
English is (cid:48)(cid:48)walk(cid:48)(cid:48) + 3 + SG + PRES → (cid:48)(cid:48)walks(cid:48)(cid:48).
There has been recent success in adopting the
encoder-decoder architecture (Kann and Sch¨utze,
2016), which has been effective in machine trans-
lation (Cho et al., 2014), to this task.

In this work, we explore representing the in-
puts to such an encoder-decoder model for mor-
phological inﬂection in two additional ways: IPA

segments and bundles of phonological distinctive
features. Representing the inputs to an inﬂec-
tion model in phonetic space can unify the charac-
ter inventory between languages with separate or-
thographies. The shared character inventory could
also enable transfer learning in some instances
where it otherwise would be impossible. There are
also confusing idiosyncrasies in some orthogra-
phies that are not necessarily present in an IPA
representation. For example, there are many in-
stances of gemination in English that do not occur
in the phonetic realizations of such words, as in
(cid:104)control(cid:105) → (cid:104)controlled(cid:105). English also exhibits
several examples of the same sound expressed by
completely different orthographic realizations as
in (cid:104)ﬂy(cid:105) → (cid:104)ﬂies(cid:105), or conversely (cid:104)arch(cid:105) (/tS/) ∼
(cid:104)monarch(cid:105) (/k/). Furthermore, a phonetic repre-
sentation serves as an interface to an even richer
representation of characters: phonological distinc-
tive features.

We explore this by representing each IPA seg-
ment in a sequence as the combination of its dis-
tinctive features. This is potentially useful because
(1) a model can learn representations for a ﬁxed set
of distinctive features, rather than for each unique
IPA segment, and (2) the differences between sim-
ilar phonemes should be more readily apparent in
the distinctive feature representations than the IPA
representations. When tasked with generating the
past tense of the English verb ”stop”, transcribed
as /stAp/, a model may need to distinguish between
both /t/ and /d/ as past tense sufﬁxes, having seen
such examples as ”kick”: /kIk/ → /kIkt/, or ”rig”:
/ôIg/ → /ôIgd/. Rather than the model needing to
learn good representations for both /p/ and /k/ as
unrelated segments that precede a /t/ in the past
tense, a phonological distinctive feature represen-
tation would explicitly capture that they share the
feature [−voice]. This encourages a model to more
quickly ﬁnd the parameters that correctly gener-

Proceedingsofthe15thSIGMORPHONWorkshoponComputationalResearchinPhonetics,Phonology,andMorphology,pages161–166Brussels,Belgium,October31,2018.c(cid:13)2018TheSpecialInterestGrouponComputationalMorphologyandPhonologyhttps://doi.org/10.18653/v1/P17161ate this voicing assimilation, and produce the form
/stApt/. That is, the model that learns from phono-
logical features should quickly be able to general-
ize that this English past tense is realized as /t/ be-
fore voiceless segments. Similarly, in the example
of ”rob”: /ôAb/ → /ôAbd/, the generated /d/ can be
conditioned on [+voice] rather than the individual
segment /b/.

An alternative hypothesis is that the proposed
distinctive feature representation may, however,
not have such a profound effect on the inﬂection
model. This is because distributional represen-
tations of IPA segments or phonemic graphemes
have been shown to capture good approximations
of the distinctive feature space (Silfverberg et al.,
2018). In order to test these two hypotheses, we
experiment on a subset of data provided by task 1
of the CoNLL-SIGMORPHON 2017 Shared Task
on Universal Morphological Reinﬂection (Cot-
terell et al., 2017), which introduced 42 more lan-
guages than the year before (Cotterell et al., 2016)
for a total of 52 languages. We use an existing tool
to perform G2P on the data, and, as a second step,
to produce distinctive feature vectors from the re-
sulting IPA segments. We evaluate the resulting
models on their ability to generate IPA segments.
Related Work Phonetic distributional vectors
have been explored for their effectiveness in sev-
eral NLP applications; especially for informing
scenarios that utilize borrowing or transfer learn-
ing (Tsvetkov et al., 2016). Phonological distinc-
tive features have also been successfully used to
inform NER (Bharadwaj et al., 2016). However,
to our knowledge, there does not seem to be work
in learning distributional properties of phonologi-
cal features that compares them directly to vectors
of IPA segments.

2 Encoder-Decoder Architecture
Our model is implemented as an RNN Encoder-
Decoder with attention, built to imitate the model
introduced by Kann and Sch¨utze (2016), varia-
tions of which found much success in the 2017
CoNLL-SIGMORPHON shared task. The system,
pictured in Figure 1, works by learning an encoder
RNN over a sequence of embeddings for the in-
put characters or morphological tags. In practice,
the encoder is bidirectional. The decoder RNN is
initialized with a sequence boundary token, and
each state of the decoder is predicted based on
the state of the previous timestep, the previous

Figure 1: The encoder-decoder with an attention mechanism
used for morphological inﬂection

Figure 2: PanPhon transforms a sequence of IPA segments
into a matrix of features

output embedding, and all of the encoder states
ei ∈ Encoder. We then use an attention mecha-
nism (Bahdanau et al., 2014) to ‘attend’ over the
encoder states, assigning a score to each ei given
the previous decoder state dj−1. The scoring func-
tion (Luong et al., 2015) is calculated as

score(ei; dj−1) = tanh([dj−1; ei] × W )

(1)

where W is a parameter matrix that is learned dur-
ing training, and [x; y] indicates the concatenation
of x and y. These scores are then normalized by
applying a softmax over all encoder states in En-
coder to compute each i,j−1.

Finally,

(cid:80)n

the attention vector is computed as
the weighted mean of all encoder states accord-
ing to their normalized score: A(dj−1, E) =
i=0 i,j−1ei, which is concatenated to the pre-
viously decoded embedding before being passed
through the decoder. We implement this model in
PyTorch (Paszke et al., 2017), using Gated Recur-
rent Units (GRU) (Cho et al., 2014) for the encoder
and decoder, and optimize with stochastic gradient
descent.

3 Embedding Inputs

The inputs to this model are sequences of charac-
ter and tag embeddings. To this end, each Uni-
code character codepoint or tag is a one-hot vec-
tor c, and an embedding matrix E ∈ R|Σ|×n is

162catNcatsEEEEEEEEEncoder Bi-RNNDecoder RNN<EOS>E<EOS>E<EOS>EPLE<EOS>EAttn[k,æ,t]-syl -son … -ant +hi+syl +son … 0ant -hi-syl -son … +ant -hiShared task

English
German
Hindi

Hungarian

Persian
Polish
Russian
Spanish
AVG

94.70
80.00
97.40
75.10
91.90
79.90
84.10
91.70
86.85

Medium
Text
89.70
71.80
84.80
67.10
84.10
67.10
66.90
76.50
76.21

IPA
72.50
60.80
89.80
65.50
85.00
63.40
66.80
82.10
72.61

High

Features Shared task
72.70
59.90
86.50
63.90
82.30
64.30
67.60
81.30
72.73

97.20
93.00
100.00
86.80
99.90
92.80
92.80
97.50
95.0

Text
96.60
89.50
99.80
83.70
99.10
88.20
89.20
95.20
92.66

IPA
77.00
82.30
99.60
82.80
99.20
88.20
86.50
96.40
89.00

Features
76.10
83.20
99.90
82.60
98.70
88.90
88.90
96.60
89.36

Table 1: Overall accuracy for each model (orthographic, IPA-based, and distinctive feature-based), and comparison with the
CoNLL-SIGMORPHON 2017 shared task top performing system for each language.

computed to store the parameters that map the
|Σ|-dimensional one-hot vectors to n-dimensional
dense vectors, where Σ is the character and tag
Similarly we use a matrix I ∈
vocabulary.
R|ΣIP A|×n for embedding IPA segments, where
ΣIP A is the IPA segment and tag vocabulary. To
produce the IPA sequence, we use the Python
library Epitran, which performs rule-based G2P
on language speciﬁc mappings (Mortensen et al.,
2018).

We then use the Python library PanPhon
(Mortensen et al., 2016), which maps IPA seg-
ments to features as in Figure 2, to obtain vectors
of phonological distinctive features. The features
are represented numerically whereby each index
of the vector corresponds to a speciﬁc feature such
as [±coronal] and stores a value from the set {1, 0,
-1}. These values correspond to ‘exhibits feature’,
‘unspeciﬁed for given class of sounds’, and ‘does
not exhibit feature’, respectively. In practice we
map -1 to 0 to obtain strictly binary feature vec-
tors. Now, each IPA segment can be represented
as a vector v which has a 1 for each feature that it
exhibits, and a 0 otherwise. The embedding ma-
trix F ∈ R|p|×n, where p is all features, tags, and
symbols is no longer just a lookup for IPA seg-
ments. Tags are still one-hot vectors, and sym-
bols are one-hot vectors for any character that has
no phonological features (e.g. a space, or apostro-
phe). But the vector for an IPA segment now has a
one for each feature that it exhibits, in contrast to
the one-hot vectors.

The operation vF is equivalent to summing
each Fi for which vi = 1. In this way, an IPA
segment is the sum of all of its distinctive feature
embeddings. In practice, we can take the matrix-
matrix product of the entire sequence of feature

vectors and F to calculate the matrix that rep-
resents a sequence of embeddings. The overall
workﬂow involves passing from orthographic in-
put sequences, through Epitran, and then PanPhon,
and ﬁnally to phonological distinctive feature em-
beddings.

4 Experiments and Results

We evaluate these models on 8 languages that
are at the intersection of CoNLL-SIGMORPHON
data, Epitran, and PanPhon supported languages,
selected to exhibit typological diversity. The lan-
guages, split into 2 training settings per the shared
task data: Medium (∼1,000 training examples),
and High (∼10,000 training examples), and their
accuracies are given in Table 1. In the high data
setting using orthographic inputs, our implementa-
tion performed comparably to the best shared task
systems for each language. The slight degrada-
tion in performance can be attributed to the fact
that we did not use ensemble voting, as the top
performing systems in the shared task did (Cot-
terell et al., 2017), and that this is a compar-
ison to the maximum score of 25 systems per
language, which increases the likelihood that the
optimal initialization will have been found.
In
the medium setting, the difference in accuracy is
much more apparent. This is due to the fact that
all of the top performing systems in the shared
task also used either some type of data augmenta-
tion method (Zhou and Neubig (2017), Silfverberg
et al. (2017), Sudhakar and Kumar (2017), Kann
and Sch¨utze (2017), Bergmanis et al. (2017)) a
hard alignment method (Makarov et al., 2017), or
both (Nicolai et al., 2017). These results illustrate
the common observation that neural systems re-
quire a large amount of data to be very accurate,

163ENSEMBLE ORACLE RESULTS
Medium

High

All inputs

94.20
79.50
94.50
78.60
91.40
79.40
78.30
89.2
85.64

Text All inputs
94.20
81.20
90.30
77.40
90.40
78.70
76.80
86.90
84.49

97.90
93.10
100.00
90.10
99.70
93.70
94.10
98.5
95.89

Text
97.50
94.30
100.00
90.10
99.60
92.6
92.50
97.0
95.45

English
German
Hindi

Hungarian

Persian
Polish
Russian
Spanish
AVG

Table 2: Ensemble Oracles for each language. If the cor-
rect word form is predicted by any of the 3 models, then it is
classiﬁed as correct. This is compared against 3 text models.

which can be partially addressed by artiﬁcially ex-
panding the training data, or enforcing some copy
bias into the system.

For both phonetic representation experiments,
the decoded outputs are in the inventory of IPA
segments, the gold standard of which comes from
the deterministic mappings implemented in Epi-
tran. This means that they differ only in terms
of the input representation in the encoder. Mod-
els trained on both IPA and feature inputs perform
comparably to the text model on both the medium
and the high setting. There are two main points of
interest in the results. (1) The lower performance
on average of the IPA and feature models when
compared to the text model is almost exclusively
due to differences in accuracy for German and En-
glish. We attribute this on the one hand to the
fact that the orthography of English is often dis-
similar to pronunciations and that their orthogra-
phies reﬂect etymological information which is
useful in determining a word’s inﬂectional behav-
ior (Scragg, 1974). An example of the discrepancy
between spelling and pronunciation is that the En-
glish vowel space has about 13 phonetic vowels
(Ladefoged and Johnson, 2014), whereas in the
orthographic alphabet, there are only 5. Further-
more, the unstressed vowel, schwa (@), can essen-
tially replace any vowel in an unstressed context.
We observe that the majority of inaccuracies in the
English predictions are related to vowels, and most
commonly to a schwa. This indicates that convert-
ing the character space to IPA can introduce some
new complications. Regarding German, there is
no obvious explanation for the lower accuracy, and
we believe that a more detailed analysis of the G2P
performance is needed in order to explore this. Ex-

periments on orthographically and morphophone-
mically similar languages may also be revealing.
An Ensemble Oracle of all three models is given
in Table 2 in order to check if the systems vary in
what they learn to predict. The results show that
this ensemble outperforms each individual system
for any given language. However, when compared
to an Ensemble Oracle of three text models, the
results are rather similar. The increase in accuracy
may simply be due to varying parameters from
different random initializations, yielding an effect
that is similar to the boosted scores that can be ob-
served in many of the shared task results.

More interesting is the fact that (2) both the IPA
and feature representation seem to yield extremely
similar accuracies with a paired permutation test
p-value of 0.43 over all languages. Even when
the training data is rather sparse as in the medium
setting, the accuracies remain extremely similar.
This suggests that the distributional properties of
IPA segments capture the information expressed
by distinctive features. Any beneﬁt that represent-
ing a segment in terms of its features might have is
already available in the IPA embeddings. To fur-
ther compare these representations, we experiment
with models that combine the IPA and feature rep-
resentations. We attempt to simply add a ‘feature’
to the distinctive feature vectors for each IPA seg-
ment. That is, the feature vector for /@/ would have
a 1 for all of its distinctive features, and an addi-
tional 1 for that speciﬁc segment. We also exper-
iment with concatenation of the embedding found
from the feature vector combination and the IPA
embedding. The input to the model is a vector of
double the embedding size to account for concate-
nation. The results, given in Table 3, show that
neither experiment seems to have much effect, and
the accuracies reﬂect the initial results.

5 Conclusion and Future Work

We have experimented with morphological inﬂec-
tion on 8 different languages and compared results
between an input space of IPA segments, and one
represented as bundles of phonological distinctive
features. The results show that both types of inputs
behave similarly. This indicates that the distribu-
tional properties of IPA segments align with those
found by phonological distinctive features, at least
to the extent that articulatory information is rele-
vant to inﬂection. Furthermore, when compared to
a baseline of a purely orthographic space, it is ev-

164INPUT COMBINATION RESULTS

Medium

High

Addition Concat Addition Concat
77.70
84.50
99.70
83.40
99.60
89.20
90.00
97.50
90.20

71.10
56.60
93.00
62.90
84.20
60.80
65.90
80.80
71.91

77.40
84.40
99.70
83.50
99.20
88.90
90.50
97.80
90.18

68.70
56.40
90.80
63.70
84.10
66.60
64.80
84.40
72.44

English
German
Hindi

Hungarian

Persian
Polish
Russian
Spanish
AVG

Table 3: Results for the combination of feature and IPA
embeddings. Addition refers to the inclusion of a speciﬁc
phoneme ‘feature’. Concat refers to concatenating the em-
bedding of both input types.

ident that for many languages the results are still
mostly redundant, and if there is a large discrep-
ancy in accuracy it is in favor of the orthographic
inputs.

There is still work to be done to explore if there
are scenarios where bundles of distinctive features
provide an advantage. That is, in the case of trans-
fer learning where the phonology of a language is
known, it becomes possible to approximate vector
representations for unseen segments. Similarly,
distinctive features may be better at representing
segments that rarely appear in a training set for a
given language.

Acknowledgements
The second author was supported by The Society
of Swedish Literature in Finland (SLS). NVIDIA
Corp. donated the Titan Xp GPU used for this re-
search.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. In ICLR 2015.

Toms Bergmanis, Katharina Kann, Hinrich Sch¨utze,
and Sharon Goldwater. 2017. Training data aug-
mentation for low-resource morphological inﬂec-
tion. In Proceedings of the CoNLL SIGMORPHON
2017 Shared Task: Universal Morphological Rein-
ﬂection, pages 31–39, Berlin, Germany. Association
for Computational Linguistics.

Akash Bharadwaj, David R. Mortensen, Chris Dyer,
Phonologically
and Jaime G. Carbonell. 2016.
aware neural model for named entity recognition in
low resource transfer settings. In Proceedings of the
2016 Conference on Empirical Methods in Natural

Language Processing, EMNLP 2016, Austin, Texas,
USA, November 1-4, 2016, pages 1462–1472.

Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014.
Learning
phrase representations using RNN encoder-decoder
for statistical machine translation. arXiv preprint
arXiv:1406.1078.

Jason Eisner,

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
G´eraldine Walther, Ekaterina Vylomova, Patrick
Xia, Manaal Faruqui, Sandra K¨ubler, David
Yarowsky,
and Mans Hulden.
2017. The CoNLL-SIGMORPHON 2017 shared
task:
reinﬂection in
the CoNLL-
52 languages.
SIGMORPHON 2017 Shared Task: Universal Mor-
phological Reinﬂection, Vancouver, Canada. Asso-
ciation for Computational Linguistics.

Universal morphological

In Proceedings of

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
David Yarowsky, Jason Eisner, and Mans Hulden.
2016. The SIGMORPHON 2016 shared task: Mor-
phological reinﬂection. In Proceedings of the 14th
SIGMORPHON Workshop on Computational Re-
search in Phonetics, Phonology, and Morphology,
Berlin, Germany. Association for Computational
Linguistics.

Katharina Kann and Hinrich Sch¨utze. 2016. MED: The
LMU system for the SIGMORPHON 2016 shared
task on morphological reinﬂection. In Proceedings
of the 14th SIGMORPHON Workshop on Computa-
tional Research in Phonetics, Phonology, and Mor-
phology, Berlin, Germany. Association for Compu-
tational Linguistics.

Katharina Kann and Hinrich Sch¨utze. 2017. The LMU
the CoNLL-SIGMORPHON shared
system for
task on universal morphological reinﬂection.
In
Proceedings of the CoNLL SIGMORPHON 2017
Shared Task: Universal Morphological Reinﬂec-
tion, pages 40–48, Berlin, Germany. Association for
Computational Linguistics.

Peter Ladefoged and Keith Johnson. 2014. A Course in

Phonetics. Nelson Education.

Minh-Thang Luong, Hieu Pham,

and Christo-
pher D. Manning. 2015. Effective approaches to
attention-based neural machine translation. CoRR,
abs/1508.04025.

Peter Makarov, Tatiana Ruzsics, and Simon Clematide.
2017. Align and copy: UZH at SIGMORPHON
2017 shared task for morphological reinﬂection. In
Proceedings of the CoNLL SIGMORPHON 2017
Shared Task: Universal Morphological Reinﬂec-
tion, pages 49–57, Berlin, Germany. Association for
Computational Linguistics.

David R. Mortensen, Siddharth Dalmia, and Patrick
Littell. 2018. Epitran: Precision G2P for many lan-
In Proceedings of the Eleventh Interna-
guages.

165Berlin, Germany. Association for Computational
Linguistics.

tional Conference on Language Resources and Eval-
uation (LREC 2018), Paris, France. European Lan-
guage Resources Association (ELRA).

David R. Mortensen, Patrick Littell, Akash Bharadwaj,
Kartik Goyal, Chris Dyer, and Lori Levin. 2016.
PanPhon: A resource for mapping IPA segments
In The 26th Inter-
to articulatory feature vectors.
national Conference on Computational Linguistics:
Technical Papers, page 34753484.

Garrett Nicolai, Bradley Hauer, Mohammad Motallebi,
Saeed Najaﬁ, and Grzegorz Kondrak. 2017. If you
can’t beat them, join them: the University of Alberta
In Proceedings of the CoNLL
system description.
SIGMORPHON 2017 Shared Task: Universal Mor-
phological Reinﬂection, pages 79–84, Berlin, Ger-
many. Association for Computational Linguistics.

Adam Paszke, Sam Gross, Soumith Chintala, Gre-
gory Chanan, Edward Yang, Zachary DeVito, Zem-
ing Lin, Alban Desmaison, Luca Antiga, and Adam
Lerer. 2017. Automatic differentiation in PyTorch.
In NIPS-W.

Donald George Scragg. 1974. A history of English

spelling, volume 3. Manchester University Press.

Miikka Silfverberg, Lingshuang Jack Mao, and Mans
Hulden. 2018. Sound analogies with phoneme em-
beddings. In Proceedings of the Society for Compu-
tation in Linguistics (SCiL), volume 1, pages 136–
144.

Miikka Silfverberg, Adam Wiemerslage, Ling Liu,
and Lingshuang Jack Mao. 2017. Data augmen-
In Proceed-
tation for morphological reinﬂection.
ings of the CoNLL SIGMORPHON 2017 Shared
Task: Universal Morphological Reinﬂection, pages
90–99, Berlin, Germany. Association for Computa-
tional Linguistics.

Akhilesh Sudhakar and Anil Singh Kumar. 2017. Ex-
periments on morphological reinﬂection: CoNLL-
2017 shared task. In Proceedings of the CoNLL SIG-
MORPHON 2017 Shared Task: Universal Morpho-
logical Reinﬂection, pages 71–78, Berlin, Germany.
Association for Computational Linguistics.

Yulia Tsvetkov, Sunayana Sitaram, Manaal Faruqui,
Guillaume Lample, Patrick Littell, David R.
Mortensen, Alan W. Black, Lori S. Levin, and Chris
Dyer. 2016. Polyglot Neural Language Models: A
Case Study in Cross-Lingual Phonetic Representa-
tion Learning. In NAACL HLT 2016, The 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, San Diego California, USA,
June 12-17, 2016, pages 1357–1366.

Chunting Zhou and Graham Neubig. 2017. Morpho-
logical inﬂection generation with multi-space vari-
In Proceedings of the
ational encoder-decoders.
CoNLL SIGMORPHON 2017 Shared Task: Uni-
versal Morphological Reinﬂection, pages 58–65,

166