Affordance Extraction and Inference

based on Semantic Role Labeling

Daniel Loureiro, Al´ıpio M´ario Jorge

LIAAD - INESC TEC

Faculty of Sciences - University of Porto, Portugal

dloureiro@fc.up.pt, amjorge@fc.up.pt

Abstract

Common-sense reasoning is becoming in-
creasingly important for the advancement of
Natural Language Processing. While word
embeddings have been very successful, they
cannot explain which aspects of ‘coffee’ and
‘tea’ make them similar, or how they could be
related to ‘shop’.
In this paper, we propose
an explicit word representation that builds
upon the Distributional Hypothesis to repre-
sent meaning from semantic roles, and allow
inference of relations from their meshing, as
supported by the affordance-based Indexical
Hypothesis. We ﬁnd that our model improves
the state-of-the-art on unsupervised word sim-
ilarity tasks while allowing for direct inference
of new relations from the same vector space.

Introduction

1
The word representations used more recently in
Natural Language Processing (NLP) have been
based on the Distributional Hypothesis (DH) (Har-
ris, 1954) — “words that occur in the same con-
texts tend to have similar meanings”. This sim-
ple idea has led to the development of powerful
word embedding models, starting with Latent Se-
mantic Analysis (LSA) (Landauer and Dumais,
1997) and later, the popular word2vec (Mikolov
et al., 2013) and GloVe (Pennington et al., 2014)
models. Although, effective at quantifying the
similarity between words (and phrases) such as
‘tea’ and ‘coffee’, they cannot relate that judge-
ment to the fact that both can be sold, for in-
stance. Furthermore, current representations can’t
inform us about possible relations between words
occurring in mostly distinct contexts, such as us-
ing a ‘newspaper’ to cover a ‘face’. While there
have been substantial improvements to word em-
bedding models over the years, these shortcom-
ings have endured (Camacho-Collados and Pile-
hvar, 2018).

Word Pairs

(w1, w2)
shop, tea

doctor, patient
newspaper, face

man, cup

Affordances

(w1 as ARG0, w2 as ARG1)

sell, import, cure

diagnose, prescribe, treat

cover, expose, poke

drink, pour, spill

Table 1: Results from affordance meshing (coordina-
tion) using automatically labelled semantic roles.

Glenberg et al. (2000) identiﬁed these issues
soon after LSA was introduced, and cautioned that
high-dimensional word representations, such as
those based on the DH, lack the necessary ground-
ing to be proper semantic analogues.
Instead,
Glenberg proposed the Indexical Hypothesis (IH)
which supports that meaning is constructed by (a)
indexing words and phrases to real objects or per-
ceptual, analog symbols; (b) deriving affordances
from the objects and symbols; and (c) meshing
the affordances under the guidance of syntax. Fol-
lowing Glenberg et al. (2000), this work considers
an object’s affordances as its possibilities for ac-
tion constrained by its context, including actions
which may not be directly perceived, which dif-
fers slightly from Gibson (1979)’s original deﬁni-
tion. Even though the language grounding advo-
cated by the IH is beyond the reach of NLP by
itself, we believe that its representation of mean-
ing through affordances can still be captured to a
useful extent.

Our contribution1 is a word-level representa-
tion that allows for the affordance correspondence
and meshing supported by the IH. These affor-
dances are approximated from occurrences of se-
mantic roles in corpora through an adaptation of
models based on the DH. Our work is motivated
by two observations: (1) a pressing need to in-
tegrate common-sense knowledge in NLP mod-

1Code, data and demo: https://a2avecs.github.io

ProceedingsoftheFirstWorkshoponFactExtractionandVERiﬁcation(FEVER),pages91–96Brussels,Belgium,November1,2018.c(cid:13)2018AssociationforComputationalLinguistics913 Method

Our word representations are modelled using
Predicate-Argument Structures (PASs).
These
structures are obtained through SRL of raw cor-
pora, and used to populate a sparse word/context
co-occurrence matrix W where roles serve as con-
texts (features), and argument spans serve as the
co-occurrence windows. The roles are predicates
speciﬁed by argument type (e.g. eat|ARG0) and
used in place of affordances. See Table 2 for a
comparison of this context deﬁnition with the tra-
ditional lexical deﬁnition.

Context
Words
e drinks|ARG0
John
drinks|ARG1
red, wine
drinks|ARGM-MNR slowly

l
o
R

y John
drinks
red
wine
slowly

c
n
e
c
a
j
d
A

drinks, red
John, red, wine
John, drinks, wine, slowly
drinks, red, slowly
red, wine

Table 2: Different context deﬁnitions applied to the
sentence ‘John drinks red wine slowly’. Top: Our pro-
posed deﬁnition; Bottom: Lexical adjacency deﬁnition
(with window size of 2).

After computing our co-occurrence matrix we
follow-up with the additional steps employed by
traditional bag-of-words models. We use Positive
Pointwise Mutual Information (PPMI) to improve
co-occurrence statistics, as used successfully by
Bullinaria and Levy (2007); Levy and Goldberg
(2014b), and maintain explicit high-dimensional
representations in order to preserve the context in-
formation required for affordance meshing. Pre-
vious works, such as Levy and Goldberg (2014a)
and Stanovsky et al. (2015), have also produced
word representations from syntactic context def-
initions (dependency parse trees and open infor-
mation extraction, respectively) but have opted for
following-up with the word2vec’s SkipGram (SG)
model, presumably inﬂuenced by a much higher
number of contexts in their approaches.

We reduce the sparsity of our explicit PPMI ma-
trix by linear combination and interpolation of se-
mantically related vectors. The semantic related-
ness is obtained from the cosine similarity of SG
vectors. As evidenced by Baroni et al. (2014), SG
seem best suited for estimating relatedness (or as-
sociation). These steps are further described in re-
mainder of this section (See Fig. 1).

Figure 1: Outline of model pipeline.

els and (2) recent improvements to Semantic Role
Labeling (SRL) have made affordance extraction
from raw corpora sufﬁciently reliable. We ﬁnd that
our model (A2Avecs) performs competitively on
word similarity tasks while enabling novel ‘who-
does-what-to-whom’ style inferences (Table 1).

2 Related Work

This work is closely related to the research area of
selectional preferences, where the goal is to pre-
dict the likelihood of a verb taking a certain argu-
ment for a particular role (e.g. likelihood of man
being an agent of drive). Most notably, Erk et al.
(2010) proposed a distributional model of selec-
tional preferences that used SRL annotations as
a primary set of verb-role-arguments from which
to generalize using word representations based
on the DH and several word similarity metrics.
Progress in selectional preferences is usually mea-
sured through correlations with human thematic ﬁt
judgements and, more recently, neural approaches
(de Cruys, 2014; Tilk et al., 2016) obtained state-
of-the-art results.

While this work shares some of these same el-
ements (i.e. SRL and word embeddings), they are
used to predict potential affordances instead of se-
lectional preferences. Consequently, our represen-
tations are designed to enable the meshing pro-
posed by the IH, allowing us to infer affordances
that would not be likely under a selectional pref-
erence learning scheme (e.g. newspaper-cover-
face from Table 1). Additionally, this work is
concerned with showing that information derived
from SRL is complementary to information de-
rived from DH methods, and thus focuses its eval-
uation on tasks related to lexical similarity rather
than thematic ﬁt correlations.

92CorpusPAS-based ContextsLexical ContextsM(VxR)M+(VxR)A(Vx300)Semantic Role LabelingSliding WindowPPMISkipGramLinear Combination3.1 Extracting PASs

We use the AllenNLP (Gardner et al., 2017) im-
plementation of He et al. (2017) state-of-the art
SRL to extract PASs from an English Wikipedia
dump from April 2010 (1B words). Since the
automatic identiﬁcation of predicates by an end-
to-end SRL may produce erroneous results, we
ensure that these predicates are valid by restrict-
ing them to the set of verbs tagged on the Brown
corpus (Francis and Kucera, 1979). We also use
the spaCy parser (Honnibal and Montani, 2017)
to reduce each argument phrase to its head noun
phrase, reducing the dilution of the more relevant
noun and predicate co-occurrence statistics (See
Fig. 2). Additionally, we lemmatize the predicates
(verbs) to their root form using WordNet’s Mor-
phy Lemmatizer (Miller, 1992). Finally, we trim
the vocabulary size and the number of roles by dis-
carding those which occur less than 100 times, and
consider only core and adjunct argument types.
The result is a set C of observed contexts, such as
<chase|ARG1, (the, cat)>, used to populate W .

ROOT

NPARG0

VP

NPARG0

PP

chasedPRED NPARG1

The dog

with NP

the cat

PST PMI THR RND MEN
L
.249 (1)
.309 (47)
.606 (47)
.611 (47)

P

0.5
0.5
0.6
0.4

N/Aa
.687 (0)
HDR
HDR .654 (14)
HDR
.668 (0)

L+H
L+H
L+H A+P
L+H A+P
L+H A+P
L+H A+P
L+H A+P

SP
98.71
99.41
99.58
99.59
< 41.2
98.21
97.98
98.77

aFailed after using too much memory.

Table 3: Sensitivity/Impact analysis for some parame-
ters of our approach.
Legend: PST: Post-Processing (L: Lemmatization; H: Head
noun phrase isolation); PMI: PMI Variations (P: PPMI; A:
Arg-speciﬁc PPMI); THR: Similarity threshold (tested val-
ues); RND: Rounding (HDR: Half down rounding); MEN:
MEN-3K task (Spearman correlation, #OOV failures); SP:
Sparsity (percentage of zero values on a 155Kx18K matrix).

each CARG, such that for each Ww,p:

P P M I(w, r) = max(P M I(w, r), 0))

P M I(w, r) = log

f (w, r)
f (w)f (r)

= log

#(w, r) · |CARG|

#(w) · #(r)

where w is a word from the vocabulary V , r is a
role (context) from the set R of the same argument
type as CARG, and f is the probability function.
The resulting matrix M = P P M I(W ) maintains
the dimensions W and is slightly sparser.

white stripes

3.3 Leveraging Association

Figure 2: Parse tree for the sentence ‘The dog with
white stripes chased the cat.’. The label for ARG0 is
repositioned to the smaller subtree.

3.2 Argument-speciﬁc PPMI

The authors of PropBank (Kingsbury and Palmer,
2002), which provides the annotations used for
learning SRL, state that arguments are predicate-
speciﬁc. Still, they also acknowledge that there are
some trends in the argument assignments. For in-
stance, the most consistent trends are that ARG0
is usually the agent, and ARG1 is the direct ob-
ject or theme of the relation. This realisation leads
us to adapting the PPMI measure to better account
for the correlations between roles of the same ar-
gument types. Thus, we segment C by argument
type, and apply PPMI independently considering

The constraints imposed by SRL yield a very re-
duced number of PAS-based contexts that can be
extracted from a corpus, in comparison to lexi-
cal adjacency-based contexts. Moreover, the post-
processing steps we perform, while otherwise ben-
eﬁcial (see Table 3), further trim this information.
To mitigate this issue, we also compute an embed-
ding matrix A (see Section 3 for parameters), us-
ing the state-of-the-art lexical-based SG model of
Bojanowski et al. (2017), and use those embed-
dings to obtain similarity values that can be used to
interpolate missing values in M, through weighted
linear combination. This way, existing vectors are
re-computed as:

(cid:126)v1 ∗ α1 + ... + (cid:126)vn ∗ αn

(cid:80)n

i=1 αi

(cid:126)vw =

93with αi deﬁned as:



A(cid:126)vw·A(cid:126)vi
(cid:107)A(cid:126)vw(cid:107)(cid:107)A(cid:126)vi

(cid:107) = cosA((cid:126)vw, (cid:126)vi),

if cosA((cid:126)vw, (cid:126)vi) > 0.5

αi =

0, otherwise

where cosA corresponds to the cosine similarity

in the SG representations.

The similarity threshold is tested on a few nat-
ural choices (0.5 ± 0.1) and validated from re-
sults on a single word similarity task (see Ta-
ble 3). This approach is also used to deﬁne rep-
resentations for words that are out-of-vocabulary
(OOV) for M, but can be interpolated from related
representations, similarly to Zhao et al. (2015).
In conjunction with the interpolation, we apply
half down rounding to the vectors, before and
after re-computing them, so that our representa-
tions remain efﬁciently sparse while beneﬁtting
from improved performance.
Finally, we ap-
ply a quadratic transformation to enlarge the in-
ﬂuence of meaningful co-occurrences, obtaining
M + = interpolate(M, A)2.

Inferring Relations

3.4
The examples shown in Table 1 are easily obtained
with our model through a simple procedure (see
Algorithm 1) that matches different arguments of
the same predicates. As was the case with Arg-
speciﬁc PPMI, this procedure is made possible by
the fact that a signiﬁcant portion of argument as-
signments remain consistent across predicates.

relations ← []
(cid:126)v1, (cid:126)v2 ← get vec(w1, M +), get vec(w2, M +)
for f1 ∈ f eatures((cid:126)v1) ∧ arg(f1) = a1 do

Algorithm 1 Affordance Meshing Algorithm
1: procedure INFERENCE(M +, w1, w2, a1, a2)
2:
3:
4:
5:
6:
7:
8:

for f2 ∈ f eatures((cid:126)v2) ∧ arg(f2) = a2 do

relations.add((f1 ∗ f2, pred(f1)))

if pred(f1) = pred(f2) then

return sorted(relations)

4 Evaluation and Experiments

The A2Avecs model introduced in this paper is
used to generate 155,183 word vectors of 18,179
affordance dimensions. This section compares
our model with lexical-based models (word2vec
(Mikolov et al., 2013), GloVe (Pennington et al.,

2014) and fastText (Bojanowski et al., 2017)) and
other syntactic-based models (Deps (Levy and
Goldberg, 2014a) and OpenIE (Stanovsky et al.,
2015)). We’re using Deps and OpenIE embed-
dings that
the respective authors trained on a
Wikipedia corpus and distributed online. Lexical
models were trained using the same parameters,
wherever applicable: Wikipedia corpus from April
2010 (same as mentioned in section 2.1); mini-
mum word frequency of 100; window size of 2;
300 vector dimensions; 15 negative samples; and
ngrams sized from 3 to 6 characters.

We also show that our approach can make use
of high-quality pretrained embeddings. We exper-
iment with a fastText model pretrained on 600B
tokens, referred to as ‘fastText 600B’ in contrast
with the fastText model trained on Wikipedia.

4.1 Model Introspection
The explicit nature of the representations pro-
duced by our model makes them directly inter-
pretable, similarly to other sparse representations
such as Faruqui and Dyer (2015b). The examples
presented at Table 4 demonstrate the relational ca-
pacity of our model, beyond associating meaning-
ful predicates. In this introspection we highlight
the top role contexts for a set of words, inspired
by (Levy and Goldberg, 2014a) which presented
the top syntactic context for the same words, and
note that this introspection produces results that
should correspond to Erk et al. (2010)’s inverse se-
lectional preferences.

Our online demonstration provides access to ad-
ditional introspection queries, such as top words
for given affordances, or which affordances are
most distinguishable between a pair of words (de-
termined by absolute difference).

batman
foil|ARG0
ﬂirt|ARGM-MNR
apprehend|ARG0
subdue|ARG0
rescue|ARGM-DIR
ﬂorida
base|ARGM-MNR
vacation|ARG1
reside|ARGM-DIS
fort|ARG1
vacation|ARGM-LOC

hogwarts
ambush|ARGM-MNR
rock|ARGM-LOC
express|ARG0
prevent|ARGM-LOC
expel|ARG2
object-oriented
deﬁne|ARG1
deﬁne|ARG0
use|ARG1
implement|ARG1
express|ARGM-MNR

turing
travel|ARGM-TMP
pass|ARGM-ADV
solve|ARG0
simulate|ARG1
prove|ARG1
dancing
dance|ARG0
dance|ARGM-MNR
dance|ARGM-LOC
dance|ARGM-ADV
dance|ARG1

Table 4: Words and their top role contexts. Using the
same words from the introspection of (Levy and Gold-
berg, 2014a) to clarify the difference in the representa-
tions of both approaches.

94Context

Lexical

Syntactic

Model
word2vec

GloVe

fastText (A)

Deps

Open IE

A2Avecs (M +)

A2Avecs (SVD(M +))

SL-666 SL-999 WS-SIM WS-ALL MEN RG-65
.793
.601
.799
.765
.801
.802
.789

.762
.637
.779
.758
.746
.734
.672

.672
.535
.702
.629
.696
.577
.509

.721
.636
.751
.606
.281
.687
.599

.426
.333
.426
.475
.397
.461
.436

.414
.325
.419
.446
.390
.412
.386

Lexical SOTA
Intp. w/SOTA
Intp. & Conc.
Deps Conc.

fastText 600B (A)
A2Avecs (M +)
A2Avecs (M + (cid:107) A)

Deps (cid:107) A

.523
.513
.540
.524

.504
.468
.521
.503

.839
.780
.846
.818

.791
.619
.771
.752

.836
.744
.829
.770

.859
.814
.857
.835

Table 5: Spearman correlations for word similarity tasks (see Faruqui and Dyer (2014) for task descriptions). Top
section shows results from training on the Wikipedia corpus exclusively. Bottom section shows results where we
used SG embeddings (A) trained on a larger corpus for performing interpolation and concatenation on the same
set of roles used above. For comparison, we also show results for Deps concatenated with those embeddings.

4.2 Word Similarity
The results presented on Table 5 show that our
model can outperform lexical and syntactic mod-
els, in spite of maintaining an explicit representa-
tion. In fact, applying Singular Value Decomposi-
tion (SVD) to obtain dense 300-dimensional em-
beddings degrades performance. We achieve best
results with the concatenation of the fastText 600B
vectors with our model interpolated using those
same vectors for the vocabulary VM + ∩ VA, after
normalizing both to unit length (L2). Interestingly,
the same concatenation process with Deps embed-
dings doesn’t seem as beneﬁcial, suggesting that
our representations are more complementary.

5 Conclusion

Our results suggest that semantic similarity can
be captured in a vector space that also allows for
the inference of new relations through affordance-
based representations, which opens up exciting
possibilities for the ﬁeld. In the process, we pre-
sented more evidence to support that information
obtained from SRL is complementary to informa-
tion obtained from adjacency-based contexts, or
even contexts based on syntactical dependencies.
We believe this work helps bridge the gap between
selectional preferences and semantic plausibility,
beyond frequentist generalizations based on the
DH. In the near term, we expect that speciﬁc tasks
such as Entity Disambiguation and Coreference
can beneﬁt from these representations. With fur-
ther developments, semantic plausibility assess-
ments should also be useful for more broad tasks
such as Fact Veriﬁcation and Story Understanding.

References
Marco Baroni, Georgiana Dinu,

and Germ´an
a
Kruszewski. 2014.
systematic comparison of context-counting vs.
context-predicting semantic vectors. In ACL.

Don’t count, predict!

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. TACL, 5:135–146.

John A. Bullinaria and Joseph P. Levy. 2007. Ex-
tracting semantic representations from word co-
occurrence statistics: a computational study. Behav-
ior research methods, 39 3:510–26.

Jos´e Camacho-Collados and Mohammad Taher Pile-
hvar. 2018. From word to sense embeddings: A sur-
vey on vector representations of meaning.

Tim Van de Cruys. 2014. A neural network approach

to selectional preference acquisition. In EMNLP.

Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
ﬂexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics,
36:723–763.

Manaal Faruqui and Chris Dyer. 2014. Community
evaluation and exchange of word vectors at word-
vectors.org. In ACL.

Manaal Faruqui and Chris Dyer. 2015b.

Non-
distributional word vector representations. In ACL.

W. Nelson Francis and Henry Kucera. 1979. The
Brown Corpus: A Standard Corpus of Present-Day
Edited American English. Brown University Ligu-
istics Department.

Matt Gardner, Joel Grus, Mark Neumann, Oyvind
Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew
Peters, Michael Schmitz, and Luke S. Zettlemoyer.
2017. Allennlp: A deep semantic natural language
processing platform.

95J. J. Gibson. 1979. The ecological approach to visual

perception. Brain and language.

Arthur M. Glenberg, David A. Robertson, Brianna
Benjamin, Jennifer Dolland, Jeanette Hegyi, Kather-
ine V Kortenkamp, Erik Kraft, Nathan Pruitt,
Dana Scherr, and Sara Steinberg. 2000. Symbol
grounding and meaning: A comparison of high-
dimensional and embodied theories of meaning.

Zellig Harris. 1954. Distributional structure.

10(23):146162.

page

Luheng He, Kenton Lee, Mike Lewis, and Luke S.
Zettlemoyer. 2017. Deep semantic role labeling:
What works and what’s next. In ACL.

Matthew Honnibal and Ines Montani. 2017. spacy 2:
Natural language understanding with bloom embed-
dings, convolutional neural networks and incremen-
tal parsing. To appear.

Paul Kingsbury and Martha Palmer. 2002. From tree-

bank to propbank. In LREC.

Thomas K. Landauer and Susan T. Dumais. 1997. A
solution to plato’s problem: The latent semantic
analysis theory of acquisition, induction, and repre-
sentation of knowledge.

Omer Levy and Yoav Goldberg. 2014a. Dependency-

based word embeddings. In ACL.

Omer Levy and Yoav Goldberg. 2014b. Linguistic reg-
ularities in sparse and explicit word representations.
In CoNLL.

Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In HLT-NAACL.

George A. Miller. 1992. Wordnet: A lexical database

for english. Commun. ACM, 38:39–41.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In EMNLP.

Gabriel Stanovsky, Ido Dagan, and Mausam. 2015.
Open ie as an intermediate structure for semantic
tasks. In ACL.

Ottokar Tilk, Vera Demberg, Asad B. Sayeed, Dietrich
Klakow, and Stefan Thater. 2016. Event participant
modelling with neural networks. In EMNLP.

Kai Zhao, Hany Hassan, and Michael Auli. 2015.
Learning translation models from monolingual con-
tinuous representations. In HLT-NAACL.

96