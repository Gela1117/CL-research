A neural parser as a direct classiﬁer for head-ﬁnal languages

Hiroshi Kanayama Masayasu Muraoka

Ryosuke Kohita

fhkana, mmuraokag@jp.ibm.com, Ryosuke.Kohita1@ibm.com

IBM Research
Tokyo, Japan

Abstract

the output of

This paper demonstrates a neural parser
implementation suitable for consistently
head-ﬁnal
languages such as Japanese.
Unlike the transition- and graph-based al-
gorithms in most state-of-the-art parsers,
our parser directly selects the head word
of a dependent from a limited number
of candidates. This method drastically
simpliﬁes the model so that we can eas-
ily interpret
the neural
model. Moreover, by exploiting grammat-
ical knowledge to restrict possible modiﬁ-
cation types, we can control the output of
the parser to reduce speciﬁc errors with-
out adding annotated corpora. The neu-
ral parser performed well both on conven-
tional Japanese corpora and the Japanese
version of Universal Dependency corpus,
and the advantages of distributed represen-
tations were observed in the comparison
with the non-neural conventional model.

Introduction

1
Dependency parsing helps a lot
to give intu-
itive relationships between words such as noun-
verb and adjective-noun combinations. Those
outputs are consumed in text mining systems
(Nasukawa and Nagano, 2001) and rule-based ap-
proaches such as in ﬁne-grained sentiment extrac-
tors (Kanayama et al., 2004), though some of re-
cent end-to-end systems do not require intermedi-
ate parsing structures.

Many recent dependency parsers have been im-
plemented with neural net (NN) methods with
(typically bidirectional) LSTM and distributed
word vectors (Dozat et al., 2017; Shi et al., 2017),
as we can see in the 2017 shared task on de-
pendency parsing from raw text for 49 lan-

guages (Zeman et al., 2017) based on the multi-
lingual corpora of Universal Dependencies (UD)
(Nivre et al., 2015).

Most of such dependency parsers exploit a
transition-based algorithm (Nivre et al., 2007), a
graph-based algorithm (McDonald et al., 2005)
or a combination of both (Nivre and McDonald,
2008). Those algorithms addressed several prob-
lems in multilingual dependency analysis such as
bidirectional dependency relationships and non-
projective sentences. However, it is hard to in-
tuitively interpret the actions to be trained on the
transition-based parser. Though it can handle the
history of past parsing actions, the output may vi-
olate syntactic constraints due to the limitation of
visible histories. The graph-based approach cap-
tures global information in a sentence, but the dif-
ﬁculty in reﬂecting the interaction of attachment
decisions causes contradictory labels in a tree.

The parsing results from the participants in the
2017 shared task show low scores on Japanese (67
to 82% in the UAS scores, excluding the team that
provided the data) in particular, which shows that
the language-universal approaches do not work ef-
fectively for Japanese.1

The syntactic structures in the Japanese version
of Universal Dependencies (Tanaka et al., 2016;
Asahara et al., 2018) have dependencies in both
directions, as well as in other languages, since
it is based on the word level annotations and
the content-head dependency schema. However,
when the syntactic structures are expressed with
the dependencies between phrasal units (so-called
bunsetsus in Japanese; ‘PU’ hereafter in this pa-
per), the head element always comes in the right
position, since Japanese is a consistently head-
ﬁnal language. This allows us to apply a method
for such languages to simplify the model. We con-
1Note that another factor in the low score was the incon-

sistent tokenization (84 to 93% F1 value).

ProceedingsoftheWorkshopontheRelevanceofLinguisticStructureinNeuralArchitecturesforNLP,pages38–46Melbourne,Australia,July19,2018.c(cid:13)2018AssociationforComputationalLinguistics38nsubj

obj

advcl

obl

?
男の子
otokonoko

case ?
は
ha

‘boy’
NOUN

-TOPIC
ADP

acl?

赤い
akai
‘red’
ADJ

?
ボール

boru
‘ball’
NOUN

case ?
を
wo
-ACC
ADP

?
買っ
kat-
‘buy’
VERB

mark ?
て
te

-ADV
SCONJ

?
学校
gakko
‘school’
NOUN

case ?
で
de

-LOC
ADP

root

punct

aux
mark ?
で
de

-ADV
SCONJ

?
遊ん
ason
‘play’
VERB

?
いる
iru

-PROG
AUX

?
。
.
‘.’

PUNCT

Figure 1: Japanese word-level dependencies in the UD-style content-head schema for an example sen-
tence “男の子は赤いボールを買って学校で遊んでいる。” (‘A boy bought a red ball and is playing at
the school’) .

?
男の子
‘boy’
NOUN

は

-TOPIC
ADP

?
赤い
‘red’
ADJ

?
ボール
‘ball’
NOUN

を
-ACC
ADP

?
買っ
‘buy’
VERB

?
学校
‘school’
NOUN

て
-ADV
SCONJ

root

?

で
-LOC
ADP

遊ん
‘play’
VERB

で
-ADV
SCONJ

いる
-PROG
AUX

。
‘.’

PUNCT

Figure 2: Japanese dependencies in PUs (phrasal units). There is a strict head-ﬁnal constraint.

structed a neural parsing model to directly select
the head word among the limited candidates. The
model works as a classiﬁer that outputs intuitive
and consistent results while exploiting grammati-
cal knowledge.

to exploit

Section 2 reviews the head-ﬁnal property
of Japanese and the Triplet/Quadruplet Model
(Kanayama et al., 2000)
syntactic
knowledge in a machine-learning parser. Section 3
designs our neural model relying on the grammati-
cal knowledge, and its experimental results are re-
ported in Section 4. Other head-ﬁnal languages
are discussed in Section 5 and some related ap-
proaches are discussed in Section 6. Section 7
concludes this paper.

2 Background

First, Section 2.1 shows the head-ﬁnal property of
the Japanese language. and Sections 2.2 and 2.3
explain the main ideas in the Triplet/Quadruplet
Model:
the methods of simpliﬁcation of depen-
dency parsing task using the linguistic knowledge.

2.1 Head-ﬁnal structure in Japanese
Figure 1 shows an example of a word-level de-
pendency structure of a Japanese sentence in the
representation of Universal Dependencies. Tradi-
tionally Japanese dependency parsers have been
evaluated on the unit of bunsetsu, a phrasal unit
(PU), as performed in Kyoto University Text Cor-
pus (Kawahara et al., 2002). A PU consists of a

content word2 and optional functional words and
preﬁxes and sufﬁxes. Figure 2 depicts the depen-
dency structure represented in PUs, where the all
dependencies are in a single direction. The head
PU is always in the right and the rightmost PU is
always the root, as long as exceptional inversion
cases are not cared. In this paper we exploit this
property to apply a simpliﬁed parsing algorithm:
the parsing can be regarded as the selection of the
head PU from the limited number of candidates
PUs located to the right of the dependent in ques-
tion. For example, the second PU “赤い” (‘red’)
in Figure 2 must modify one of the four PUs from
the third “ボール を” (‘ball’-ACC) to the sixth PU
“遊ん で いる” (‘play’-PROG). The correct head
is “ボール を” (‘ball’-ACC).

2.2 Restriction of modiﬁcation candidates
The head-ﬁnal feature can further simplify the de-
pendency parsing by adding syntactic constraints.
The Triplet/Quadruplet Model (Kanayama et al.,
2000) has been proposed to achieve the statisti-
cal dependency parsing making most of the lin-
guistic knowledge and heuristics. In their work, a
small number (about 50) of hand-crafted grammar
rules determine whether a PU can modify each PU
to its right in a sentence as shown in Table 1. In
the rules, the modiﬁed PUs are determined on the
conditions of the rightmost morpheme in the mod-
iﬁer PU.
In addition to PoS-level relationships,

2In case of compound nouns and verbs, multiple content

words may be included in a single PU.

39Rightmost morpheme of the modiﬁer PU Conditions for the modiﬁed PUs

postpositional “を” wo (accusative)
postpositional “から” kara (‘from’)
postpositional “から” kara (‘from’)
proper noun + postpositional “から “
postpositional “の” no (genitive, nominative)
postpositional “と” to (conjunctive)
postpositional “と” to (conjunctive)
adverb

verb, adjective
verb, adjective
nominal followed by postpositonal “まで” made (‘to’)
proper noun followed by postpositional “の” (-GEN)
noun, verb, adjective
noun, verb, adjective
adverb “一緒に” isshoni (‘together’)
verb, adjective, adverb, nominal with copula

Table 1: The excerpt of Japanese grammar rules. The left side is the condition of the modiﬁer PU
speciﬁed with the rightmost morpheme (except for punctuation) with optional preceding morphemes,
and the right side is the list of the condition for the modiﬁable PUs speciﬁed with the head word and
optional functional words.

# of

Ratio

1st

candidates

1
2
3
4
(cid:21)5
Total

32.7
28.1
17.5
9.9
11.8
100

100.0
74.3
70.6
70.4
70.2
(cid:0)

2nd
(cid:0)
26.7
12.6
11.1
11.1
(cid:0)

Last
(cid:0)
(cid:0)
16.8
13.8
10.5
(cid:0)

Sum

100.0
100.0
100.0
95.3
91.9
98.6

Table 2: Percentages of the position of the correct
modiﬁed PU among the candidate PUs selected
by the initial grammar rules. The column ‘Sum’
shows the coverage of the 1st, 2nd and last (the far-
thest) PUs in the distance from the modiﬁer PUs.
The EDR Japanese corpus was used in this analy-
sis.

two or three candidates and by ignoring the other
PUs with a small sacriﬁce (1.4%) of parsing ac-
curacy. Retaining the farthest modiﬁable PU from
the modiﬁer, the long distance dependencies are
captured.

2.3 Calculation of modiﬁcation probabilities
Let u be a modiﬁer PU in question, cun the u’s n-
th modiﬁcation candidate PU, (cid:8)u and (cid:9)cun the re-
spective attributes of u and cun. Then the probabil-
ity of u modifying its n-th candidate is calculated
by the triplet equation (1) when u has two candi-
dates or the quadruplet equation (2) when u has
three candidates.3 These two equations are known
as the Triplet and Quadruplet Model.

detailed condition with speciﬁc functional words
and exceptional content words are covered in the
rules. Even with these simpliﬁed rules, 98.5% of
the modiﬁcations between PUs are covered.

The role of the grammar rules is to maximize
the coverage, and the rules are simply describing
high-level syntactic dependencies so that the rules
can be created easily without worrying about pre-
cision or contradictory rules. The statistical infor-
mation is later used to select the rules necessary
for a given sentence to produce an accurate pars-
ing result.

Furthermore, an analysis of the EDR corpus
shows that 98.6% of the correct dependencies are
either the nearest PU, the second nearest PU, or
the farthest PU from the modiﬁer (more details in
Table 2) among the modiﬁable PUs enumerated
by the grammar rules. Therefore, the model can
be simpliﬁed by restricting the candidates to these

P (u   cun) = P (n j (cid:8)u; (cid:9)cu1; (cid:9)cu2)
(1)
P (u   cun) = P (n j (cid:8)u; (cid:9)cu1; (cid:9)cu2; (cid:9)cu3) (2)
Assuming the independence of those modiﬁca-
tions, the probability of the dependency tree for
an entire sentence P (T ) is calculated as the prod-
uct of the probabilities of all of the dependencies
in the sentence using beam search from the right-
most PU to the left, to maximize P (T ) under the
constraints of the projected structure.
P (u   cun)

P (T ) ≃

∏

(3)

u

Equations (1) and (2) have two major advan-
tages. First, all the attributes of the modiﬁer and
its candidates can be handled simultaneously – the
model expresses the context through the combi-
nation of those attributes. Second, the probabil-
ity of each modiﬁcation is calculated based on the
3It is trivial to show that P (u   cu1) = 1, when u has

only one candidate.

40softmax

●
6
●●●
6

hidden layer ●●●●●●●●●●●●●●●●●●●●●●

●●●●
‘president’

●●●
noun

●●●●

●●●

wo

part+comma

●●●●
‘acquire’

●●●
verb

●●●●

●●●

ta

aux

●●
(0,1,1)
6

●●●●
‘introduce’

●●
(0,1,3)
6

●●●
verb+‘,‘

●●●●
‘introduce’

●●●
verb+‘,‘

●●
(0,2,7)
6

●●●●
‘launch’

●●●
verb

●●●●

‘.’

●●●
period

社長　　を　、
Shacho 　wo 　,
‘president’-ACC

Modiﬁer

買収し　　た
baishu-shi 　ta
‘acquired’-ADN
Candidate 1

紹介　　、
shokai 　,

‘introduced’-ADV

Candidate 2

開始し　た　。
kaishi-shi 　ta
‘launch’-PAST
Candidate 3

Figure 3: The neural net for the quadruplet model to select the head of the PU “社長を” (‘president’-
ACC) from three modiﬁcation candidates in an example sentence “ … 以前の社長を、0買収した1 企業
に紹介、2 … 事業を開始した。3” (‘... introduced2 the previous president0 to the acquired1 company, and
launched3 a ... business’). The attributes of the modiﬁer PU and three modiﬁcation candidates, and the
features between the modiﬁer and each candidate are input as distributed vectors.

relative positions of the candidates, instead of the
distance from the modiﬁer PU in the surface sen-
tence, making the model more robust.

3 NN parsing model

In the past
implementation of the parser by
the Triplet/Quadruplet model (Kanayama et al.,
2000),
the equations (1) and (2) were calcu-
lated with logistic regression (maximum entropy
method) in which many binary features represent
the attributes of each PU. We designed the NN
model using distributed representation of words
and parts-of-speech as Chen and Manning (2014)
did.

Figure 3 shows the neural net model that di-
rectly selects the head PU and an example sen-
tence. Here, the head of “社長を” (‘president-
ACC’) is predicted among three modiﬁcation can-
didates selected by the method described in Sec-
tion 2.2. The second candidate PU “紹介、”
(‘introduced-ADV’) is the correct head.

To make the prediction, the attributes for each
PU are extracted, and we focus on two words in a
PU: the head word – the rightmost content word in
the PU – and the form word – the rightmost func-
tional word in the PU except for a punctuation.
First, the surface form and the PoS of the head
word and the form word are converted into vector
representations. That is, two vectors are used for
6 PUs in the triplet model and 8 PUs are used in
the quadruplet model. Furthermore, the following
attributes between two PUs are added.

(cid:15) the number of a postpositional “は ha”4 be-
tween two PUs (0, 1, 2, 3, 4, or 5+)
(cid:15) the number of commas between two PUs (0,
1, 2, 3, 4, or 5+)
(cid:15) the distance between two PUs (1, 2, 3, ..., 9,
or 10+)

These features expressed as vectors are concate-
nated to form a single layer, and the ﬁnal output is
given as the softmax of two or three values (1, 2,
or 3).

The above calculation computes the probabili-
ties of the modiﬁcation to candidate PUs, but it
does so independently for each modiﬁer PU; there-
fore, there may be crossing of modiﬁcation in a
whole sentence. Since the Japanese dependency
structures are fully projective, the optimal tree for
the sentence is constructed using a beam search to
maximize the Equation (3) in Section 2.3, exclud-
ing modiﬁcation pairs that violate the projective
constraint in each step of the beam search. More
speciﬁcally, combinations of dependencies which
violate projective constraints (e.g. 5   7 and 6  
8) are excluded from the beam, then the projective
tree structure is guaranteed.

4 Experiments
4.1 Experimental settings
We used EDR Japanese Corpus (EDR, 1996) for
the initial training and evaluation. After remov-

4Typical used as a topic marker, which suggests a long-

distance dependency.

41Training method
nearest baseline
logistic regression

NN
NN
NN
NN

Training size
none
190k
40k
80k
120k
160k

Accuracy

62.03% (13581/21894)
88.92% (19468/21894)
88.15% (19300/21894)
88.49% (19373/21894)
89.17% (19522/21894)
89.31% (19554/21894)

Table 3: The accuracy of PU dependencies tested on EDR corpus. The ‘nearest baseline’ denotes the
ratio of the case where the head is the right next PU.

ing inconsistent PUs due to tokenization mis-
match between the corpus and the runtime pro-
cess, the evaluation was conducted on 2,941 test
sentences. 160,080 sentences were used for train-
ing and 8,829 sentences were kept for validation.
The models were implemented with Tensor-
Flow (Abadi et al., 2015).
The loss function
was calculated by cross entropy. The L2 nor-
(cid:0)8 was added,
malization factor multiplied by 10
and output was optimized with AdamOptimizer
(Kingma and Ba, 2014).

Words are expressed by two vectors. One was
100 dimensional embeddings of the surface form
– the other was 50 dimensional embeddings of 148
types of values of the combination of 74 types of
ﬁne-grained PoS and a binary feature to ﬁnd the
existence of a comma in the PU. The three features
between PUs were converted into 10 dimensional
vectors. All of these vectors were randomly ini-
tialized and updated during the training. The input
layer formed 990 in the triplet model and 1,320 di-
mensions in the quadruplet model. The dimension
of the hidden layer was set to 200 and conducted a
beam search with the size 5.

4.2 Experimental results
Table 3 shows the accuracies of dependency pars-
ing by the conventional model trained with logis-
tic regression and our proposed neural net model.
Both models used the very similar grammar rules
and the features are used. While the logistic
regression method required manual selection of
combination of features to get optimal accuracy,
the neural net model outperformed the others
when the training corpus was more than 120k sen-
tences, by 0.4 points when the training corpus was
160k sentences. The maximum number of the
training data in neural net model (160k) is less
than that used in the logistic regression method
(190k) because the development set needed to be

Content words Commas Accuracy
89.31%
88.95%
87.40%
87.24%

Yes
Yes
No
No

Yes
No
Yes
No

Table 4: Ablation studies to remove content word
vocabularies and commas.

kept for the neural model, and some sentences
were dropped as described in Section 4.1.

Only words in the modiﬁer PU and the candi-
date PUs were used in these methods, and other
surrounding context and other dependencies were
not considered. By capturing appropriate contexts
of candidate PUs selected by the grammar rules
and heuristics, our method successfully predicted
the dependencies with relatively small pieces of
information compared to the initial
transition-
based neural parser (Chen and Manning, 2014)
that used a maximum of 18 words in the buffer,
stack and modiﬁers.

There was a huge difference in the training
speed. The logistic regression method took 4 to
20 hours on a CPU, but the neural net model con-
verged in 5 to 15 seconds on a GPU.

We conducted an ablation study to see the con-
tribution of attributes. We focused on the vo-
cabulary of content words that can be better cap-
tured using distributed representation rather than
the conventional method, and commas that played
an important role in suggesting long-distance at-
tachments. According to the results in Table 4,
the contribution of the content words (the vocab-
ulary size was 11,362) was not very big; even if
the content words were ignored, the loss of accu-
racy was only 0.36 points. On the other hand, the
model ignoring commas (where all of the features
regarding commas was removed) downgraded the

42word-based (UD)

?
彼
‘he’

彼
‘he’

?
が

-NOM

が

-NOM
6

?
3
‘3’

3
‘3’

?
km
‘km’

km
‘km’
6

?
た

-PAST

た

-PAST

走っ
‘run’

走っ
‘run’

?
。
.

。
.

PU-based

Figure 4: Conversion between PU-based and
word-based dependencies.

accuracy by nearly 2 points, which suggests that
commas are important in parsing.
The example dependency in Figure 3 (‘presi-
dent’   ‘introduced’) was correctly solved by our
neural model. Though many PUs followed the
modiﬁer PU in question, the model selected the
head word from only three candidates restricted by
the grammar rules, and the known dependency re-
lationship between two PUs is guaranteed to be as-
sociated with the parsing result. The conventional
model without neural net wrongly selected the ﬁrst
candidate (‘acquired’) as the head. The ablation of
the content words also made the prediction wrong,
that clariﬁed that it was because the conventional
model did not capture the content words and the
attributes in the distance were stronger. On the
other hand, the neural model with the content word
embeddings appropriately captured the relation-
ship between the functional word in the modiﬁer
PU (accusative case) and the content word of the
correct candidate PU (‘introduced’).

4.3 Comparison on Japanese UD
To compare the performance of our parser with
the results in the 2017 Shared Task (Zeman et al.,
2017), we apply the trained model
to UD
Japanese-GSD 5 test data. As shown in Figure 4,
the word-based dependency in UD Japanese and
PU-based dependencies are interchangeable with
a strict rule to detect PU boundaries and the head
word in a PU. In UD Japanese-GSD data, the at-
tachment direction between head words in PUs is
always the same after converting to the PU-based
structure. Also the non-head words in a PU always
depends on the head word of the PU.

The ﬁrst section of Table 5 shows comparisons
with the shared task results. Here we evaluate

5It was formerly known as UD Japanese until 2017.

them by UAS (unlabeled attachment score) rather
than by LAS (labeled attachment score) because
most of the Japanese labels can be deterministi-
cally assigned with the combination of the head
and the dependent, and assignment with the rules
can reproduce the labels in UD Japanese-GSD
corpus, thus it is not fair to compare LAS with
other machine learning methods. The scores are
associated with tokenization accuracies because
they highly affect Japanese parsing accuracies in
the shared task to handle raw text inputs. Our
model performed better than any other results in
the shared task, though the comparison is not com-
pletely fair since we rely on the segmentation and
functional word attachment based on the consis-
tent rules with the UD data creation.

In the 2017 Shared Task, the raw text was used
as the input, thus the performance of sentence
splitting and tokenization highly affected the pars-
ing result.6 To make more direct comparisons in
parsing, our results were mapped with the base-
line tokenzation by UDPipe (Straka et al., 2016)
which many task participants have used. That is,
the parsing score was intentionally downgraded,
but it outperformed any other results which used
UDPipe tokenization as it was, as shown in the
second section of Table 5.

Also we compared our parser when the gold
tokens are given, with UDPipe UDv2.0 model
(Straka and Strakov´a, 2017), and RBG Parser
(Lei et al., 2014) which was trained with UD
Japanese-GSD training set. Our model had 9%
and 20% less errors than UDPipe and RBG Parser,
respectively.

5 Application to other languages

Our approach relies on the head-ﬁnal feature of
the languages.
In addition to Japanese, Korean
and Tamil are categorized as rigid head-ﬁnal lan-
guages (Polinsky, 2012). Table 6 shows the ra-
tio of head-ﬁnal dependencies by languages in the
Universal Dependencies version 2.0 development
data. Though the word-level dependencies in UD
do not reﬂect the head ﬁnalness as only 45% of
Japanese dependencies have the head in the right
side, but when it comes to content words (the list
of functional PoSs are shown in the caption of Ta-
ble 6) without functional labels and exceptional la-
bels such as conjunction (see the caption again),

6The mismatched tokens are always regarded as parsing

errors in the calculation of UAS/LAS.

43Own tokenizers

Models
Our model
TRL (Kanayama et al., 2017)
HIT-SCIR (Che et al., 2017)
Our model - UDPipe aligned

UDPipe default tokenization C2L2 (Shi et al., 2017)

Gold tokenization

Stanford (Dozat et al., 2017)
Our model - with gold tokenization
UDPipe UDv2.0 model (Straka and Strakov´a, 2017)
RBG Parser (Lei et al., 2014)

Tokens UAS
94.03
98.61
91.14
98.59
81.94
92.95
75.88
89.41
75.46
89.68
75.42
89.68
95.97
100.0
100.0
95.48
94.94
100.0

Table 5: F1 scores of tokenization and UAS on the UD Japanese-GSD test set. The top section shows the
systems which used their own tokenizers. The second section is a comparison with the systems relying
on the default settings of UDPipe, and the bottom section is the situation to ru parsers using the gold PoS
as input.

language

ar
cs
en
ﬁ
ja
he
hi
hu
id
kk
ko
ro
ru
ta
tr
ur
vi
zh

all
0.31
0.56
0.61
0.57
0.45
0.48
0.58
0.69
0.36
0.59
0.63
0.47
0.49
0.71
0.64
0.59
0.41
0.72

content
0.09
0.45
0.49
0.54
0.96
0.21
0.91
0.72
0.24
0.77
0.70
0.26
0.39
0.92
0.78
0.89
0.34
0.79

selected

0.09
0.49
0.54
0.60
1.00
0.21
0.95
0.76
0.30
0.82
0.98
0.30
0.43
0.97
0.87
0.94
0.36
0.83

Table 6: The ratio of head-ﬁnal dependencies by
languages. “All” denotes the ratio of all nodes ex-
cept for the root. “Content” is the head-ﬁnal ra-
tio for content words, i.e. functional PoSs (ADP,
AUX, CCONJ, DET, SCONJ, SYM, PART, and
PUNCT) are excluded.
“selected” means the
more selective ones, excluding the labels conj,
ﬁxed, ﬂat, aux and mark.

Japanese has the complete head-ﬁnal structures,
and Korean and Tamil have high ratios supporting
the linguistic theory.

However, the UD Korean corpus has so many
coordination structures under the UD’s general
constraint that the left coordinate should be the
head, because many subordinating structures are
represented as coordination while corresponding
Japanese ones are not, that it is difﬁcult to con-
vert the corpus to the strictly head-ﬁnal structure.
That is the reason why we could not evaluate
our method on Korean, but the Triplet/Quadruplet
Model has been applied to Korean with sim-
ilar grammatical rules and it has been shown
that the transfer learning from Japanese worked
(Kanayama et al., 2014), thus our neural classiﬁer
approach to Korean parsing is expected to work
well.

Also UD Tamil data has exceptional cases in
proper nouns and other phenomena, and the rela-
tively small corpus made the further investigation
difﬁcult. We are leaving it to future work.

6 Related work
The parsing approach to select heads of depen-
dents has been proposed by Zhang et al. (2017).
They applied bidirectional RNN to select the prob-
ability that each word chooses another word or the
ROOT node as its head. They reported compa-
rable results for four languages. Their method re-
quired a maximum spanning tree algorithm to gen-
erate valid trees. On the other hand, our approach
straightforwardly outputs the projective tree by ex-
ploiting the head-ﬁnal feature in Japanese.

Mart´ınez-Alonso et al. (2017) shares the similar

44motivation with ours. They tackled multilingual
parsing by using a small set of attachment rules
determined with Universal POS, and achieved 55
UAS value with predicted PoS as input. Our
method applied a neural model on top of the gram-
matical restriction to achieve higher accuracy for a
speciﬁc language.

Garc´ıa et al. (2017) tackled the multilingual
shared task with the rule-based approach. The
rules are simpliﬁed with the almost delexicalized
PoS-level constraints and created with a small ef-
fort by an expert. Though the performance was
limited compared to other supervised approaches,
it is meaningful for the comparison of linguistic
features, and the combination with machine learn-
ing methods can be useful as we are aiming at.
7 Conclusion
In this paper we implemented a neural net pars-
ing model as the direct classiﬁer to predict the
attachment of phrasal units in a intuitive manner
by exploiting grammatical knowledge and heuris-
tics, and conﬁrmed that the neural net model
outperformed the conventional machine learning
method, and our method worked better than the
shared task results. Unlike the most of neural
parsing methods in which interpretation of the
model output and control of the model without
data supervision are difﬁcult, our method is simple
enough to understand the behavior of the model,
and the grammatical knowledge can be reﬂected in
the restriction of modiﬁcation candidates. More-
over, the neural net with distributed vector repre-
sentations enabled us to handle more vocabularies
than the logistic regression with distinct word fea-
tures in which only the limited number of content
words and their combination with other features
could be distinguished in the parsing model.

Our experiments showed that a limited number
of words are seen as able to predict attachments.
For further improvement, we can integrate the
LSTM model, which handles more contextual in-
formation with simpliﬁcation (Cross and Huang,
2016). We did not handle coordination relation-
ships explicitly in this work, but we will intend to
address coordination with more lexical knowledge
and a broader context.

rado, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Ian Goodfellow, Andrew Harp,
Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal
Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
Levenberg, Dan Man´e, Rajat Monga, Sherry Moore,
Derek Murray, Chris Olah, Mike Schuster, Jonathon
Shlens, Benoit Steiner, Ilya Sutskever, Kunal Tal-
war, Paul Tucker, Vincent Vanhoucke, Vijay Vasude-
van, Fernanda Vi´egas, Oriol Vinyals, Pete Warden,
Martin Wattenberg, Martin Wicke, Yuan Yu, and Xi-
aoqiang Zheng. 2015. TensorFlow: Large-scale ma-
chine learning on heterogeneous systems. Software
available from tensorﬂow.org.

Masayuki Asahara, Hiroshi Kanayama, Takaaki
Tanaka, Yusuke Miyao, Sumire Uematsu, Shinsuke
Mori, Yuji Matsumoto, Mai Omura, and Yugo Mu-
rawaki. 2018. Universal Dependencies version 2 for
Japanese. In Proceedings of LREC 2018.

Wanxiang Che, Jiang Guo, Yuxuan Wang, Bo Zheng,
Huaipeng Zhao, Yang Liu, Dechuan Teng, and Ting
Liu. 2017. The hit-scir system for end-to-end pars-
ing of universal dependencies. Proceedings of the
CoNLL 2017 Shared Task: Multilingual Parsing
from Raw Text to Universal Dependencies pages 52–
62.

Danqi Chen and Christopher Manning. 2014. A fast
and accurate dependency parser using neural net-
In Proceedings of the 2014 conference on
works.
empirical methods in natural language processing
(EMNLP). pages 740–750.

James Cross and Liang Huang. 2016.

Incremental
parsing with minimal features using bi-directional
In The 54th Annual Meeting of the Associa-
lstm.
tion for Computational Linguistics. page 32.

Timothy Dozat, Peng Qi, and Christopher D Manning.
2017. Stanford’s graph-based neural dependency
parser at the conll 2017 shared task. Proceedings
of the CoNLL 2017 Shared Task: Multilingual Pars-
ing from Raw Text to Universal Dependencies pages
20–30.

EDR. 1996. EDR (Japan Electronic Dictionary Re-
search Institute, Ltd.) electronic dictionary version
1.5 technical guide.

Marcos Garc´ıa and Pablo Gamallo. 2017. A rule-
based system for cross-lingual parsing of romance
languages with universal dependencies. In CoNLL
Shared Task.

Hiroshi Kanayama, Masayasu Muraoka, and Kat-
sumasa Yoshikawa. 2017.
A semi-universal
pipelined approach to the conll 2017 ud shared task.
Proceedings of the CoNLL 2017 Shared Task: Mul-
tilingual Parsing from Raw Text to Universal Depen-
dencies pages 265–273.

References
Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene
Brevdo, Zhifeng Chen, Craig Citro, Greg S. Cor-

Hiroshi Kanayama, Tetsuya Nasukawa, and Hideo
Watanabe. 2004. Deeper sentiment analysis using
machine translation technology. In COLING 2004.
pages 494–500.

45Hiroshi Kanayama, Youngja Park, Yuta Tsuboi, and
Dongmook Yi. 2014.
Learning from a neigh-
bor: Adapting a japanese parser for korean through
In Proceedings of the
feature transfer learning.
EMNLP’2014 Workshop on Language Technology
for Closely Related Languages and Language Vari-
ants. pages 2–12.

Hiroshi Kanayama, Kentaro Torisawa, Yutaka Mitsu-
ishi, and Jun’ichi Tsujii. 2000. A hybrid Japanese
parser with hand-crafted grammar and statistics. In
Proceedings of the 18th International Conference on
Computational Linguistics. pages 411–417.

Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti
Hasida. 2002. Construction of a japanese relevance-
tagged corpus. In LREC.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .

Tao Lei, Yuan Zhang, Regina Barzilay, and Tommi
Jaakkola. 2014. Low-rank tensors for scoring de-
pendency structures. Association for Computational
Linguistics.

H´ector Mart´ınez Alonso, ˇZeljko Agi´c, Barbara Plank,
and Anders Søgaard. 2017. Parsing universal depen-
dencies without training. In Proceedings of the 15th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics. Valencia, Spain,
pages 230–240.

Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
pages 523–530.

Tetsuya Nasukawa and Tohru Nagano. 2001. Text anal-
IBM systems

ysis and knowledge mining system.
journal 40(4):967–984.

Joakim Nivre, Cristina Bosco, Jinho Choi, Marie-
Catherine de Marneffe, Timothy Dozat, Richard
Farkas, Jennifer Foster, Filip Ginter, Yoav Gold-
berg, Jan Haji, Jenna Kanerva, Veronika Laippala,
Alessandro Lenci, Teresa Lynn, Christopher Man-
ning, Ryan McDonald, Anna Missila, Simonetta
Montemagni, Slav Petrov, Sampo Pyysalo, Natalia
Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty,
Veronika Vincze, and Daniel Zeman. 2015. Univer-
sal dependencies 1.0.

Joakim Nivre,

Johan Hall,

Jens Nilsson, Atanas
Chanev, G¨uls¸en Eryigit, Sandra K¨ubler, Svetoslav
Marinov, and Erwin Marsi. 2007. Maltparser: A
language-independent system for data-driven de-
pendency parsing. Natural Language Engineering
13(2):95–135.

Joakim Nivre and Ryan McDonald. 2008.

Integrat-
ing graph-based and transition-based dependency
parsers. Proceedings of ACL-08 pages 950–958.

Maria Polinsky. 2012. Headness, again. UCLA Work-
ing Papers in Linguistics, Theories of Everything
17:348–359.

Tianze Shi, Felix G Wu, Xilun Chen, and Yao Cheng.
2017. Combining global models for parsing univer-
sal dependencies. Proceedings of the CoNLL 2017
Shared Task: Multilingual Parsing from Raw Text to
Universal Dependencies pages 31–39.

Milan Straka, Jan Hajic, and Jana Strakov´a. 2016.
Udpipe: Trainable pipeline for processing conll-u
ﬁles performing tokenization, morphological analy-
sis, pos tagging and parsing. In LREC.

Milan Straka and Jana Strakov´a. 2017. Tokenizing,
pos tagging, lemmatizing and parsing ud 2.0 with
udpipe. In Proceedings of the CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Univer-
sal Dependencies. Association for Computational
Linguistics, pages 88–99.

Takaaki Tanaka, Yusuke Miyao, Masayuki Asahara,
Sumire Uematsu, Hiroshi Kanayama, Shinsuke
Mori, and Yuji Matsumoto. 2016. Universal depen-
dencies for japanese. In Proceedings of LREC 2016.

Daniel Zeman, Martin Popel, Milan Straka,

Jan
Hajiˇc, Joakim Nivre, Filip Ginter, Juhani Luotolahti,
Sampo Pyysalo, Slav Petrov, Martin Potthast, Fran-
cis Tyers, Elena Badmaeva, Memduh G¨okırmak,
Anna Nedoluzhko, Silvie Cinkov´a, Jan Hajiˇc jr.,
Jaroslava Hlav´aˇcov´a, V´aclava Kettnerov´a, Zdeˇnka
Ureˇsov´a, Jenna Kanerva, Stina Ojala, Anna Mis-
sil¨a, Christopher Manning, Sebastian Schuster, Siva
Reddy, Dima Taji, Nizar Habash, Herman Leung,
Marie-Catherine de Marneffe, Manuela Sanguinetti,
Maria Simi, Hiroshi Kanayama, Valeria de Paiva,
Kira Droganova, Hˇector Mart´ınez Alonso, Hans
Uszkoreit, Vivien Macketanz, Aljoscha Burchardt,
Kim Harris, Katrin Marheinecke, Georg Rehm,
Tolga Kayadelen, Mohammed Attia, Ali Elkahky,
Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael
Mandl, Jesse Kirchner, Hector Fernandez Alcalde,
Jana Strnadova, Esha Banerjee, Ruli Manurung, An-
tonio Stella, Atsuko Shimada, Sookyoung Kwak,
Gustavo Mendonc¸a, Tatiana Lando, Rattima Nitis-
aroj, and Josie Li. 2017. CoNLL 2017 Shared Task:
Multilingual Parsing from Raw Text to Universal
Dependencies. In Proceedings of the CoNLL 2017
Shared Task: Multilingual Parsing from Raw Text to
Universal Dependencies. Association for Computa-
tional Linguistics.

Xingxing Zhang, Jianpeng Cheng, and Mirella Lapata.
2017. Dependency parsing as head selection.
In
Proceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics. pages 665–676.

46