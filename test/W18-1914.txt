Turning	NMT	research	
into	commercial	
products	

Dragos	Munteanu	and	Adrià	de	Gispert	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 166helping	big	brands	go	global	

•  Founded	in	1992	
•  3800+	Employees	
•  56	Offices	
•  38	Countries	
•  400	Partners	
•  1500	Enterprise	
customers	

78	of	the	top	
100	global	
companies	
work	with	
SDL	

+10	BILLION	
words	
translated	
monthly	

marketing	campaigns	 eCommerce	 documentation	 web,	social	media	 analytics	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 167SDL	Research	–	a	long	history	in	MT	
•  Research	labs	in	Los	Angeles	(USA)	and	Cambridge	(UK)	
•  Team	members	have	published	+100	on	SMT	and	related	tech	

–  Bill	Byrne,	Abdessamad	Echihabi,	Dragos	Munteanu,	Gonzalo	Iglesias,	Eva	
Hasler,	Adrià	de	Gispert,	Steve	DeNeefe,	Jonathan	Graehl,	Wes	Feely,	Ling	
Tsou...	

•  Formerly	Language	Weaver	

–  15	years	of	leading	expertise	in	SMT	
–  major	contributions	(papers/patents)	in	phrase-based	and	string-to-tree	MT,	

automata-based	hierarchical	MT,	quality	estimation,	tuning,	evaluation...		

•  Strong	links	with	academia		(University	of	Cambridge)	
•  Summer	internships,	industrial	post-docs	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 168Our	mission:	Bring	MT	research	results	to	products	

○  We	strive	to	provide	our	customers:		

High	translation	
quality	

Translation	speed	

Approaches	that	
work	for	many	
language	pairs	

Terminology	and	
dictionaries	

Privacy!	Top-quality	MT	
on	premise	and	in	
private	cloud	

Consistency	

Customization	/	
Personalization	

Respect	file	
formats	and	tags	

Controllable	
memory	and	disk	
footprint	

Ability	to	learn	
over	time	
(AdaptiveMT)	

Robustness	to	
mis-spellings	

Connectors,	
plug-ins…	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 169SDL	Secure	Enterprise	Translation	Server	

Data	Security	
-  On	premises/private	cloud	
-  Used	by	gov’t	for	15	years	

Quality	/	Customization	
-  Neural	MT	
-  Custom	MT	out-of-the-box	

Cost-effective	scalability	
-  Elastic,	optimized	footprint	
-  Commodity	hardware	

Ease	of	Use	/	Integration	
-  deploys	In	hours	
-  MS	plug-in	&	REST	API	

ü 45	NMT	engines	currently	available	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 170Neural Machine Translation 

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 171A	paradigm	shift	

Independence	assumption	
(separate	sub-problems)	

SMT	
•  Symbolic	models	
• 
•  Maximum-likelihood	
•  CPU-oriented	training	
•  Source-side-guided	decoding	
•  Large	databases	

estimation	

Neural	MT	
•  Continuous-space	models	
•  Single	end-to-end	model	
•  Discriminative	training	
•  Reliance	on	GPUs	
•  Target-side-guided	decoding	
•  Smaller	compact	models	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 172Better	translation	models	

[Sutskever	et	al.’14]	[Bahdanau	et	al.’15]	

[Gehring	et	al.’17]	

[Vaswani	et	al.’17]	

[Zhou	et	al.’16]	

Proceedings of AMTA 2018, vol. 2: MT Users' TrackBoston, March 17 - 21, 2018   |   Page 173Better	BLEU	scores	

Statistical MT 

Rules-Based 

1970 

2002 

2016 

Neural MT 

WAT	
2014	
2015	
2016	
2017	

Jpn-Eng	
23.8	
25.4	
27.6	
28.4	
+4.4 !! 

Eng-Jpn	
35.0	
35.8	
36.2	
41.5	
+6.5 !! 

COMPARING	OUTPUTS 

©	2017	SDL	Plc	

SMT	

NMT 

Observable	quality	improvement	

国連難民高等弁務官事務所（UNHCR）は、内戦状態にあるシリアから逃れ
た難民の数が5百万人を超えたと発表した。	

Ofﬁce of the United Nations High Commissioner for Refugees 
(UNHCR) is in a state of civil war when the number of refugees who 
have escaped from Syria have exceeded 5 million people.	
The United Nations High Commissioner for Refugees (UNHCR) 
announced that the number of refugees escaped from Syria in the 
civil war was over ﬁve million people.	

ü  30%	improvement	over	SMT	across	all	our	productized	engines	

But…	is	it	ALL	that	good?	

There	are	situations	in	which	NMT	fails	
	
•  When	it	fails,	it	fails	spectacularly 

–  unrelated	fluent	text	
–  repetitions,	neurobabble…	

•  MT	user/customer	expectations	
–  “MT	is	not	supposed	to	do	this”	!!!?!	
–  “Can	it	support	the	features	I	need”	???	

Over-generation	and	‘neurobabble’	

There was no clear correlation between the measured mass density 
and the measured mass density, and neither experiment A or B. 	

The company will pay approximately EUR 600 million in ﬁnes, and 
the U.S. Department of Justice (SEC) to pay for approximately EUR 
600 million, and the U.S. Department of Justice and the Justice 
Department of Justice (SEC) to reduce the amount of internal control 
of the board of directors of the board of directors of the board of 
directors… 

Over-generation	and	‘neurobabble’	

There was no clear correlation between the measured mass density 
and the measured mass density, and neither experiment A or B. 	

The company will pay approximately EUR 600 million in ﬁnes, and 
the U.S. Department of Justice (SEC) to pay for approximately EUR 
600 million, and the U.S. Department of Justice and the Justice 
Department of Justice (SEC) to reduce the amount of internal control 
of the board of directors of the board of directors of the board of 
directors… 

Data	is	EVEN	MORE	important	
•  New	NMT	models	are	better	learners	

– A	better	fit	to	the	training	data	
– Relevant	training	data	is	key		
– Avoid	babble	and	get	huge	gains!	

•  Domain	adaptation/data	selection	

[Freitag	and	Al-Onaizan’16]	[Chen	et	al.’17]	[Britz	et	al.’17]	
[Farajian	et	al.’17]	[Van	der	Wees	et	al.’17]	[Wang	et	al.’17]	
…	

Adapting	neural	models	

Jpn-Eng	corpus	
Generic	
Automotive	

#	words	
>	300M	
<	1M	

Major	improvements!	
	
Challenge:	
§  Adapt	to	customer	
domain/data	with	
minimal	re-training	

§  Maintain	high	quality	

across	domains	

Lexical	selection	
•  NMT	models	have	freedom	to	
produce	any	target	word	
–  Guided	by	source,	not	constrained	
•  SMT	engines	were	good	at	lexical	
selection	–	can	we	leverage?	
–  T-table,	n-gram	and	phrase	

probabilities,	memory-augmented	
models/search	

[Arthur	et	al.	EMNLP’16]	[Stahlberg	et	al.	EACL’17]	[Wang	et	al.;	Dahlmann	et	al.;						
Feng	et	al.	EMNLP’17]	[Zhang	et	al.	IJCNLP’17]	…	

[Arthur	et	al.	EMNLP’16]	

[Wang	et	al.	EMNLP’17]	

NMT	can	use	N-gram	posterior	probabilities	

Stahlberg	et	al.	(EACL’17):	“Neural	Machine	Translation	by	Minimising	the	Bayes-risk	with	Respect	
to	Syntactic	Translation	Lattices”	

But…	are	there	guarantees?	
•  Control	is	a	must	for	commercial	success	
•  One	very	bad	sentence	can	put	off	a	customer	

–  Back-off	if	needed	

•  Customers/Users	expect	certain	‘features’	
–  Decoding	speed,	dictionary	support,	formatting	

constraints,	Adaptive	MT,	…	

Dictionary	support	

English	
Zimra	Games	
Coke	Assault	3	
…	

“Zimra Games continues to innovate with 
the release next month of Coke Assault 3, 
which will satisfy the most demanding 
gamers.”	
•  Translation	output	must	translate	dictionary	
matches	exactly	–	constrained	search	
•  Easy	for	SMT	decoders	
•  NMT	beam	decoder	does	not	keep	an	alignment	between	

German	
Zimra	Games	GmbH	
Coke	Assault	III	
…	

[Anderson	et	al.	EMNLP’17]	
[Hokamp	&	Liu	ACL’17]		
[Chatterjee	et	al.	WMT’17]	

source	and	target	words	

Dictionary	support	

Constrained	search	
•  Build	a	finite-state	acceptor	with	
the	target-side	constraints	
•  Keep	one	separate	stack	per	
•  Output	only	hypotheses	from	
Ø Constraints	can	be	words	or	

the	final	acceptor	state	

each	acceptor	state	

phrases	

[Anderson	et	al.	EMNLP’17]	

Dictionary	support	

Challenges	
•  Computational	complexity	

grows	exponentially	with	the	
number	of	constraints	
–  order	is	unknown		

•  Nothing	prevents	repeated	

decoding:	

“Zimra Games GmbH setzt mit dem Veröffentlichung 
auf Coke Assault III im nächsten Monat der Angriff …
	

Entity	constraints	

“<B>Zimra Games</B> continues to innovate with the release <I>next 
month</I> of <B>Coke Assault <c=red>3</c></B>, which will satisfy the 
most demanding gamers.”	
•  Decoder	must	also	respect	meta-tags	
•  NMT	model	should	not	break	sequential	history		
•  Solutions	require	model	specialization	and/or	
decoding	restrictions	

–  Key	to	support	file	formats	used	by	MT	users	

Decoding	speed	
•  MT	users	are	expected	to	certain	translation	speeds	
–  Target	speed	varies,	but	well	above	research	engines	
•  Goal	is	to	provide	best	quality	at	desired	speed	
•  NMT	deployment	scenarios	

–  Speed	vs	quality	trade-off	

–  CPU	only	–	hand-held	devices,	…		
–  GPU	
•  NMT	training	speed	also	relevant	

Decoding	speed	vs	quality	trade-off	(1)	
•  Model	architecture	

–  recurrent,	

convolutional,	
attentional…	

–  number	of	

parameters,	layer	
precomputations…	

–  Unfolding	and	

shrinking	ensembles	

[Stahlberg	and	Byrne,	EMNLP’17]	

Stahlberg	and	Byrne	(EMNLP’17):	“Unfolding	and	Shrinking	Neural	Machine	Translation	Ensembles”	

Decoding	speed	vs	quality	trade-off	(2)	
•  Hardware	and	Linear	Algebra	
library	
–  Type	of	GPU	card	
–  CPU-GPU	communication	
–  GPU	usage	

•  Batching	

–  standard	in	training	

Decoding	speed	vs	quality	trade-off	(3)	
•  Decoding	parameters	
–  beam	size,	early	stopping…	
•  Reduced	vocabulary	softmax	(CPU)	
•  Weight	clipping	in	training	

–  Low-precision	inference	

[Wu	et	al.’16]		[Devlin,	EMNLP’17]	…	

Software	and	Services	for	Human	Understanding	
Copyright	©	2008-2017	SDL	plc.	All	rights	reserved.	All	company	names,	brand	names,	
trademarks,	service	marks,	images	and	logos	are	the	property	of	their	respective	owners.	
	
This	presentation	and	its	content	are	SDL	confidential	unless	otherwise	specified,	and	may	
not	be	copied,	used	or	distributed	except	as	authorised	by	SDL.	

